<!doctype html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="Refrain">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Refrain">
<meta property="og:description" content="学无止境">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Refrain">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title> Refrain </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Refrain</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/22/SparkStreaming初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/22/SparkStreaming初体验/" itemprop="url">
                  SparkStreaming初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-22T15:53:39+08:00">
                2017-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkStreaming简单介绍"><a href="#SparkStreaming简单介绍" class="headerlink" title="SparkStreaming简单介绍"></a>SparkStreaming简单介绍</h2><p>Spark Streaming是建立在Spark上的实时计算框架<br>输入和输出概览：<br><img src="/images/201701/SparkStreaming_1.png"><br>Spark Streaming把实时输入数据流以时间片(如1秒)为单位切分成块。SparkStreaming会把每块数据作为一个RDD，并使用RDD操作处理每一小块数据<br><img src="/images/201701/SparkStreaming_2.png"></p>
<h2 id="例子-从kafka输入源-读取数据后-直接输出"><a href="#例子-从kafka输入源-读取数据后-直接输出" class="headerlink" title="例子:从kafka输入源 读取数据后 直接输出"></a>例子:从kafka输入源 读取数据后 直接输出</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</div><div class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">process_58_data</span> </span>&#123;</div><div class="line">  <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">ERROR</span>)</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> masterUrl = <span class="string">"local[2]"</span> <span class="comment">//不能local，需要两个核以上</span></div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(masterUrl).setAppName(<span class="string">"58_data"</span>)</div><div class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</div><div class="line">    <span class="keyword">val</span> topics = <span class="type">Set</span>(<span class="string">"58_data"</span>) <span class="comment">//kafka的topic</span></div><div class="line">    <span class="keyword">val</span> brokers = <span class="string">"master:9092,worker1:9092,worker2:9092"</span> <span class="comment">//kafka端口</span></div><div class="line">    <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">"metadata.broker.list"</span> -&gt; brokers)</div><div class="line">    <span class="keyword">val</span> kafkaStream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](ssc, kafkaParams, topics) <span class="comment">//调用Kafka工具包创建DSteam</span></div><div class="line">    kafkaStream.foreachRDD(rdd =&gt;&#123;</div><div class="line">      rdd.foreachPartition(iter =&gt; &#123;</div><div class="line">        iter.foreach( x =&gt;</div><div class="line">          println(x._2)</div><div class="line">        )</div><div class="line">      &#125;)</div><div class="line">    &#125;)</div><div class="line">    ssc.start() <span class="comment">//启动流计算环境StreamingContext</span></div><div class="line">    ssc.awaitTermination() <span class="comment">//等待作业完成</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之前写过简单的爬虫用来抓取网页信息，将数据放入kafka中，配合SparkStreaming，最后输出结果如下:<br><img src="/images/201701/SparkStreaming_3.png"></p>
<h2 id="SparkStreaming中DSteam转化操作"><a href="#SparkStreaming中DSteam转化操作" class="headerlink" title="SparkStreaming中DSteam转化操作"></a>SparkStreaming中DSteam转化操作</h2><h3 id="无状态："><a href="#无状态：" class="headerlink" title="无状态："></a>无状态：</h3><p>SparkStreaming是建立在Spark，所以很多RDD转化操作都适用于Dsteam.<br>例如: map, flatMap, filter, repartition, join, reduceByKey<br>(注: 针对键值对的Dsteam转化操作需要import StreamingContext._)</p>
<h3 id="有状态-SparkStreaming特有的操作-："><a href="#有状态-SparkStreaming特有的操作-：" class="headerlink" title="有状态(SparkStreaming特有的操作)："></a>有状态(SparkStreaming特有的操作)：</h3><p>滑动窗口和updateStateByKey<br>滑动窗口使用详情可以参考：<a href="http://blog.csdn.net/legotime/article/details/51836040" target="_blank" rel="external">http://blog.csdn.net/legotime/article/details/51836040</a></p>
<p>参考文档：<br><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a><br>《Spark快速大数据分析》</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/21/spark机器学习初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/21/spark机器学习初体验/" itemprop="url">
                  spark机器学习初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-21T18:19:48+08:00">
                2017-01-21
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="垃圾邮件分类例子"><a href="#垃圾邮件分类例子" class="headerlink" title="垃圾邮件分类例子"></a>垃圾邮件分类例子</h2><h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><p>垃圾邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">spam.txt</div><div class="line">Dear sir, I am a Prince in a far kingdom you have not heard of.  I want to send you money via wire transfer so please ...</div><div class="line">Get Viagra real cheap!  Send money right away to ...</div><div class="line">Oh my gosh you can be really strong too with these drugs found in the rainforest. Get them cheap right now ...</div><div class="line">YOUR COMPUTER HAS BEEN INFECTED!  YOU MUST RESET YOUR PASSWORD.  Reply to this email with your password and SSN ...</div><div class="line">THIS IS NOT A SCAM!  Send money and get access to awesome stuff really cheap and never have to ...</div></pre></td></tr></table></figure></p>
<p>正常邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ham.txt</div><div class="line">Dear Spark Learner, Thanks so much for attending the Spark Summit 2014!  Check out videos of talks from the summit at ...</div><div class="line">Hi Mom, Apologies for being late about emailing and forgetting to send you the package.  I hope you and bro have been ...</div><div class="line">Wow, hey Fred, just heard about the Spark petabyte sort.  I think we need to take time to try it out immediately ...</div><div class="line">Hi Spark user list, This is my first question to this list, so thanks in advance for your help!  I tried running ...</div><div class="line">Thanks Tom for your email.  I need to refer you to Alice for this one.  I haven&apos;t yet figured out that part either ...</div><div class="line">Good job yesterday!  I was attending your talk, and really enjoyed it.  I want to try out GraphX ...</div><div class="line">Summit demo got whoops from audience!  Had to let you know. --Joe</div></pre></td></tr></table></figure></p>
<h3 id="Scala代码"><a href="#Scala代码" class="headerlink" title="Scala代码"></a>Scala代码</h3><p>这个程序使用了MLlib两个函数：HashingTF(从文本数据构建 词频特征向量)和LogisticRegressionWithSGD(随机体度下降法实现逻辑回归)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.<span class="type">LogisticRegressionWithSGD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.feature.<span class="type">HashingTF</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">MLlib</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">s"Book example: Scala"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line"></div><div class="line">    <span class="comment">// Load 2 types of emails from text files: spam and ham (non-spam).</span></div><div class="line">    <span class="comment">// Each line has text from one email.</span></div><div class="line">    <span class="keyword">val</span> spam = sc.textFile(<span class="string">"files/spam.txt"</span>)</div><div class="line">    <span class="keyword">val</span> ham = sc.textFile(<span class="string">"files/ham.txt"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Create a HashingTF instance to map email text to vectors of 100 features.</span></div><div class="line">    <span class="keyword">val</span> tf = <span class="keyword">new</span> <span class="type">HashingTF</span>(numFeatures = <span class="number">100</span>)</div><div class="line">    <span class="comment">// Each email is split into words, and each word is mapped to one feature.</span></div><div class="line">    <span class="comment">// 1、特征提取</span></div><div class="line">    <span class="keyword">val</span> spamFeatures = spam.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line">    <span class="keyword">val</span> hamFeatures = ham.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line"></div><div class="line">    <span class="comment">// Create LabeledPoint datasets for positive (spam) and negative (ham) examples.</span></div><div class="line">    <span class="comment">// 2、将文本数据转换为数值特征，返回LabeledPoint类型RDD(包含一个特质向量和一个标签)</span></div><div class="line">    <span class="keyword">val</span> positiveExamples = spamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">1</span>, features))</div><div class="line">    <span class="keyword">val</span> negativeExamples = hamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">0</span>, features))</div><div class="line">    <span class="keyword">val</span> trainingData = positiveExamples ++ negativeExamples</div><div class="line">    trainingData.cache() <span class="comment">// Cache data since Logistic Regression is an iterative algorithm.</span></div><div class="line"></div><div class="line">    <span class="comment">// Create a Logistic Regression learner which uses the LBFGS optimizer.</span></div><div class="line">    <span class="comment">// 3、调用分类算法，返回模型对象</span></div><div class="line">    <span class="keyword">val</span> lrLearner = <span class="keyword">new</span> <span class="type">LogisticRegressionWithSGD</span>()</div><div class="line">    <span class="comment">// Run the actual learning algorithm on the training data.</span></div><div class="line">    <span class="keyword">val</span> model = lrLearner.run(trainingData)</div><div class="line"></div><div class="line">    <span class="comment">// Test on a positive example (spam) and a negative one (ham).</span></div><div class="line">    <span class="comment">// First apply the same HashingTF feature transformation used on the training data.</span></div><div class="line">    <span class="keyword">val</span> posTestExample = tf.transform(<span class="string">"O M G GET cheap stuff by sending money to ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="keyword">val</span> negTestExample = tf.transform(<span class="string">"Hi Dad, I started studying Spark the other ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="comment">// Now use the learned model to predict spam/ham for new emails.</span></div><div class="line">    println(<span class="string">s"Prediction for positive test example: <span class="subst">$&#123;model.predict(posTestExample)&#125;</span>"</span>)</div><div class="line">    println(<span class="string">s"Prediction for negative test example: <span class="subst">$&#123;model.predict(negTestExample)&#125;</span>"</span>)</div><div class="line"></div><div class="line">    sc.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>运行结果如果所示：<br><img src="/images/201701/SparkML_1.png"></p>
<h2 id="机器学习流水线中典型步骤"><a href="#机器学习流水线中典型步骤" class="headerlink" title="机器学习流水线中典型步骤"></a>机器学习流水线中典型步骤</h2><p>源数据ETL-&gt;数据预处理-&gt;特征提取(返回MLlib的数据类型，比如上例的LabeledPoint类型)-&gt;训练(返回模型)-&gt;模型评估</p>
<h2 id="简单理解"><a href="#简单理解" class="headerlink" title="简单理解"></a>简单理解</h2><p>确定模型—-训练模型—-使用模型<br>模型简单说可以理解为函数。<br>确定模型是说自己认为这些数据的特征符合哪个函数(应该使用什么模型)<br>训练模型就是用已有的数据，通过一些方法（最优化或者其他方法）确定函数的参数，参数确定后的函数就是训练的结果<br>使用模型就是把新的数据代入函数求值</p>
<p>参考文档：<br>《Spark快速大数据分析》<br><a href="https://www.zhihu.com/question/29271217?sort=created" target="_blank" rel="external">https://www.zhihu.com/question/29271217?sort=created</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/20/spark源码浅析-提交Task到Executor/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/20/spark源码浅析-提交Task到Executor/" itemprop="url">
                  spark源码浅析：提交Task到Executor
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-20T16:15:23+08:00">
                2017-01-20
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="从DAGScheduler-submitMissingTasks-开始追源码"><a href="#从DAGScheduler-submitMissingTasks-开始追源码" class="headerlink" title="从DAGScheduler.submitMissingTasks 开始追源码"></a>从DAGScheduler.submitMissingTasks 开始追源码</h2><p>DAGScheduler.submitMissingTasks主要功能<br>1、找到RDD中需要计算的partition<br>2、获取Task的最佳计算位置<br>3、序列化Task的Binary，并进行广播<br>4、根据stage的不同类型创建，为stage的每个分区创建创建task,并封装成TaskSet<br>5、调用TaskScheduler的submitTasks，提交TaskSet<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** Called when stage's parents are available and we can now do its task. */</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>) &#123;</div><div class="line">  logDebug(<span class="string">"submitMissingTasks("</span> + stage + <span class="string">")"</span>)</div><div class="line">  <span class="comment">// Get our pending tasks and remember them in our pendingTasks entry</span></div><div class="line">  stage.pendingPartitions.clear()</div><div class="line"></div><div class="line">  <span class="comment">// First figure out the indexes of partition ids to compute.</span></div><div class="line">  <span class="comment">// 1、找到RDD中需要计算的partition</span></div><div class="line">  <span class="comment">// 对于Shuffle类型的Stage，需要判断stage中是否缓存了该结果</span></div><div class="line">  <span class="comment">// 对于Result类型的Stage，则判断计算Job中该partition是否已经计算完成</span></div><div class="line">  <span class="keyword">val</span> partitionsToCompute: <span class="type">Seq</span>[<span class="type">Int</span>] = stage.findMissingPartitions()</div><div class="line"></div><div class="line">  <span class="comment">// Create internal accumulators if the stage has no accumulators initialized.</span></div><div class="line">  <span class="comment">// Reset internal accumulators only if this stage is not partially submitted</span></div><div class="line">  <span class="comment">// Otherwise, we may override existing accumulator values from some tasks</span></div><div class="line">  <span class="keyword">if</span> (stage.internalAccumulators.isEmpty || stage.numPartitions == partitionsToCompute.size) &#123;</div><div class="line">    stage.resetInternalAccumulators()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Use the scheduling pool, job group, description, etc. from an ActiveJob associated</span></div><div class="line">  <span class="comment">// with this Stage</span></div><div class="line">  <span class="keyword">val</span> properties = jobIdToActiveJob(jobId).properties</div><div class="line"></div><div class="line">  runningStages += stage</div><div class="line">  <span class="comment">// SparkListenerStageSubmitted should be posted before testing whether tasks are</span></div><div class="line">  <span class="comment">// serializable. If tasks are not serializable, a SparkListenerStageCompleted event</span></div><div class="line">  <span class="comment">// will be posted, which should always come after a corresponding SparkListenerStageSubmitted</span></div><div class="line">  <span class="comment">// event.</span></div><div class="line">  stage <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - <span class="number">1</span>)</div><div class="line">    <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</div><div class="line">      outputCommitCoordinator.stageStart(</div><div class="line">        stage = s.id, maxPartitionId = s.rdd.partitions.length - <span class="number">1</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 2、获取Task的最佳计算位置</span></div><div class="line">  <span class="comment">// 根据RDD的数据信息得到task的最佳计算位置，从而获取较好的数据本地性</span></div><div class="line">  <span class="keyword">val</span> taskIdToLocations: <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">TaskLocation</span>]] = <span class="keyword">try</span> &#123;</div><div class="line">    stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap</div><div class="line">      <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="keyword">val</span> job = s.activeJob.get</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> p = s.partitions(id)</div><div class="line">          (id, getPreferredLocs(stage.rdd, p))</div><div class="line">        &#125;.toMap</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      stage.makeNewStageAttempt(partitionsToCompute.size)</div><div class="line">      listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</div><div class="line">      abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)</div><div class="line">  listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</div><div class="line"></div><div class="line">  <span class="comment">// <span class="doctag">TODO:</span> Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.</span></div><div class="line">  <span class="comment">// Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast</span></div><div class="line">  <span class="comment">// the serialized copy of the RDD and for each task we will deserialize it, which means each</span></div><div class="line">  <span class="comment">// task gets a different copy of the RDD. This provides stronger isolation between tasks that</span></div><div class="line">  <span class="comment">// might modify state of objects referenced in their closures. This is necessary in Hadoop</span></div><div class="line">  <span class="comment">// where the JobConf/Configuration object is not thread-safe.</span></div><div class="line">  <span class="comment">// 3、序列化Task的Binary，并进行广播</span></div><div class="line">  <span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).</span></div><div class="line">    <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).</span></div><div class="line">    <span class="keyword">val</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>).array()</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">        closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>).array()</div><div class="line">    &#125;</div><div class="line">    taskBinary = sc.broadcast(taskBinaryBytes)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="comment">// In the case of a failure during serialization, abort the stage.</span></div><div class="line">    <span class="keyword">case</span> e: <span class="type">NotSerializableException</span> =&gt;</div><div class="line">      abortStage(stage, <span class="string">"Task not serializable: "</span> + e.toString, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line"></div><div class="line">      <span class="comment">// Abort execution</span></div><div class="line">      <span class="keyword">return</span></div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      abortStage(stage, <span class="string">s"Task serialization failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 4、根据stage的不同类型创建，为stage的每个分区创建创建task,并封装成TaskSet</span></div><div class="line">  <span class="comment">// Stage分两种类型ShuffleMapStage生成ShuffleMapTask，ResultStage生成ResultTask</span></div><div class="line">  <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</div><div class="line">    stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">          <span class="keyword">val</span> part = stage.rdd.partitions(id)</div><div class="line">          <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">            taskBinary, part, locs, stage.internalAccumulators)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="keyword">val</span> job = stage.activeJob.get</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</div><div class="line">          <span class="keyword">val</span> part = stage.rdd.partitions(p)</div><div class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">          <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">            taskBinary, part, locs, id, stage.internalAccumulators)</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</div><div class="line">    logInfo(<span class="string">"Submitting "</span> + tasks.size + <span class="string">" missing tasks from "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">")"</span>)</div><div class="line">    stage.pendingPartitions ++= tasks.map(_.partitionId)</div><div class="line">    logDebug(<span class="string">"New pending partitions: "</span> + stage.pendingPartitions)</div><div class="line">    <span class="comment">// 5、调用TaskScheduler的submitTasks，提交TaskSet</span></div><div class="line">    taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</div><div class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))</div><div class="line">    stage.latestInfo.submissionTime = <span class="type">Some</span>(clock.getTimeMillis())</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// Because we posted SparkListenerStageSubmitted earlier, we should mark</span></div><div class="line">    <span class="comment">// the stage as completed here in case there are no tasks to run</span></div><div class="line">    markStageAsFinished(stage, <span class="type">None</span>)</div><div class="line">    <span class="keyword">val</span> debugString = stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        <span class="string">s"Stage <span class="subst">$&#123;stage&#125;</span> is actually done; "</span> +</div><div class="line">          <span class="string">s"(available: <span class="subst">$&#123;stage.isAvailable&#125;</span>,"</span> +</div><div class="line">          <span class="string">s"available outputs: <span class="subst">$&#123;stage.numAvailableOutputs&#125;</span>,"</span> +</div><div class="line">          <span class="string">s"partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)"</span></div><div class="line">      <span class="keyword">case</span> stage : <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="string">s"Stage <span class="subst">$&#123;stage&#125;</span> is actually done; (partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)"</span></div><div class="line">    &#125;</div><div class="line">    logDebug(debugString)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSchedulerImpl-submitTasks"><a href="#TaskSchedulerImpl-submitTasks" class="headerlink" title="TaskSchedulerImpl.submitTasks"></a>TaskSchedulerImpl.submitTasks</h2><p>TaskSchedulerImpl.submitTasks主要功能<br>1、创建TaskSetManager<br>2、将TaskSetManager加入rootPool调度池中，由schedulableBuilder决定调度顺序<br>3、调用SchedulerBackend的reviveOffers方法对Task进行调度，决定task具体运行在哪个Executor中<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.submitTasks</div><div class="line">  <span class="comment">/*</span></div><div class="line">  * 主要将任务加入调度池，最后调用了backend.reviveOffers()</div><div class="line">  * 这里的backend是CoarseGrainedSchedulerBackend一个Executor任务调度对象</div><div class="line">  */</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">submitTasks</span></span>(taskSet: <span class="type">TaskSet</span>) &#123;</div><div class="line">    <span class="keyword">val</span> tasks = taskSet.tasks</div><div class="line">    logInfo(<span class="string">"Adding task set "</span> + taskSet.id + <span class="string">" with "</span> + tasks.length + <span class="string">" tasks"</span>)</div><div class="line">    <span class="keyword">this</span>.synchronized &#123;</div><div class="line">      <span class="comment">// 1、创建TaskSetManager</span></div><div class="line">      <span class="comment">// TaskSetManager会负责task的失败重试；跟踪每个task的执行状态；处理locality-aware的调用。</span></div><div class="line">      <span class="keyword">val</span> manager = createTaskSetManager(taskSet, maxTaskFailures)</div><div class="line">      <span class="keyword">val</span> stage = taskSet.stageId</div><div class="line">      <span class="keyword">val</span> stageTaskSets =</div><div class="line">        taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">TaskSetManager</span>])</div><div class="line">      stageTaskSets(taskSet.stageAttemptId) = manager</div><div class="line">      <span class="keyword">val</span> conflictingTaskSet = stageTaskSets.exists &#123; <span class="keyword">case</span> (_, ts) =&gt;</div><div class="line">        ts.taskSet != taskSet &amp;&amp; !ts.isZombie</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (conflictingTaskSet) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"more than one active taskSet for stage <span class="subst">$stage</span>:"</span> +</div><div class="line">          <span class="string">s" <span class="subst">$&#123;stageTaskSets.toSeq.map&#123;_._2.taskSet.id&#125;</span>.mkString("</span>,<span class="string">")&#125;"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// 2、将TaskSetManager加入rootPool调度池中，由schedulableBuilder决定调度顺序</span></div><div class="line">      <span class="comment">// SchedulerBuilder有两个实现FIFOSchedulerBuilder和FairSchedulerBuilder，默认采用的是FIFO方式</span></div><div class="line">      schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!isLocal &amp;&amp; !hasReceivedTask) &#123;</div><div class="line">        starvationTimer.scheduleAtFixedRate(<span class="keyword">new</span> <span class="type">TimerTask</span>() &#123;</div><div class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">            <span class="keyword">if</span> (!hasLaunchedTask) &#123;</div><div class="line">              logWarning(<span class="string">"Initial job has not accepted any resources; "</span> +</div><div class="line">                <span class="string">"check your cluster UI to ensure that workers are registered "</span> +</div><div class="line">                <span class="string">"and have sufficient resources"</span>)</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">              <span class="keyword">this</span>.cancel()</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;, <span class="type">STARVATION_TIMEOUT_MS</span>, <span class="type">STARVATION_TIMEOUT_MS</span>)</div><div class="line">      &#125;</div><div class="line">      hasReceivedTask = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 3、调用SchedulerBackend的reviveOffers方法对Task进行调度，决定task具体运行在哪个Executor中</span></div><div class="line">    backend.reviveOffers()</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>调用CoarseGrainedSchedulerBackend的reviveOffers方法，该方法给driverEndpoint发送ReviveOffer消息</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="type">CoarseGrainedSchedulerBackend</span>.reviveOffers</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>() &#123;</div><div class="line">    driverEndpoint.send(<span class="type">ReviveOffers</span>)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>driverEndpoint收到ReviveOffer消息后调用makeOffers方法</p>
<h2 id="CoarseGrainedSchedulerBackend-makeOffers"><a href="#CoarseGrainedSchedulerBackend-makeOffers" class="headerlink" title="CoarseGrainedSchedulerBackend.makeOffers"></a>CoarseGrainedSchedulerBackend.makeOffers</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="type">CoarseGrainedSchedulerBackend</span>.makeOffers</div><div class="line">    <span class="comment">// Make fake resource offers on all executor</span></div><div class="line">    <span class="comment">// makeOffers方法中，将Executor的信息集合与调度池中的Tasks封装成WokerOffers列表传给了 launchTasks</span></div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeOffers</span></span>() &#123;</div><div class="line">      <span class="comment">// Filter out executors under killing</span></div><div class="line">      <span class="comment">// 过滤出活跃状态的Executor</span></div><div class="line">      <span class="keyword">val</span> activeExecutors = executorDataMap.filterKeys(executorIsAlive)</div><div class="line">      <span class="comment">// 将Executor封装成WorkerOffer对象</span></div><div class="line">      <span class="keyword">val</span> workOffers = activeExecutors.map &#123; <span class="keyword">case</span> (id, executorData) =&gt;</div><div class="line">        <span class="keyword">new</span> <span class="type">WorkerOffer</span>(id, executorData.executorHost, executorData.freeCores)</div><div class="line">      &#125;.toSeq</div><div class="line">      launchTasks(scheduler.resourceOffers(workOffers))</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>注意：上面代码中的executorDataMap，在客户端向Master注册Application的时候，Master已经为Application分配并启动好Executor，然后注册给CoarseGrainedSchedulerBackend，注册信息就是存储在executorDataMap数据结构中。</p>
<h2 id="TaskSchedulerImpl-resourceOffers"><a href="#TaskSchedulerImpl-resourceOffers" class="headerlink" title="TaskSchedulerImpl.resourceOffers"></a>TaskSchedulerImpl.resourceOffers</h2><p>准备好计算资源后，接下来TaskSchedulerImpl基于这些计算资源为task分配Executor<br>看一下TaskSchedulerImpl的resourceOffers方法：<br>传递的参数offers表示worker提供的资源，该方法根据资源情况，结合待执行任务的优先级，将任务平衡的分配给executors<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.resourceOffers</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Called by cluster manager to offer resources on slaves. We respond by asking our active task</div><div class="line">   * sets for tasks in order of priority. We fill each node with tasks in a round-robin manner so</div><div class="line">   * that tasks are balanced across the cluster.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">resourceOffers</span></span>(offers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>]): <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]] = synchronized &#123;</div><div class="line">    <span class="comment">// Mark each slave as alive and remember its hostname</span></div><div class="line">    <span class="comment">// Also track if new executor is added</span></div><div class="line">    <span class="comment">// 激活所有slave节点，记录其hostname，并检查是否有新的executor加入</span></div><div class="line">    <span class="keyword">var</span> newExecAvail = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (o &lt;- offers) &#123;</div><div class="line">      executorIdToHost(o.executorId) = o.host</div><div class="line">      executorIdToTaskCount.getOrElseUpdate(o.executorId, <span class="number">0</span>)</div><div class="line">      <span class="keyword">if</span> (!executorsByHost.contains(o.host)) &#123;</div><div class="line">        executorsByHost(o.host) = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()</div><div class="line">        executorAdded(o.executorId, o.host)</div><div class="line">        newExecAvail = <span class="literal">true</span></div><div class="line">      &#125;</div><div class="line">      <span class="keyword">for</span> (rack &lt;- getRackForHost(o.host)) &#123;</div><div class="line">        hostsByRack.getOrElseUpdate(rack, <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()) += o.host</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Randomly shuffle offers to avoid always placing tasks on the same set of workers.</span></div><div class="line">    <span class="comment">// 随机打乱offers,避免总是前几个worker被分配到任务</span></div><div class="line">    <span class="keyword">val</span> shuffledOffers = <span class="type">Random</span>.shuffle(offers)</div><div class="line">    <span class="comment">// Build a list of tasks to assign to each worker.</span></div><div class="line">    <span class="comment">// 构建一个二维数组，保存每个Executor上将要分配的那些task</span></div><div class="line">    <span class="keyword">val</span> tasks = shuffledOffers.map(o =&gt; <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>](o.cores))</div><div class="line">    <span class="keyword">val</span> availableCpus = shuffledOffers.map(o =&gt; o.cores).toArray</div><div class="line">    <span class="comment">// 根据SchedulerBuilder的调度算法，给TaskManager排好序</span></div><div class="line">    <span class="keyword">val</span> sortedTaskSets = rootPool.getSortedTaskSetQueue</div><div class="line">    <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets) &#123;</div><div class="line">      logDebug(<span class="string">"parentName: %s, name: %s, runningTasks: %s"</span>.format(</div><div class="line">        taskSet.parent.name, taskSet.name, taskSet.runningTasks))</div><div class="line">      <span class="keyword">if</span> (newExecAvail) &#123;</div><div class="line">        taskSet.executorAdded()</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Take each TaskSet in our scheduling order, and then offer it each node in increasing order</span></div><div class="line">    <span class="comment">// of locality levels so that it gets a chance to launch local tasks on all of them.</span></div><div class="line">    <span class="comment">// <span class="doctag">NOTE:</span> the preferredLocality order: PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></div><div class="line">    <span class="comment">// 按照调度优先级顺序遍历TaskSet，在所有系统资源(WorkerOffer)上从最高Locality到最低Locality依次尝试执行最适合的task</span></div><div class="line">    <span class="comment">// 数据本地性级别顺序: PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></div><div class="line">    <span class="keyword">var</span> launchedTask = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets; maxLocality &lt;- taskSet.myLocalityLevels) &#123;</div><div class="line">      do &#123;</div><div class="line">        launchedTask = resourceOfferSingleTaskSet(</div><div class="line">            taskSet, maxLocality, shuffledOffers, availableCpus, tasks)</div><div class="line">      &#125; <span class="keyword">while</span> (launchedTask)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</div><div class="line">      hasLaunchedTask = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> tasks</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSchedulerImpl-resourceOfferSingleTaskSet"><a href="#TaskSchedulerImpl-resourceOfferSingleTaskSet" class="headerlink" title="TaskSchedulerImpl.resourceOfferSingleTaskSet"></a>TaskSchedulerImpl.resourceOfferSingleTaskSet</h2><p>下面再看看resourceOfferSingleTaskSet代码<br>用当前的数据本地性，调用TaskSetManager的resourceOffer方法，在当前executor上分配task<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.resourceOfferSingleTaskSet</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">resourceOfferSingleTaskSet</span></span>(</div><div class="line">      taskSet: <span class="type">TaskSetManager</span>,</div><div class="line">      maxLocality: <span class="type">TaskLocality</span>,</div><div class="line">      shuffledOffers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>],</div><div class="line">      availableCpus: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">      tasks: <span class="type">Seq</span>[<span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>]]) : <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">var</span> launchedTask = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until shuffledOffers.size) &#123;</div><div class="line">      <span class="keyword">val</span> execId = shuffledOffers(i).executorId</div><div class="line">      <span class="keyword">val</span> host = shuffledOffers(i).host</div><div class="line">      <span class="comment">// 判断executor是否有足够的CPU核数来运行task</span></div><div class="line">      <span class="keyword">if</span> (availableCpus(i) &gt;= <span class="type">CPUS_PER_TASK</span>) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="comment">// 真正调用的是TaskSetManager.resourceOffer方法</span></div><div class="line">          <span class="keyword">for</span> (task &lt;- taskSet.resourceOffer(execId, host, maxLocality)) &#123;</div><div class="line">            tasks(i) += task</div><div class="line">            <span class="keyword">val</span> tid = task.taskId</div><div class="line">            taskIdToTaskSetManager(tid) = taskSet</div><div class="line">            taskIdToExecutorId(tid) = execId</div><div class="line">            executorIdToTaskCount(execId) += <span class="number">1</span></div><div class="line">            executorsByHost(host) += execId</div><div class="line">            availableCpus(i) -= <span class="type">CPUS_PER_TASK</span></div><div class="line">            assert(availableCpus(i) &gt;= <span class="number">0</span>)</div><div class="line">            launchedTask = <span class="literal">true</span></div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="keyword">case</span> e: <span class="type">TaskNotSerializableException</span> =&gt;</div><div class="line">            logError(<span class="string">s"Resource offer failed, task set <span class="subst">$&#123;taskSet.name&#125;</span> was not serializable"</span>)</div><div class="line">            <span class="comment">// Do not offer resources for this task, but don't throw an error to allow other</span></div><div class="line">            <span class="comment">// task sets to be submitted.</span></div><div class="line">            <span class="keyword">return</span> launchedTask</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> launchedTask</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSetManager-resourceOffer"><a href="#TaskSetManager-resourceOffer" class="headerlink" title="TaskSetManager.resourceOffer"></a>TaskSetManager.resourceOffer</h2><p>TaskSetManager.resourceOffer方法的作用是为executor资源提供一个最符合数据本地性的任务<br>TaskLocality是枚举类，表示数据本地化的级别，其优先级为 PROCESS_LOCAL(最高) &lt; NODE_LOCAL &lt; NO_PREF &lt; RACK_LOCAL &lt; ANY(最低)<br>其中PROCESS_LOCAL，NODE_LOCAL，RACK_LOCAL可分别设置对应的延迟时间，默认值是3s<br>TaskSetManager内部维护了以下几个HashMap<br>1、pendingTasksForExecutor<br>2、pendingTasksForHost<br>3、pendingTasksForRack<br>4、pendingTasksWithNoPrefs<br>TaskSetManager在初始化时，若Task的preferredLocations不为空，则将Task添加到前三个pending队列；若为空，则加入pendingTasksWithNoPrefs<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// TaskSetManager.resourceOffer</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">resourceOffer</span></span>(</div><div class="line">    execId: <span class="type">String</span>,</div><div class="line">    host: <span class="type">String</span>,</div><div class="line">    maxLocality: <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span>)</div><div class="line">  : <span class="type">Option</span>[<span class="type">TaskDescription</span>] =</div><div class="line">&#123;</div><div class="line">  <span class="keyword">if</span> (!isZombie) &#123;</div><div class="line">    <span class="keyword">val</span> curTime = clock.getTimeMillis()</div><div class="line"></div><div class="line">    <span class="keyword">var</span> allowedLocality = maxLocality</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</div><div class="line">      <span class="comment">// 结合各Locality设置的延迟时间及上次成功在当前Locality级别提交任务的时间，获得能够允许的最高本地化级别的Locality级别</span></div><div class="line">      allowedLocality = getAllowedLocalityLevel(curTime)</div><div class="line">      <span class="comment">// 大于表示本地化级别更低</span></div><div class="line">      <span class="keyword">if</span> (allowedLocality &gt; maxLocality) &#123;</div><div class="line">        <span class="comment">// </span></div><div class="line">        allowedLocality = maxLocality</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// dequeueTask返回的是允许的Locality范围内Locality级别最高的Task的TaskDescription</span></div><div class="line">    dequeueTask(execId, host, allowedLocality) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>((index, taskLocality, speculative)) =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> task = tasks(index)</div><div class="line">        <span class="keyword">val</span> taskId = sched.newTaskId()</div><div class="line">        <span class="comment">// Do various bookkeeping</span></div><div class="line">        copiesRunning(index) += <span class="number">1</span></div><div class="line">        <span class="keyword">val</span> attemptNum = taskAttempts(index).size</div><div class="line">        <span class="keyword">val</span> info = <span class="keyword">new</span> <span class="type">TaskInfo</span>(taskId, index, attemptNum, curTime,</div><div class="line">          execId, host, taskLocality, speculative)</div><div class="line">        taskInfos(taskId) = info</div><div class="line">        taskAttempts(index) = info :: taskAttempts(index)</div><div class="line">        <span class="comment">// 除非Task的Locality级别为NO_PREF，否则更新当前Locality级别为该task的Locality，并更新lastLaunchTime</span></div><div class="line">        <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</div><div class="line">          currentLocalityIndex = getLocalityIndex(taskLocality)</div><div class="line">          lastLaunchTime = curTime</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 序列化task</span></div><div class="line">        <span class="keyword">val</span> startTime = clock.getTimeMillis()</div><div class="line">        <span class="keyword">val</span> serializedTask: <span class="type">ByteBuffer</span> = <span class="keyword">try</span> &#123;</div><div class="line">          <span class="type">Task</span>.serializeWithDependencies(task, sched.sc.addedFiles, sched.sc.addedJars, ser)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="comment">// 序列化出错没有重试的必要</span></div><div class="line">          <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">            <span class="keyword">val</span> msg = <span class="string">s"Failed to serialize task <span class="subst">$taskId</span>, not attempting to retry it."</span></div><div class="line">            logError(msg, e)</div><div class="line">            abort(<span class="string">s"<span class="subst">$msg</span> Exception during serialization: <span class="subst">$e</span>"</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">TaskNotSerializableException</span>(e)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 若task过大，则存在优化的必要</span></div><div class="line">        <span class="keyword">if</span> (serializedTask.limit &gt; <span class="type">TaskSetManager</span>.<span class="type">TASK_SIZE_TO_WARN_KB</span> * <span class="number">1024</span> &amp;&amp;</div><div class="line">            !emittedTaskSizeWarning) &#123;</div><div class="line">          emittedTaskSizeWarning = <span class="literal">true</span></div><div class="line">          logWarning(<span class="string">s"Stage <span class="subst">$&#123;task.stageId&#125;</span> contains a task of very large size "</span> +</div><div class="line">            <span class="string">s"(<span class="subst">$&#123;serializedTask.limit / 1024&#125;</span> KB). The maximum recommended task size is "</span> +</div><div class="line">            <span class="string">s"<span class="subst">$&#123;TaskSetManager.TASK_SIZE_TO_WARN_KB&#125;</span> KB."</span>)</div><div class="line">        &#125;</div><div class="line">        addRunningTask(taskId)</div><div class="line"></div><div class="line">        <span class="comment">// We used to log the time it takes to serialize the task, but task size is already</span></div><div class="line">        <span class="comment">// a good proxy to task serialization time.</span></div><div class="line">        <span class="comment">// val timeTaken = clock.getTime() - startTime</span></div><div class="line">        <span class="keyword">val</span> taskName = <span class="string">s"task <span class="subst">$&#123;info.id&#125;</span> in stage <span class="subst">$&#123;taskSet.id&#125;</span>"</span></div><div class="line">        logInfo(<span class="string">"Starting %s (TID %d, %s, %s, %d bytes)"</span>.format(</div><div class="line">            taskName, taskId, host, taskLocality, serializedTask.limit))</div><div class="line"></div><div class="line">        <span class="comment">// 通知DAGScheduler任务开始执行</span></div><div class="line">        sched.dagScheduler.taskStarted(task, info)</div><div class="line">        <span class="keyword">return</span> <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">TaskDescription</span>(taskId = taskId, attemptNumber = attemptNum, execId,</div><div class="line">          taskName, index, serializedTask))</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> _ =&gt;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="type">None</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSetManager-getAllowedLocalityLevel"><a href="#TaskSetManager-getAllowedLocalityLevel" class="headerlink" title="TaskSetManager.getAllowedLocalityLevel"></a>TaskSetManager.getAllowedLocalityLevel</h2><p>TaskSetManager.getAllowedLocalityLevel结合各Locality设置的延迟时间及上次成功在当前Locality级别提交任务的时间，获得能够允许的最高本地化级别的Locality级别<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// TaskSetManager.getAllowedLocalityLevel</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getAllowedLocalityLevel</span></span>(curTime: <span class="type">Long</span>): <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span> = &#123;</div><div class="line">  <span class="comment">// 移除已被调度或完成的task，采用的是lazy方式</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tasksNeedToBeScheduledFrom</span></span>(pendingTaskIds: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">var</span> indexOffset = pendingTaskIds.size</div><div class="line">    <span class="keyword">while</span> (indexOffset &gt; <span class="number">0</span>) &#123;</div><div class="line">      indexOffset -= <span class="number">1</span></div><div class="line">      <span class="keyword">val</span> index = pendingTaskIds(indexOffset)</div><div class="line">      <span class="keyword">if</span> (copiesRunning(index) == <span class="number">0</span> &amp;&amp; !successful(index)) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="literal">true</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        pendingTaskIds.remove(indexOffset)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="literal">false</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 遍历pendingTasks，移除已被调度的task，若仍有task待调度，返回true</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">moreTasksToRunIn</span></span>(pendingTasks: <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]]): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">val</span> emptyKeys = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">String</span>]</div><div class="line">    <span class="keyword">val</span> hasTasks = pendingTasks.exists &#123;</div><div class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, tasks: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]) =&gt;</div><div class="line">        <span class="keyword">if</span> (tasksNeedToBeScheduledFrom(tasks)) &#123;</div><div class="line">          <span class="literal">true</span></div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          emptyKeys += id</div><div class="line">          <span class="literal">false</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// The key could be executorId, host or rackId</span></div><div class="line">    emptyKeys.foreach(id =&gt; pendingTasks.remove(id))</div><div class="line">    hasTasks</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// currentLocalityIndex记录了当前运行在哪个TaskLocality</span></div><div class="line">  <span class="keyword">while</span> (currentLocalityIndex &lt; myLocalityLevels.length - <span class="number">1</span>) &#123;</div><div class="line">    <span class="keyword">val</span> moreTasks = myLocalityLevels(currentLocalityIndex) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">PROCESS_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForExecutor)</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">NODE_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForHost)</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span> =&gt; pendingTasksWithNoPrefs.nonEmpty</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">RACK_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForRack)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (!moreTasks) &#123;</div><div class="line">      <span class="comment">// 若当前Locality没有需要执行的task，则进入更低一级Locality，并更新lastLaunchTime</span></div><div class="line">      lastLaunchTime = curTime</div><div class="line">      logDebug(<span class="string">s"No tasks for locality level <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex)&#125;</span>, "</span> +</div><div class="line">        <span class="string">s"so moving to locality level <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex + 1)&#125;</span>"</span>)</div><div class="line">      currentLocalityIndex += <span class="number">1</span></div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curTime - lastLaunchTime &gt;= localityWaits(currentLocalityIndex)) &#123;</div><div class="line">      <span class="comment">// 若距离上次成功在此Locality级别提交任务的时间间隔超过了该Locality级别设定的延迟时间，则进入更低一级Locality，并更新lastLaunchTime</span></div><div class="line">      lastLaunchTime += localityWaits(currentLocalityIndex)</div><div class="line">      currentLocalityIndex += <span class="number">1</span></div><div class="line">      logDebug(<span class="string">s"Moving to <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex)&#125;</span> after waiting for "</span> +</div><div class="line">        <span class="string">s"<span class="subst">$&#123;localityWaits(currentLocalityIndex)&#125;</span>ms"</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> myLocalityLevels(currentLocalityIndex)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  myLocalityLevels(currentLocalityIndex)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>取得最适合运行的Task后，调用ScheduledBackend.launchTasks方法 将task在Executor上启动运行</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="http://www.cnblogs.com/zhouyf/p/5743382.html" target="_blank" rel="external">http://www.cnblogs.com/zhouyf/p/5743382.html</a><br><a href="http://blog.csdn.net/anzhsoft/article/details/40238111#comments" target="_blank" rel="external">http://blog.csdn.net/anzhsoft/article/details/40238111#comments</a><br><a href="http://blog.csdn.net/bigdata_wang/article/details/48846129" target="_blank" rel="external">http://blog.csdn.net/bigdata_wang/article/details/48846129</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/19/hbase分布式搭建/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/19/hbase分布式搭建/" itemprop="url">
                  hbase分布式搭建
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-19T11:45:40+08:00">
                2017-01-19
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="已有的环境"><a href="#已有的环境" class="headerlink" title="已有的环境"></a>已有的环境</h2><p>三台机器hostname: master, worker1, worker2<br>并已安装好分布式Hadoop2.6.0</p>
<h3 id="定位JAVA-HOME"><a href="#定位JAVA-HOME" class="headerlink" title="定位JAVA_HOME"></a>定位JAVA_HOME</h3><p>mac: 使用命令/usr/libexec/java_home<br><img src="/images/201701/JAVA_HOME_2.png"><br>linux: 如下图所示<br><img src="/images/201701/JAVA_HOME_1.png"></p>
<h2 id="下载HBase"><a href="#下载HBase" class="headerlink" title="下载HBase"></a>下载HBase</h2><p>官网下载地址：<a href="http://www.apache.org/dyn/closer.cgi/hbase/" target="_blank" rel="external">http://www.apache.org/dyn/closer.cgi/hbase/</a><br>我下载的是Stable版本：<a href="http://mirrors.cnnic.cn/apache/hbase/stable/hbase-1.2.4-bin.tar.gz" target="_blank" rel="external">http://mirrors.cnnic.cn/apache/hbase/stable/hbase-1.2.4-bin.tar.gz</a></p>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>将下载后的压缩包解压后 放到/Users/xiwu/hbase-1.2.4目录下</p>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-env-sh"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-env-sh" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-env.sh"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-env.sh</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=通过之前方法定位</div><div class="line"><span class="built_in">export</span> HBASE_LOG_DIR=/Users/xiwu/hbase-1.2.4/logs</div><div class="line"><span class="comment">#如果使用HBase自带的Zookeeper值设成true 如果使用自己安装的Zookeeper需要将该值设为false</span></div><div class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">true</span></div></pre></td></tr></table></figure>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-site-xml"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-site-xml" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-site.xml"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.rootdir&lt;/name&gt;</div><div class="line">        &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</div><div class="line">        &lt;value&gt;true&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</div><div class="line">        &lt;value&gt;master,worker1,worker2&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.master.maxclockskew&lt;/name&gt;</div><div class="line">        &lt;value&gt;180000&lt;/value&gt;</div><div class="line">        &lt;description&gt;Time difference of regionserver from master&lt;/description&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>hbase.rootdir 指定Hbase数据存储目录<br>hbase.cluster.distributed 指定是否是完全分布式模式，单机模式和伪分布式模式需要将该值设为false<br>hbase.zookeeper.quorum 指定zooke的集群，多台机器以逗号分隔</p>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-regionservers"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-regionservers" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim regionservers"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim regionservers</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">master</div><div class="line">worker1</div><div class="line">worker2</div></pre></td></tr></table></figure>
<p>PS.以上操作在三台机器都相同。可以在一台机器上弄好后，scp复制过去</p>
<h2 id="启动HBase"><a href="#启动HBase" class="headerlink" title="启动HBase"></a>启动HBase</h2><p>//先启动hdfs<br>cd ${HADOOP_HOME} &amp;&amp; ./sbin/start-dfs.sh<br>//再启动hbase<br>cd ${HBASE_HOME} &amp;&amp; ./bin/start-hbase.sh<br>正确启动后结果如图所示:<br><img src="/images/201701/hbase_1.png"><br>master: HMaster,HQuorumPeer,HRegionServer<br>worker1,worker2: HQuorumPeer,HRegionServer<br>也可以登录：<a href="http://master:16010/" target="_blank" rel="external">http://master:16010/</a> 查看HBase状态<br>如果所示:<br><img src="/images/201701/hbase_2.png"></p>
<h2 id="测试HBase"><a href="#测试HBase" class="headerlink" title="测试HBase"></a>测试HBase</h2><p>cd ${HBASE_HOME} &amp;&amp; ./bin/hbase shell<br><img src="/images/201701/hbase_3.png"><br><img src="/images/201701/hbase_4.png"><br><img src="/images/201701/hbase_5.png"><br>更多操作参考<a href="http://www.yiibai.com/hbase/hbase_shell.html" target="_blank" rel="external">http://www.yiibai.com/hbase/hbase_shell.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/18/spark提交任务源码浅析/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/18/spark提交任务源码浅析/" itemprop="url">
                  Spark源码浅析：Stage划分及提交Task
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-18T11:37:59+08:00">
                2017-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="spark版本"><a href="#spark版本" class="headerlink" title="spark版本"></a>spark版本</h3><p>spark 1.6.1</p>
<h2 id="从Rdd的action开始追源码，最后都会到rdd-runJob"><a href="#从Rdd的action开始追源码，最后都会到rdd-runJob" class="headerlink" title="从Rdd的action开始追源码，最后都会到rdd.runJob"></a>从Rdd的action开始追源码，最后都会到rdd.runJob</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// RDD.scala</span></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Run a function on a given set of partitions in an RDD and pass the results to the given</div><div class="line">   * handler function. This is the main entry point for all actions in Spark.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](</div><div class="line">      rdd: <span class="type">RDD</span>[<span class="type">T</span>],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</div><div class="line">      partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</div><div class="line">      resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">if</span> (stopped.get()) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"SparkContext has been shutdown"</span>)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> callSite = getCallSite</div><div class="line">    <span class="keyword">val</span> cleanedFunc = clean(func)</div><div class="line">    logInfo(<span class="string">"Starting job: "</span> + callSite.shortForm)</div><div class="line">    <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.logLineage"</span>, <span class="literal">false</span>)) &#123;</div><div class="line">      logInfo(<span class="string">"RDD's recursive dependencies:\n"</span> + rdd.toDebugString)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</div><div class="line">    progressBar.foreach(_.finishAll())</div><div class="line">    rdd.doCheckpoint()</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>可以看到接下来调用了dagScheduler.runJob<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</div><div class="line">      rdd: <span class="type">RDD</span>[<span class="type">T</span>],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</div><div class="line">      partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</div><div class="line">      callSite: <span class="type">CallSite</span>,</div><div class="line">      resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</div><div class="line">      properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> start = <span class="type">System</span>.nanoTime</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</div><div class="line">    waiter.awaitResult() <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">JobSucceeded</span> =&gt;</div><div class="line">        logInfo(<span class="string">"Job %d finished: %s, took %f s"</span>.format</div><div class="line">          (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</div><div class="line">      <span class="keyword">case</span> <span class="type">JobFailed</span>(exception: <span class="type">Exception</span>) =&gt;</div><div class="line">        logInfo(<span class="string">"Job %d failed: %s, took %f s"</span>.format</div><div class="line">          (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</div><div class="line">        <span class="comment">// SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.</span></div><div class="line">        <span class="keyword">val</span> callerStackTrace = <span class="type">Thread</span>.currentThread().getStackTrace.tail</div><div class="line">        exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)</div><div class="line">        <span class="keyword">throw</span> exception</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</div><div class="line">      rdd: <span class="type">RDD</span>[<span class="type">T</span>],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</div><div class="line">      partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</div><div class="line">      callSite: <span class="type">CallSite</span>,</div><div class="line">      resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</div><div class="line">      properties: <span class="type">Properties</span>): <span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</div><div class="line">    <span class="comment">// Check to make sure we are not launching a task on a partition that does not exist.</span></div><div class="line">    <span class="keyword">val</span> maxPartitions = rdd.partitions.length</div><div class="line">    partitions.find(p =&gt; p &gt;= maxPartitions || p &lt; <span class="number">0</span>).foreach &#123; p =&gt;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(</div><div class="line">        <span class="string">"Attempting to access a non-existent partition: "</span> + p + <span class="string">". "</span> +</div><div class="line">          <span class="string">"Total number of partitions: "</span> + maxPartitions)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> jobId = nextJobId.getAndIncrement()</div><div class="line">    <span class="keyword">if</span> (partitions.size == <span class="number">0</span>) &#123;</div><div class="line">      <span class="comment">// Return immediately if the job is running 0 tasks</span></div><div class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, <span class="number">0</span>, resultHandler)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    assert(partitions.size &gt; <span class="number">0</span>)</div><div class="line">    <span class="keyword">val</span> func2 = func.asInstanceOf[(<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _]</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>(<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</div><div class="line">    eventProcessLoop.post(<span class="type">JobSubmitted</span>(</div><div class="line">      jobId, rdd, func2, partitions.toArray, callSite, waiter,</div><div class="line">      <span class="type">SerializationUtils</span>.clone(properties)))</div><div class="line">    waiter</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>eventProcessLoop是DAGSchedulerEventProcessLoop类的实例，DAGSchedulerEventProcessLoop类是EventLoop的子类。EventLoop里有一个阻塞队列，post函数往队列里放请求，还有开启了一个线程不断从队列里取请求。<br>以上代码总结，往队列里放了一个JobSubmitted的请求，然后需要处理JobSubmitted请求了<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line"><span class="keyword">private</span>[scheduler] <span class="class"><span class="keyword">class</span> <span class="title">DAGSchedulerEventProcessLoop</span>(<span class="params">dagScheduler: <span class="type">DAGScheduler</span></span>)</span></div><div class="line">  <span class="keyword">extends</span> <span class="type">EventLoop</span>[<span class="type">DAGSchedulerEvent</span>](<span class="string">"dag-scheduler-event-loop"</span>) <span class="keyword">with</span> <span class="type">Logging</span> &#123;</div><div class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> timer = dagScheduler.metricsSource.messageProcessingTimer</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * The main event loop of the DAG scheduler.</div><div class="line">   */</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> timerContext = timer.time()</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      doOnReceive(event)</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      timerContext.stop()</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doOnReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = event <span class="keyword">match</span> &#123;</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">case</span> <span class="type">JobSubmitted</span>(jobId, rdd, func, partitions, callSite, listener, properties) =&gt;</div><div class="line">      dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</div><div class="line">      ...</div><div class="line">      ...</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="comment">/*</span></div><div class="line">  * 下面的代码中，调用了newResultStage进行任务的划分，该方法是划分任务的核心方法，划分任务的根据最后一个依赖关系作为开始，</div><div class="line">  * 通过递归，将每个宽依赖做为切分Stage的依据，切分Stage的过程是流程中的一环，当任务切分完毕后</div><div class="line">  * 代码继续执行来到submitStage(finalStage)这里开始进行任务提交</div><div class="line">  */</div><div class="line">  <span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</div><div class="line">      finalRDD: <span class="type">RDD</span>[_],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</div><div class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">      callSite: <span class="type">CallSite</span>,</div><div class="line">      listener: <span class="type">JobListener</span>,</div><div class="line">      properties: <span class="type">Properties</span>) &#123;</div><div class="line">    <span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="comment">// New stage creation may throw an exception if, for example, jobs are run on a</span></div><div class="line">      <span class="comment">// HadoopRDD whose underlying HDFS files have been deleted.</span></div><div class="line">      <span class="comment">//== Next Step 1==</span></div><div class="line">      finalStage = newResultStage(finalRDD, func, partitions, jobId, callSite)</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">        logWarning(<span class="string">"Creating new stage failed due to exception - job: "</span> + jobId, e)</div><div class="line">        listener.jobFailed(e)</div><div class="line">        <span class="keyword">return</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)</div><div class="line">    clearCacheLocs()</div><div class="line">    logInfo(<span class="string">"Got job %s (%s) with %d output partitions"</span>.format(</div><div class="line">      job.jobId, callSite.shortForm, partitions.length))</div><div class="line">    logInfo(<span class="string">"Final stage: "</span> + finalStage + <span class="string">" ("</span> + finalStage.name + <span class="string">")"</span>)</div><div class="line">    logInfo(<span class="string">"Parents of final stage: "</span> + finalStage.parents)</div><div class="line">    logInfo(<span class="string">"Missing parents: "</span> + getMissingParentStages(finalStage))</div><div class="line"></div><div class="line">    <span class="keyword">val</span> jobSubmissionTime = clock.getTimeMillis()</div><div class="line">    jobIdToActiveJob(jobId) = job</div><div class="line">    activeJobs += job</div><div class="line">    finalStage.setActiveJob(job)</div><div class="line">    <span class="keyword">val</span> stageIds = jobIdToStageIds(jobId).toArray</div><div class="line">    <span class="keyword">val</span> stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))</div><div class="line">    listenerBus.post(</div><div class="line">      <span class="type">SparkListenerJobStart</span>(job.jobId, jobSubmissionTime, stageInfos, properties))</div><div class="line">    <span class="comment">//== Next Step 2==</span></div><div class="line">    submitStage(finalStage)</div><div class="line">    submitWaitingStages()</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>newResultStage函数 通过传入finalRDD最后返回finalStage (stage之间和rdd之间都会有依赖关系, newResultStage函数是 通过rdd之间的依赖关系 划分stage的)<br>继续看源码<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Create a ResultStage associated with the provided jobId.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">newResultStage</span></span>(</div><div class="line">      rdd: <span class="type">RDD</span>[_],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</div><div class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">      jobId: <span class="type">Int</span>,</div><div class="line">      callSite: <span class="type">CallSite</span>): <span class="type">ResultStage</span> = &#123;</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">val</span> (parentStages: <span class="type">List</span>[<span class="type">Stage</span>], id: <span class="type">Int</span>) = getParentStagesAndId(rdd, jobId)</div><div class="line">    <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ResultStage</span>(id, rdd, func, partitions, parentStages, jobId, callSite)</div><div class="line">    stageIdToStage(id) = stage</div><div class="line">    updateJobIdStageIdMaps(jobId, stage)</div><div class="line">    stage</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getParentStagesAndId</span></span>(rdd: <span class="type">RDD</span>[_], firstJobId: <span class="type">Int</span>): (<span class="type">List</span>[<span class="type">Stage</span>], <span class="type">Int</span>) = &#123;</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">val</span> parentStages = getParentStages(rdd, firstJobId)</div><div class="line">    <span class="keyword">val</span> id = nextStageId.getAndIncrement()</div><div class="line">    (parentStages, id)</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>以上代码是为了获取finalRDD对应finalStages的所有依赖父Stage</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Get or create the list of parent stages for a given RDD.  The new Stages will be created with</div><div class="line">   * the provided firstJobId.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getParentStages</span></span>(rdd: <span class="type">RDD</span>[_], firstJobId: <span class="type">Int</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> parents = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</div><div class="line">    <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></div><div class="line">    <span class="comment">// caused by recursively visiting</span></div><div class="line">    <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(r: <span class="type">RDD</span>[_]) &#123;</div><div class="line">      <span class="keyword">if</span> (!visited(r)) &#123;</div><div class="line">        visited += r</div><div class="line">        <span class="comment">// Kind of ugly: need to register RDDs with the cache here since</span></div><div class="line">        <span class="comment">// we can't do it in its constructor because # of partitions is unknown</span></div><div class="line">        <span class="keyword">for</span> (dep &lt;- r.dependencies) &#123;</div><div class="line">          dep <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</div><div class="line">              <span class="comment">//== Next Step == PS.如果是finalRdd的直接宽依赖，那么需要划分stage了</span></div><div class="line">              parents += getShuffleMapStage(shufDep, firstJobId)</div><div class="line">            <span class="keyword">case</span> _ =&gt;</div><div class="line">              waitingForVisit.push(dep.rdd)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    waitingForVisit.push(rdd)</div><div class="line">    <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</div><div class="line">      visit(waitingForVisit.pop())</div><div class="line">    &#125;</div><div class="line">    parents.toList</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Get or create a shuffle map stage for the given shuffle dependency's map side.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getShuffleMapStage</span></span>(</div><div class="line">      shuffleDep: <span class="type">ShuffleDependency</span>[_, _, _],</div><div class="line">      firstJobId: <span class="type">Int</span>): <span class="type">ShuffleMapStage</span> = &#123;</div><div class="line">    shuffleToMapStage.get(shuffleDep.shuffleId) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(stage) =&gt; stage</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        <span class="comment">// We are going to register ancestor shuffle dependencies</span></div><div class="line">        <span class="comment">//== Next Step == PS.找到finalRdd的直接宽依赖rdd 对应的祖先宽依赖，进行注册</span></div><div class="line">        getAncestorShuffleDependencies(shuffleDep.rdd).foreach &#123; dep =&gt;</div><div class="line">          shuffleToMapStage(dep.shuffleId) = newOrUsedShuffleStage(dep, firstJobId)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// Then register current shuffleDep</span></div><div class="line">        <span class="keyword">val</span> stage = newOrUsedShuffleStage(shuffleDep, firstJobId)</div><div class="line">        shuffleToMapStage(shuffleDep.shuffleId) = stage</div><div class="line">        stage</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>以上代码是找到finalRdd的直接父Stage。并在找到直接宽依赖rdd的时候，对先找到这些rdd的所有祖先宽依赖，再对这些祖先宽依赖进行注册(这里也会划分stage)。<br>下面的代码是如果找到rdd的所有祖先宽依赖(直接或间接)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line">  <span class="comment">/** Find ancestor shuffle dependencies that are not registered in shuffleToMapStage yet */</span></div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getAncestorShuffleDependencies</span></span>(rdd: <span class="type">RDD</span>[_]): <span class="type">Stack</span>[<span class="type">ShuffleDependency</span>[_, _, _]] = &#123;</div><div class="line">    <span class="keyword">val</span> parents = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">ShuffleDependency</span>[_, _, _]]</div><div class="line">    <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></div><div class="line">    <span class="comment">// caused by recursively visiting</span></div><div class="line">    <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(r: <span class="type">RDD</span>[_]) &#123;</div><div class="line">      <span class="keyword">if</span> (!visited(r)) &#123;</div><div class="line">        visited += r</div><div class="line">        <span class="keyword">for</span> (dep &lt;- r.dependencies) &#123;</div><div class="line">          dep <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</div><div class="line">              <span class="keyword">if</span> (!shuffleToMapStage.contains(shufDep.shuffleId)) &#123;</div><div class="line">                parents.push(shufDep)</div><div class="line">              &#125;</div><div class="line">            <span class="keyword">case</span> _ =&gt;</div><div class="line">          &#125;</div><div class="line">          waitingForVisit.push(dep.rdd)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    waitingForVisit.push(rdd)</div><div class="line">    <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</div><div class="line">      visit(waitingForVisit.pop())</div><div class="line">    &#125;</div><div class="line">    parents</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>下面举一个例子来说明划分stage的过程<br><img src="/images/201701/dagPicture_1.png"><br>图说明：12表示finalRdd,蓝色表示宽依赖,黑色表示窄依赖<br>1、newResultStage函数 入参12号finalRdd, 通过函数getParentStagesAndId得到finalRdd的直接宽依赖9,10,4,5号Rdd在的Stage。并且注册9,10,4,5号Rdd在的Stage对应的所有直接或间接Stage(通过getParentStagesAndId下的getShuffleMapStage函数)<br>2、getShuffleMapStage函数 入参(举例:10号Rdd在的Stage), 通过函数getAncestorShuffleDependencies得到10号Rdd的所有直接或间接宽依赖(宽依赖有2号和3号)，并通过函数newOrUsedShuffleStage进行注册2号和3号成为新的Stage<br>最后划分的Stage如下图所示：<br><img src="/images/201701/dagPicture_2.png"></p>
<p>回到DAGScheduler.handleJobSubmitted函数<br>以上部分完成了handleJobSubmitted函数的newResultStage步骤(划分Stage)，函数还有submitStage步骤<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** Submits stage, but first recursively submits any missing parents. */</span></div><div class="line"><span class="comment">//递归的方式提交stage</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>) &#123;</div><div class="line">  <span class="keyword">val</span> jobId = activeJobForStage(stage)</div><div class="line">  <span class="keyword">if</span> (jobId.isDefined) &#123;</div><div class="line">    logDebug(<span class="string">"submitStage("</span> + stage + <span class="string">")"</span>)</div><div class="line">    <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</div><div class="line">      <span class="comment">//== Next Step 1 ==</span></div><div class="line">      <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id) <span class="comment">//获取未提交过的直接宽依赖</span></div><div class="line">      logDebug(<span class="string">"missing: "</span> + missing)</div><div class="line">      <span class="keyword">if</span> (missing.isEmpty) &#123;</div><div class="line">        logInfo(<span class="string">"Submitting "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">"), which has no missing parents"</span>)</div><div class="line">        <span class="comment">//== Next Step 2 ==</span></div><div class="line">        submitMissingTasks(stage, jobId.get) <span class="comment">//提交任务(parentStage都提交过了)</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">for</span> (parent &lt;- missing) &#123;</div><div class="line">          <span class="comment">//提交 没有提交过的parentStage</span></div><div class="line">          submitStage(parent)</div><div class="line">        &#125;</div><div class="line">        waitingStages += stage <span class="comment">//记录待提交的Stages</span></div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    abortStage(stage, <span class="string">"No active job for stage "</span> + stage.id, <span class="type">None</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getMissingParentStages</span></span>(stage: <span class="type">Stage</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> missing = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</div><div class="line">  <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</div><div class="line">  <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></div><div class="line">  <span class="comment">// caused by recursively visiting</span></div><div class="line">  <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">RDD</span>[_]]</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(rdd: <span class="type">RDD</span>[_]) &#123;</div><div class="line">    <span class="keyword">if</span> (!visited(rdd)) &#123;</div><div class="line">      visited += rdd</div><div class="line">      <span class="keyword">val</span> rddHasUncachedPartitions = getCacheLocs(rdd).contains(<span class="type">Nil</span>)</div><div class="line">      <span class="keyword">if</span> (rddHasUncachedPartitions) &#123;</div><div class="line">        <span class="keyword">for</span> (dep &lt;- rdd.dependencies) &#123;</div><div class="line">          dep <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</div><div class="line">              <span class="keyword">val</span> mapStage = getShuffleMapStage(shufDep, stage.firstJobId)</div><div class="line">              <span class="keyword">if</span> (!mapStage.isAvailable) &#123;</div><div class="line">                missing += mapStage</div><div class="line">              &#125;</div><div class="line">            <span class="keyword">case</span> narrowDep: <span class="type">NarrowDependency</span>[_] =&gt;</div><div class="line">              waitingForVisit.push(narrowDep.rdd)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  waitingForVisit.push(stage.rdd)</div><div class="line">  <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</div><div class="line">    visit(waitingForVisit.pop())</div><div class="line">  &#125;</div><div class="line">  missing.toList</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>继续以上面的图为例，submitStage(Stage8) =&gt; getMissingParentStages(Stage8) 得到 Stage4, Stage5, Stage6, Stage7<br>再递归提交submitStage(Stage4), submitStage(Stage5),submitStage(Stage6),submitStage(Stage7)…<br>最后能调用submitMissingTasks函数的有Stage1, Stage2, Stage3, Stage4, Stage5<br>waitingStages记录待提交有Stage6, Stage7, Stage8.最后通过DAGScheduler.handleJobSubmitted的submitWaitingStages处理这些待提交的Stage<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitWaitingStages</span></span>() &#123;</div><div class="line">  <span class="comment">// <span class="doctag">TODO:</span> We might want to run this less often, when we are sure that something has become</span></div><div class="line">  <span class="comment">// runnable that wasn't before.</span></div><div class="line">  logTrace(<span class="string">"Checking for newly runnable parent stages"</span>)</div><div class="line">  logTrace(<span class="string">"running: "</span> + runningStages)</div><div class="line">  logTrace(<span class="string">"waiting: "</span> + waitingStages)</div><div class="line">  logTrace(<span class="string">"failed: "</span> + failedStages)</div><div class="line">  <span class="keyword">val</span> waitingStagesCopy = waitingStages.toArray</div><div class="line">  waitingStages.clear()</div><div class="line">  <span class="keyword">for</span> (stage &lt;- waitingStagesCopy.sortBy(_.firstJobId)) &#123;</div><div class="line">    submitStage(stage)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>先告一段落..</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/17/elk简单搭建/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/17/elk简单搭建/" itemprop="url">
                  elk简单分布式搭建
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-17T17:16:52+08:00">
                2017-01-17
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="机器Hostname"><a href="#机器Hostname" class="headerlink" title="机器Hostname"></a>机器Hostname</h2><p>master, worker1, worker2</p>
<h1 id="安装logstash"><a href="#安装logstash" class="headerlink" title="安装logstash"></a>安装logstash</h1><h3 id="下载logstash"><a href="#下载logstash" class="headerlink" title="下载logstash"></a>下载logstash</h3><p>master,worker1,worker2 重复以下操作<br>官网下载地址：<a href="https://www.elastic.co/downloads/logstash" target="_blank" rel="external">https://www.elastic.co/downloads/logstash</a><br>我将下载后的压缩包解压在/opt/elasticsearch/logstash-5.1.1目录</p>
<h3 id="举一个简单的使用例子"><a href="#举一个简单的使用例子" class="headerlink" title="举一个简单的使用例子:"></a>举一个简单的使用例子:</h3><p>编辑测试数据<br>vim /opt/elasticsearch/logstash-5.1.1/test_data/2.log<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">efg</div></pre></td></tr></table></figure></p>
<h3 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><p>vim /opt/elasticsearch/logstash-5.1.1/config/test.conf<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">input &#123;</div><div class="line">    file &#123;</div><div class="line">        <span class="comment">#监听文件的路径</span></div><div class="line">        path =&gt; <span class="string">"/opt/elasticsearch/logstash-5.1.1/test_data/2.log"</span></div><div class="line">        <span class="comment">#监听文件的起始位置，默认是end</span></div><div class="line">        start_position =&gt; beginning</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line">filter &#123;</div><div class="line">&#125;</div><div class="line">output &#123;</div><div class="line">    <span class="comment">#输出到屏幕上</span></div><div class="line">    stdout &#123;&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="启动logstash"><a href="#启动logstash" class="headerlink" title="启动logstash"></a>启动logstash</h3><p>cd /opt/elasticsearch/logstash-5.1.1 &amp;&amp; ./bin/logstash -f ./config/test.conf<br>结果如图所示，PS.追加写文件，logstash也会跟着输出到屏幕上<br><img src="/images/201701/logstash_1.png"></p>
<h1 id="安装elasticsearch"><a href="#安装elasticsearch" class="headerlink" title="安装elasticsearch"></a>安装elasticsearch</h1><h3 id="下载elasticsearch"><a href="#下载elasticsearch" class="headerlink" title="下载elasticsearch"></a>下载elasticsearch</h3><p>官网下载地址：<a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="external">https://www.elastic.co/downloads/elasticsearch</a><br>将下载后的压缩包解压在/opt/elasticsearch/elasticsearch-5.1.1目录</p>
<h3 id="编辑配置文件-1"><a href="#编辑配置文件-1" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><p>cd /opt/elasticsearch/elasticsearch-5.1.1 &amp;&amp; vim ./config/elasticsearch.yml<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#master的config/elasticsearch.yml</span></div><div class="line">cluster.name: elasticsearch_cluster</div><div class="line">node.name: node-master</div><div class="line">path.data: /opt/elasticsearch/elasticsearch-5.1.1/data <span class="comment">#需要自己建目录</span></div><div class="line">path.logs: /opt/elasticsearch/elasticsearch-5.1.1/logs <span class="comment">#需要自己建目录</span></div><div class="line">network.host: master</div><div class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"master"</span>, <span class="string">"worker1"</span>, <span class="string">"worker2"</span>]</div><div class="line"></div><div class="line"><span class="comment">#worker1的config/elasticsearch.yml</span></div><div class="line">cluster.name: elasticsearch_cluster</div><div class="line">node.name: node-worker1</div><div class="line">path.data: /opt/elasticsearch/elasticsearch-5.1.1/data <span class="comment">#需要自己建目录</span></div><div class="line">path.logs: /opt/elasticsearch/elasticsearch-5.1.1/logs <span class="comment">#需要自己建目录</span></div><div class="line">network.host: worker1</div><div class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"master"</span>, <span class="string">"worker1"</span>, <span class="string">"worker2"</span>]</div><div class="line"></div><div class="line"><span class="comment">#worker2的config/elasticsearch.yml</span></div><div class="line">cluster.name: elasticsearch_cluster</div><div class="line">node.name: node-worker2</div><div class="line">path.data: /opt/elasticsearch/elasticsearch-5.1.1/data <span class="comment">#需要自己建目录</span></div><div class="line">path.logs: /opt/elasticsearch/elasticsearch-5.1.1/logs <span class="comment">#需要自己建目录</span></div><div class="line">network.host: worker2</div><div class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"master"</span>, <span class="string">"worker1"</span>, <span class="string">"worker2"</span>]</div></pre></td></tr></table></figure></p>
<h3 id="启动elasticsearch"><a href="#启动elasticsearch" class="headerlink" title="启动elasticsearch"></a>启动elasticsearch</h3><p>cd /opt/elasticsearch/elasticsearch-5.1.1 &amp;&amp; ./bin/elasticsearch<br>启动结果如果所示(先启动master，再worker1,worker2)<br><img src="/images/201701/elasticSearch_1.png"><br>可以在master的启动日志 看到加入节点worker1、worker2的消息<br>PS.不能用root用户启动，我是创建了elasticSearch用户</p>
<h1 id="安装kibana"><a href="#安装kibana" class="headerlink" title="安装kibana"></a>安装kibana</h1><h3 id="下载kibana"><a href="#下载kibana" class="headerlink" title="下载kibana"></a>下载kibana</h3><p>官网下载地址：<a href="https://www.elastic.co/downloads/kibana" target="_blank" rel="external">https://www.elastic.co/downloads/kibana</a><br>注.mac和linux版本不一样<br>将下载后的压缩包解压在/opt/elasticsearch/kibana-5.1.1-linux-x86_64目录</p>
<h3 id="编辑配置文件-2"><a href="#编辑配置文件-2" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><p>cd /opt/elasticsearch/kibana-5.1.1-linux-x86_64 &amp;&amp; vim ./config/kibana.yml<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#worker1的config/kibana.yml</span></div><div class="line">server.port: 5601</div><div class="line">server.host: <span class="string">"master"</span></div><div class="line">elasticsearch.url: <span class="string">"http://master:9200"</span> <span class="comment">#elasticsearch地址</span></div><div class="line"></div><div class="line"><span class="comment">#worker1的config/kibana.yml</span></div><div class="line">server.port: 5601</div><div class="line">server.host: <span class="string">"worker1"</span></div><div class="line">elasticsearch.url: <span class="string">"http://worker1:9200"</span> <span class="comment">#elasticsearch地址</span></div><div class="line"></div><div class="line"><span class="comment">#worker2的config/kibana.yml</span></div><div class="line">server.port: 5601</div><div class="line">server.host: <span class="string">"worker2"</span></div><div class="line">elasticsearch.url: <span class="string">"http://worker2:9200"</span> <span class="comment">#elasticsearch地址</span></div></pre></td></tr></table></figure></p>
<h3 id="启动kibana"><a href="#启动kibana" class="headerlink" title="启动kibana"></a>启动kibana</h3><p>cd /opt/elasticsearch/elasticsearch-5.1.1 &amp;&amp; ./bin/kibana</p>
<h3 id="登录kibana"><a href="#登录kibana" class="headerlink" title="登录kibana"></a>登录kibana</h3><p>访问master:5601<br>结果如图所示:<br><img src="/images/201701/kibana_1.png"></p>
<h1 id="elk配合使用-elasticsearch-logstash-kibana"><a href="#elk配合使用-elasticsearch-logstash-kibana" class="headerlink" title="elk配合使用(elasticsearch, logstash, kibana)"></a>elk配合使用(elasticsearch, logstash, kibana)</h1><h3 id="创建es的index"><a href="#创建es的index" class="headerlink" title="创建es的index"></a>创建es的index</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#es_test 是index</span></div><div class="line">curl -XPUT <span class="string">'http://master:9200/es_test/'</span> <span class="_">-d</span> <span class="string">'&#123;</span></div><div class="line">  "settings":&#123;</div><div class="line">      "index":&#123;</div><div class="line">          "number_of_shards":3,</div><div class="line">          "number_of_replicas":1</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">&#125;'</div></pre></td></tr></table></figure>
<p>之前我们已经启动了elasticsearch, logstash, kibana<br>接下来我们启动一个新的logstash，数据存入elasticsearch(三台机器一样操作)</p>
<h3 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#master </span></div><div class="line">cat /opt/elasticsearch/logstash-5.1.1/test_data/1.log</div><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line"><span class="comment">#worker1</span></div><div class="line">cat /opt/elasticsearch/logstash-5.1.1/test_data/1.log</div><div class="line">1</div><div class="line">5</div><div class="line">6</div><div class="line"><span class="comment">#worker2</span></div><div class="line">cat /opt/elasticsearch/logstash-5.1.1/test_data/1.log</div><div class="line">1</div><div class="line">7</div><div class="line">8</div></pre></td></tr></table></figure>
<h3 id="编辑配置文件-3"><a href="#编辑配置文件-3" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><p>vim /opt/elasticsearch/logstash-5.1.1/config/es_test.conf<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">input &#123;</div><div class="line">    file &#123;</div><div class="line">        path =&gt; <span class="string">"/opt/elasticsearch/logstash-5.1.1/test_data/1.log"</span></div><div class="line">        start_position =&gt; beginning</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line">output&#123;</div><div class="line">    <span class="comment">#将logstash的输出和elasticsearch对接</span></div><div class="line">    elasticsearch &#123;</div><div class="line">        hosts =&gt; <span class="string">"master:9200"</span></div><div class="line">        <span class="comment">#index类似mysql的database，之后我们会在kibana用到</span></div><div class="line">        index =&gt; <span class="string">"es_test"</span></div><div class="line">    &#125;</div><div class="line">    stdout&#123;codec=&gt;rubydebug&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>启动logstash<br>cd /opt/elasticsearch/logstash-5.1.1 &amp;&amp; ./bin/logstash -f ./config/es_test.conf</p>
<h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><p>再次登录master:5601<br>输入es_test，如图所示<br><img src="/images/201701/kibana_2.png"></p>
<p>搜索1，在3台机器上输出源都有，搜索结果如下<br><img src="/images/201701/kibana_3.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/11/13/azkaban安装/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/13/azkaban安装/" itemprop="url">
                  azkaban安装
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-11-13T01:24:40+08:00">
                2016-11-13
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="本机已经有的环境"><a href="#本机已经有的环境" class="headerlink" title="本机已经有的环境"></a>本机已经有的环境</h3><p>mysql: Ver 14.14 Distrib 5.6.33, for osx10.11 (x86_64) using  EditLine wrapper<br>hadoop: hadoop-2.6.0</p>
<h3 id="需要下载的azkaban软件"><a href="#需要下载的azkaban软件" class="headerlink" title="需要下载的azkaban软件"></a>需要下载的azkaban软件</h3><p>web管理:<a href="https://s3.amazonaws.com/azkaban2/azkaban2/2.5.0/azkaban-web-server-2.5.0.tar.gz" target="_blank" rel="external">https://s3.amazonaws.com/azkaban2/azkaban2/2.5.0/azkaban-web-server-2.5.0.tar.gz</a><br>executor:<a href="https://s3.amazonaws.com/azkaban2/azkaban2/2.5.0/azkaban-executor-server-2.5.0.tar.gz" target="_blank" rel="external">https://s3.amazonaws.com/azkaban2/azkaban2/2.5.0/azkaban-executor-server-2.5.0.tar.gz</a><br>sql_script:<a href="https://s3.amazonaws.com/azkaban2/azkaban2/2.5.0/azkaban-sql-script-2.5.0.tar.gz" target="_blank" rel="external">https://s3.amazonaws.com/azkaban2/azkaban2/2.5.0/azkaban-sql-script-2.5.0.tar.gz</a></p>
<h3 id="配置mysql"><a href="#配置mysql" class="headerlink" title="配置mysql"></a>配置mysql</h3><p>一、新增mysql的azkaban新用户和数据库<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">mysql -u root -p 密码</div><div class="line">mysql&gt; create database azkaban;</div><div class="line">mysql&gt; CREATE USER <span class="string">'azkaban'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'azkaban'</span>;</div><div class="line">mysql&gt; GRANT SELECT,INSERT,UPDATE,DELETE ON azkaban.* to <span class="string">'azkaban'</span>@<span class="string">'%'</span> WITH GRANT OPTION;</div><div class="line">mysql&gt; quit</div><div class="line"><span class="comment">#编辑my.cnf(mysql配置文件，默认在/etc/my.cnf)</span></div><div class="line"><span class="comment">#添加</span></div><div class="line">[mysqld]</div><div class="line">max_allowed_packet=1024M</div></pre></td></tr></table></figure></p>
<p>重启mysql</p>
<p>二、导入下载的sql脚本<br>解压sql_script: tar -xzvf azkaban-sql-script-2.5.0.tar.gz<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">mysql -u root -p 密码</div><div class="line"><span class="comment">#切换数据库</span></div><div class="line">mysql&gt; use azkaban;</div><div class="line">mysql&gt; <span class="built_in">source</span> (解压sql_script的路径)/create-all-sql-2.5.0.sql</div><div class="line"><span class="comment">#对表赋权</span></div><div class="line">mysql&gt; grant all privileges on azkaban.* to <span class="string">'azkaban'</span>@<span class="string">'localhost'</span> identified by <span class="string">'azkaban'</span>;</div><div class="line">mysql&gt; flush privileges;</div></pre></td></tr></table></figure></p>
<h3 id="配置web和executor"><a href="#配置web和executor" class="headerlink" title="配置web和executor"></a>配置web和executor</h3><p>一、检查是否有mysql驱动<br>解压azkaban-web-server-2.5.0.tar.gz和azkaban-executor-server-2.5.0.tar.gz<br>检查下载包web和executor的lib文件下是否有mysql驱动(mysql-connector-java-5.1.28.jar)，若不存在，则拷贝一个</p>
<p>二、使用keytool 生成SSL证书<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /var/root</div><div class="line"><span class="comment">#生成一个含有一个私钥的keystore文件</span></div><div class="line">keytool -genkey -keystore keystore -alias jetty-azkaban -keyalg RSA</div><div class="line"><span class="comment">#PS.我的密码一直是keystore</span></div><div class="line">cp keystore xx(解压目录)/azkaban-web-2.5.0/web/</div></pre></td></tr></table></figure></p>
<p>三、web 修改配置conf中azkaban.properties<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#需要修改的地方写出来</span></div><div class="line"></div><div class="line"><span class="comment">#1、修改时区</span></div><div class="line">default.timezone.id=Asia/Shanghai</div><div class="line"></div><div class="line"><span class="comment">#2、修改ssl信息</span></div><div class="line">jetty.ssl.host=localhost  <span class="comment">#默认是localhost，如果在线上环境，输入服务器ip</span></div><div class="line">jetty.keystore=web/keystore</div><div class="line">jetty.password=keystore</div><div class="line">jetty.keypassword=keystore</div><div class="line">jetty.truststore=web/keystore</div><div class="line">jetty.trustpassword=keystore</div></pre></td></tr></table></figure></p>
<p>四、启动web ui<br>cd xxx/azkaban-web-2.5.0 &amp;&amp; ./bin/azkaban-web-start.sh<br>登陆本地<a href="https://localhost:8443" target="_blank" rel="external">https://localhost:8443</a> 可查看<br>PS.1、默认的帐号和密码是azkaban, 2、一定要输入https</p>
<p>五、executor 修改配置conf中azkaban.properties<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#修改</span></div><div class="line">default.timezone.id=Asia/Shanghai</div><div class="line">mysql.database=azkaban  <span class="comment">#原来是azkaban2</span></div></pre></td></tr></table></figure></p>
<p>六、启动executor<br>cd xxx/azkaban-executor-2.5.0 &amp;&amp; ./bin/azkaban-executor-start.sh</p>
<h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p><a href="http://www.cnblogs.com/tannerBG/archive/2014/07/10/3835952.html" target="_blank" rel="external">http://www.cnblogs.com/tannerBG/archive/2014/07/10/3835952.html</a><br><a href="http://www.jianshu.com/p/484564beda1d" target="_blank" rel="external">http://www.jianshu.com/p/484564beda1d</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/10/10/build-hive/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/10/build-hive/" itemprop="url">
                  搭建hive
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-10-10T21:06:58+08:00">
                2016-10-10
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>目前有三台物理机: master worker1 worker2<br>我把hive服务端安装在worker1中<br>所以在worker1中配置mysql</p>
<h2 id="安装mysql启动服务"><a href="#安装mysql启动服务" class="headerlink" title="安装mysql启动服务"></a>安装mysql启动服务</h2><h3 id="mac安装mysql"><a href="#mac安装mysql" class="headerlink" title="mac安装mysql"></a>mac安装mysql</h3><p>1、官网下载<a href="http://dev.mysql.com/downloads/mysql/" target="_blank" rel="external">http://dev.mysql.com/downloads/mysql/</a><br><img src="/images/201610/build_hive/main_download.jpeg" width="400" height="600"><br>2、官网默认的下载版本是5.7.15<br><img src="/images/201610/build_hive/default_download_version.jpeg" width="400" height="600"><br>但是我下载后不会安装，所以选择下载以前的版本5.6.33<br><img src="/images/201610/build_hive/download_mysql.jpeg" width="400" height="600"><br>选择下载压缩包</p>
<p>2、下载后安装配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#先cd到下载mysql的目录，mv到/usr/local下并且解压，改名</span></div><div class="line">sudo mv mysql-5.6.33-osx10.11-x86_64.tar.gz /usr/<span class="built_in">local</span>/</div><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></div><div class="line">sudo tar -xzvf mysql-5.6.33-osx10.11-x86_64.tar.gz</div><div class="line">sudo mv mysql-5.6.33-osx10.11-x86_64 mysql</div><div class="line"><span class="comment">#各种修改权限</span></div><div class="line">sudo chown -R mysql:mysql mysql</div><div class="line"><span class="built_in">cd</span> mysql</div><div class="line">sudo scripts/mysql_install_db --user=mysql</div><div class="line">sudo chown -R root .</div><div class="line">sudo chown -R mysql data</div><div class="line"><span class="comment">#配置mysql(可以设置登陆密码，默认为空)</span></div><div class="line"><span class="built_in">cd</span> /bin</div><div class="line">sudo ./mysql_secure_installation</div><div class="line"><span class="comment">#启动mysql</span></div><div class="line">sudo ./mysqld_safe </div><div class="line"><span class="comment">#登录mysql</span></div><div class="line">sudo ./mysql -u root -p </div><div class="line"><span class="comment">#停止mysql:</span></div><div class="line">sudo ./mysqld_safe stop</div></pre></td></tr></table></figure></p>
<h3 id="centos安装mysql服务"><a href="#centos安装mysql服务" class="headerlink" title="centos安装mysql服务"></a>centos安装mysql服务</h3><p>1、下载mysql<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install mysql-server</div></pre></td></tr></table></figure></p>
<p>安装失败，因为CentOS7版本将MySQL数据库软件从默认的程序列表中移除，用mariadb代替了<br>所以去官网下载安装mysql-server<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm</div><div class="line">rpm -ivh mysql-community-release-el7-5.noarch.rpm</div><div class="line">yum install mysql-community-server</div></pre></td></tr></table></figure></p>
<p>2、配置mysql<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#重启mysql服务</span></div><div class="line">service mysqld restart</div><div class="line"><span class="comment">#登入mysql</span></div><div class="line">mysql -u root</div><div class="line"><span class="comment">#设置密码</span></div><div class="line">mysql&gt; <span class="built_in">set</span> password <span class="keyword">for</span> <span class="string">'root'</span>@<span class="string">'localhost'</span>=password(xxx)</div></pre></td></tr></table></figure></p>
<h2 id="创建Hive用户"><a href="#创建Hive用户" class="headerlink" title="创建Hive用户"></a>创建Hive用户</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#在root用户下操作</span></div><div class="line">mysql&gt;CREATE USER <span class="string">'hive'</span> IDENTIFIED BY <span class="string">'hive'</span>;</div><div class="line">mysql&gt;GRANT ALL PRIVILEGES ON *.* TO <span class="string">'hive'</span>@<span class="string">'worker1'</span> WITH GRANT OPTION;</div><div class="line">mysql&gt;flush privileges;</div></pre></td></tr></table></figure>
<h2 id="Hive用户登录-创建hive数据库"><a href="#Hive用户登录-创建hive数据库" class="headerlink" title="Hive用户登录 创建hive数据库"></a>Hive用户登录 创建hive数据库</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@worker1 ~]mysql -h worker1 -uhive</div><div class="line">mysql&gt;<span class="built_in">set</span> password = password(<span class="string">'hive2016'</span>);</div><div class="line">mysql&gt;create database hive;</div></pre></td></tr></table></figure>
<h2 id="下载Hive"><a href="#下载Hive" class="headerlink" title="下载Hive"></a>下载Hive</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#下载hive</span></div><div class="line">wget http://mirrors.cnnic.cn/apache/hive/hive-1.2.1/apache-hive-1.2.1-bin.tar.gz</div><div class="line">tar -xzvf apache-hive-1.2.1-bin.tar.gz </div><div class="line"><span class="built_in">cd</span> apache-hive-1.2.1-bin</div><div class="line"><span class="built_in">pwd</span></div><div class="line"><span class="comment">#pwd路径: /home/hadoop/apache-hive-1.2.1-bin</span></div><div class="line"></div><div class="line"><span class="comment">#配置环境变量</span></div><div class="line">[root@worker1 hadoop]<span class="comment"># vi /etc/profile</span></div><div class="line">HIVE_HOME=/home/hadoop/apache-hive-1.2.1-bin</div><div class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</div><div class="line">[root@worker1 hadoop]<span class="comment"># source /etc/profile</span></div></pre></td></tr></table></figure>
<h2 id="配置Hive"><a href="#配置Hive" class="headerlink" title="配置Hive"></a>配置Hive</h2><p>进入到hive的配置文件目录下，找到hive-default.xml.template，cp份为hive-default.xml<br>另创建hive-site.xml并添加参数<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">[root@worker1 hadoop]<span class="comment"># cd /home/hadoop/apache-hive-1.2.1-bin/conf &amp;&amp; vi hive-site.xml</span></div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</div><div class="line">        &lt;value&gt;jdbc:mysql://worker1:3306/hive?createDatabaseIfNotExist=<span class="literal">true</span>&lt;/value&gt;</div><div class="line">        &lt;description&gt;JDBC connect string <span class="keyword">for</span> a JDBC metastore&lt;/description&gt;    </div><div class="line">    &lt;/property&gt;   </div><div class="line">    &lt;property&gt; </div><div class="line">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; </div><div class="line">        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; </div><div class="line">        &lt;description&gt;Driver class name <span class="keyword">for</span> a JDBC metastore&lt;/description&gt;     </div><div class="line">    &lt;/property&gt;               </div><div class="line"> </div><div class="line">    &lt;property&gt; </div><div class="line">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</div><div class="line">        &lt;value&gt;hive&lt;value&gt;</div><div class="line">        &lt;description&gt;username to use against metastore database&lt;/description&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;  </div><div class="line">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</div><div class="line">        &lt;value&gt;hive2016&lt;/value&gt;</div><div class="line">        &lt;description&gt;password to use against metastore database&lt;/description&gt;  </div><div class="line">    &lt;/property&gt;          </div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure></p>
<h3 id="JDBC下载"><a href="#JDBC下载" class="headerlink" title="JDBC下载"></a>JDBC下载</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@worker1 hadoop]<span class="comment"># wget http://cdn.mysql.com/Downloads/Connector-J/mysql-connector-java-5.1.36.tar.gz</span></div><div class="line">[root@worker1 hadoop]<span class="comment"># cp mysql-connector-java-5.1.33-bin.jar $HIVE_HOME/lib/</span></div></pre></td></tr></table></figure>
<h3 id="hive客户端配置"><a href="#hive客户端配置" class="headerlink" title="hive客户端配置"></a>hive客户端配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@worker1 hadoop]<span class="comment"># scp -r apache-hive-1.2.1-bin/ master:/home/hadoop</span></div><div class="line">[root@worker1 hadoop]<span class="comment"># vi hive-site.xml</span></div><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;  </div><div class="line">        &lt;name&gt;hive.metastore.uris&lt;/name&gt;  </div><div class="line">    &lt;value&gt;thrift://worker1:9083&lt;/value&gt;  </div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h3 id="hive启动"><a href="#hive启动" class="headerlink" title="hive启动"></a>hive启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@worker1 hadoop]<span class="comment"># hive --service metastore &amp;</span></div><div class="line">[root@worker1 hadoop]<span class="comment"># jps</span></div><div class="line">9999 RunJar  <span class="comment">#多了一个进程</span></div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/10/03/简易搭建kafka集群/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/03/简易搭建kafka集群/" itemprop="url">
                  搭建简易kafka集群
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-10-03T11:47:06+08:00">
                2016-10-03
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="选择kafka版本"><a href="#选择kafka版本" class="headerlink" title="选择kafka版本"></a>选择kafka版本</h3><p>首先看你要用来做什么，比如我要选择配合sparkstreaming来使用(已经配置好了spark1.6.1的环境)<br>1、进入spark官网的文档页<a href="http://spark.apache.org/documentation.html" target="_blank" rel="external">http://spark.apache.org/documentation.html</a><br>2、点击Spark 1.6.1<br>3、顶部有Programming Guides，点击SparkStreaming<br><img src="/images/201610/build_kafka/sparkstreaming_guide.jpeg" width="400" height="600"><br>4、command+F 或者 ctrl+F 搜索kafka，能找到kafka版本<br><img src="/images/201610/build_kafka/kafka_version.jpeg" width="400" height="600"></p>
<h3 id="kafka下载"><a href="#kafka下载" class="headerlink" title="kafka下载"></a>kafka下载</h3><p>进入官网下载页面<a href="http://kafka.apache.org/downloads.html" target="_blank" rel="external">http://kafka.apache.org/downloads.html</a><br><img src="/images/201610/build_kafka/download_kafka.jpeg"><br>binary是编译好的可以直接使用，source是还没编译过的源代码(编译挺麻烦的，直接使用编译好的)<br>Binary downloads提供不同scala版本的kafka下载，所以我们还得找到scala版本<br>回到我们已经有的环境，查看spark1.6.1需要的scala版本<br><img src="/images/201610/build_kafka/spark_scala_version.jpeg" width="400" height="600"><br>得知scala版本是2.10<br>开始下载kafka_2.10-0.8.2.1.tgz</p>
<h3 id="zookeeper下载"><a href="#zookeeper下载" class="headerlink" title="zookeeper下载"></a>zookeeper下载</h3><p>为什么要下载zookeeper，因为kafka使用zookeeper来管理，存储一些meta信息。<br>(虽然kafka文件包里带有zookeeper的服务，但是我没有试过)<br>1、选择zookeeper版本，通过官网的Kafka 0.8.2 Documentation<br><a href="http://kafka.apache.org/082/documentation.html#zkversion" target="_blank" rel="external">http://kafka.apache.org/082/documentation.html#zkversion</a><br><img src="/images/201610/build_kafka/zookeeper_version.jpeg" width="400" height="600"><br>2、开始下载zookeeper 3.3.x版本<br><a href="http://apache.fayea.com/zookeeper/" target="_blank" rel="external">http://apache.fayea.com/zookeeper/</a><br><img src="/images/201610/build_kafka/download_zookeeper.jpeg" width="400" height="600"><br>3.3.x版本的只有3.3.6<br>PS.我的下载地址都在/opt下</p>
<h3 id="zookeeper配置"><a href="#zookeeper配置" class="headerlink" title="zookeeper配置"></a>zookeeper配置</h3><p>1、配置zookeeper<br>cd /opt/zookeeper-3.3.6/conf<br>cp zoo_sample.cfg zoo.cfg<br>打开zoo.cfg 默认的配置如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># The number of milliseconds of each tick</span></div><div class="line">tickTime=2000 <span class="comment">#心跳时间，为了确保client-server连接存在的，以毫秒为单位，最小超时时间为两个心跳时间。</span></div><div class="line"><span class="comment"># The number of ticks that the initial</span></div><div class="line"><span class="comment"># synchronization phase can take</span></div><div class="line">initLimit=10 <span class="comment">#多少个tickTime内，允许其他server连接并初始化数据，如果zooKeeper管理的数据较大，则应相应增大这个值。</span></div><div class="line"><span class="comment"># The number of ticks that can pass between</span></div><div class="line"><span class="comment"># sending a request and getting an acknowledgement</span></div><div class="line">syncLimit=5 <span class="comment">#多少个tickTime内，允许follower同步，如果follower落后太多，则会被丢弃。</span></div><div class="line"><span class="comment"># the directory where the snapshot is stored.</span></div><div class="line">dataDir=/tmp/zookeeper <span class="comment">#用于存放内存数据库快照的文件夹，同时用于集群的myid文件也存在这个文件夹里</span></div><div class="line"><span class="comment"># the port at which the clients will connect</span></div><div class="line">clientPort=2181 <span class="comment">#客户端监听端口</span></div></pre></td></tr></table></figure></p>
<p>2、添加如下配置(添加到zoo.cfg文件末尾即可)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">server.1=master:2888:3888</div><div class="line">server.2=worker1:2888:3888</div><div class="line">server.3=worker2:2888:3888</div><div class="line"><span class="comment">#server.x=[hostname]:nnnnn[:nnnnn]</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment">#　　配置集群里面的主机信息，其中：</span></div><div class="line"><span class="comment">#　　①server.x：server.x的x要写在myid文件中，决定当前机器的id，</span></div><div class="line"><span class="comment">#　　②第一个port用于连接leader，</span></div><div class="line"><span class="comment">#　　③第二个用于leader选举。</span></div><div class="line"><span class="comment">#　　④如果electionAlg为0，则不需要第二个port。</span></div><div class="line"><span class="comment">#　　⑤hostname也可以填ip。</span></div><div class="line"><span class="comment">#PS.配置文件中的master,worker1,worker2是你的机器地址</span></div><div class="line"><span class="comment">#比如我的/etc/hosts里是</span></div><div class="line"><span class="comment">#192.168.1.104 master</span></div><div class="line"><span class="comment">#192.168.1.108 worker1</span></div><div class="line"><span class="comment">#192.168.1.109 worker2</span></div></pre></td></tr></table></figure></p>
<p>然后在dataDir目录下即/tmp/zookeeper下<br>echo 1 &gt; myid</p>
<p>3、启动zookeeper<br>cd /opt/zookeeper-3.3.6/bin<br>./zkServer.sh start zoo.cfg<br>判断是否启动成功<br><img src="/images/201610/build_kafka/sucess_zoo.jpeg" width="300" height="500"></p>
<p>4、集群化<br>scp -r /opt/zookeeper-3.3.6 worker1:/opt<br>scp -r /opt/zookeeper-3.3.6 worker2:/opt<br>还需要把不同机器的myid改成相应的数值，比如worker1下的/tmp/zookeeper/myid 改成2<br>在其他机器也同样启动zookeeper</p>
<h3 id="kafka配置"><a href="#kafka配置" class="headerlink" title="kafka配置"></a>kafka配置</h3><p>kafka的简单介绍<a href="http://wangzzu.github.io/2015/11/14/The-Introduce-of-Kafka/" target="_blank" rel="external">http://wangzzu.github.io/2015/11/14/The-Introduce-of-Kafka/</a><br>1、配置kafka<br>cd /opt/kafka_2.10-0.8.2.1/config<br>打开server.properties<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#需要修改的有</span></div><div class="line">broker.id=1 <span class="comment">#broker的标识，id为正数，kafka集群内不能重复，推荐用ip地址设置</span></div><div class="line">host.name=master <span class="comment">#指定broker绑定的网络接口地址</span></div><div class="line">advertised.host.name=master</div><div class="line">zookeeper.connect=master:2181,worker1:2181,worker2:2181 <span class="comment">#连接的zookeeper对应的IP和端口</span></div><div class="line">log.dirs=/tmp/kafka-logs <span class="comment">#日志文件保存的目录(可以不用修改) PS.Mac电脑不建议放在tmp目录下,同样zookeeper的dataDir也不建议</span></div></pre></td></tr></table></figure></p>
<p>2、启动kafka<br>cd /opt/kafka_2.10-0.8.2.1/bin<br>nohup ./kafka-server-start.sh ../config/server.properties &amp;<br>输入jps后 出现kafka，说明在运行中</p>
<p>3、集群化<br>scp 到其他机器，并修改对应config/server.properties中的host.name和advertised.host.name</p>
<p>4、测试<br>a.创建topic<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./kafka-topics.sh --create --zookeeper master:2181 --replication-factor 1 --partitions 1 --topic <span class="built_in">test</span>1</div></pre></td></tr></table></figure></p>
<img src="/images/201610/build_kafka/kafka_create_topic.jpeg" width="500" height="800">
<p>b.生产和消费<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">./kafka-console-producer.sh --broker-list master:9092 --topic <span class="built_in">test</span>1</div><div class="line">./kafka-console-consumer.sh --zookeeper master:2181 --topic <span class="built_in">test</span>1</div></pre></td></tr></table></figure></p>
<img src="/images/201610/build_kafka/kafka_pro_con.jpeg" width="600" height="800">
<h3 id="kafka监控"><a href="#kafka监控" class="headerlink" title="kafka监控"></a>kafka监控</h3><p>参考<a href="http://top.jobbole.com/31084/" target="_blank" rel="external">http://top.jobbole.com/31084/</a><br><a href="https://www.iteblog.com/archives/1083" target="_blank" rel="external">https://www.iteblog.com/archives/1083</a></p>
<h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p><a href="http://www.cnblogs.com/sunddenly/articles/4071730.html" target="_blank" rel="external">http://www.cnblogs.com/sunddenly/articles/4071730.html</a><br><a href="http://yanliu.org/2015/08/31/kafka%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/" target="_blank" rel="external">http://yanliu.org/2015/08/31/kafka%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/09/25/spark源码环境搭建/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/25/spark源码环境搭建/" itemprop="url">
                  spark源码环境搭建
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-09-25T12:26:47+08:00">
                2016-09-25
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>已有的环境:<br>IntelliJ IDEA</p>
<p>一、去官网下载spark源码<br><a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">http://spark.apache.org/downloads.html</a><br><img src="/images/201609/download_sparkSourceCode.png"><br>注意package type选择Source Code</p>
<p>二、解压spark-1.6.1.tgz到目录xxx/spark-1.6.1</p>
<p>三、打开IntelliJ IDEA import project<br><img src="/images/201609/import_project.png" width="500" height="500"><br>找到xxx/spark-1.6.1/pom.xml<br><img src="/images/201609/get_pom.png" width="500" height="600"></p>
<p>四、接下来一直点击next就行<br>最后出现这个说明快成功了<br><img src="/images/201609/updating_indices.png"><br>PS.如果出现Unable to save settings: Failed to save settings. Please restart IntelliJ<br>那么可能是导入的路径没有权限写入</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="xiwu1212@163.com" />
          <p class="site-author-name" itemprop="name">xiwu1212@163.com</p>
          <p class="site-description motion-element" itemprop="description">学无止境</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiwu1212@163.com</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  




  
  

  

  

  

  


</body>
</html>
