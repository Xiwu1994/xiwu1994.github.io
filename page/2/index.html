<!doctype html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="Refrain">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Refrain">
<meta property="og:description" content="学无止境">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Refrain">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>Refrain</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  















  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Refrain</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/01/SparkStreaming的window操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/01/SparkStreaming的window操作/" itemprop="url">SparkStreaming的window操作</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-01T21:38:12+08:00">
                2017-03-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="简单介绍window操作"><a href="#简单介绍window操作" class="headerlink" title="简单介绍window操作"></a>简单介绍window操作</h3><img src="/images/201703/SparkStreaming_window_1.png">
<p><strong>原始的Dstream</strong>：一个参数，表示多长时间划分一个RDD<br><strong>窗口操作</strong>：两个参数，表示</p>
<ul>
<li>window length（窗口长度）：窗口的持续时间（上图为3个时间单位）</li>
<li>sliding interval （滑动间隔）- 窗口操作的时间间隔（上图为2个时间单位）</li>
</ul>
<p><strong>对上图简单理解：每隔2个时间单位，对之前的3个时间单位操作</strong></p>
<h3 id="API说明"><a href="#API说明" class="headerlink" title="API说明"></a>API说明</h3><p>举例：<br>SparkStreaming的输入：每秒从[aa,bb,cc,dd,ee,ff,gg,hh]中随机选一个作为输入<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc,<span class="type">Seconds</span>(<span class="number">1</span>))</div><div class="line"><span class="keyword">val</span> socketStreaming = ssc.socketTextStream(<span class="string">"master"</span>,<span class="number">9999</span>)</div></pre></td></tr></table></figure></p>
<h4 id="window"><a href="#window" class="headerlink" title="window"></a>window</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> data = socketStreaming.window(<span class="type">Seconds</span>(<span class="number">3</span>), <span class="type">Seconds</span>(<span class="number">2</span>))</div><div class="line">data.print()</div></pre></td></tr></table></figure>
<p>结果如图：<br><img src="/images/201703/SparkStreaming_window_2.png"></p>
<h4 id="countByValueAndWindow"><a href="#countByValueAndWindow" class="headerlink" title="countByValueAndWindow"></a>countByValueAndWindow</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> data = socketStreaming.countByValueAndWindow(<span class="type">Seconds</span>(<span class="number">3</span>),<span class="type">Seconds</span>(<span class="number">2</span>))</div><div class="line">data.print()</div></pre></td></tr></table></figure>
<img src="/images/201703/SparkStreaming_window_3.png">
<h4 id="reduceByKeyAndWindow"><a href="#reduceByKeyAndWindow" class="headerlink" title="reduceByKeyAndWindow"></a>reduceByKeyAndWindow</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> data = socketStreaming.map(x=&gt;(x,<span class="number">1</span>)).</div><div class="line">    reduceByKeyAndWindow(</div><div class="line">    _+_, <span class="comment">// 加上新进入窗口的新批次中的元素 </span></div><div class="line">    _-_, <span class="comment">// 减去离开窗口的的老批次的元素</span></div><div class="line">    <span class="type">Seconds</span>(<span class="number">3</span>),<span class="type">Seconds</span>(<span class="number">2</span>))</div><div class="line">data.print()</div></pre></td></tr></table></figure>
<img src="/images/201703/SparkStreaming_window_4.png">
<ul>
<li>reduceByKeyAndWindow(func,windowLength, slideInterval, [numTasks])</li>
<li>reduceByKeyAndWindow(func, invFunc,windowLength, slideInterval, [numTasks])</li>
<li>使用逆函数invFunc可以提高效率</li>
<li><img src="/images/201703/SparkStreaming_reduceByKeyAndWindow_1.png"></li>
<li><img src="/images/201703/SparkStreaming_reduceByKeyAndWindow_2.png">
</li>
</ul>
<h4 id="reduceByWindow和countByWindow"><a href="#reduceByWindow和countByWindow" class="headerlink" title="reduceByWindow和countByWindow"></a>reduceByWindow和countByWindow</h4><p>暂时没看明白,mark</p>
<p>PS.在今天面试之前，面试官竟然看了我的博客，还是很开心的～</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/28/MapReduce调优简单总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/28/MapReduce调优简单总结/" itemprop="url">MapReduce调优简单总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-28T13:57:14+08:00">
                2017-02-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <img src="/images/201702/mr_optimize_1.png">
<table>
<thead>
<tr>
<th>选项</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>mapreduce.map.memory.mb</td>
<td>int</td>
<td>1024</td>
<td>map使用的内存</td>
</tr>
<tr>
<td>mapred.min.split.size</td>
<td>int</td>
<td>1</td>
<td>Input Split的最小值</td>
</tr>
<tr>
<td>mapred.map.tasks</td>
<td>int</td>
<td>1</td>
<td>Map Task的数量</td>
</tr>
<tr>
<td>io.sort.mb</td>
<td>int</td>
<td>100</td>
<td>map缓冲区大小</td>
</tr>
<tr>
<td>io.sort.factor</td>
<td>int</td>
<td>10</td>
<td>并行处理spill的个数</td>
</tr>
<tr>
<td>min.num.spill.for.combine</td>
<td>int</td>
<td>3</td>
<td>最少有3个Spill文件需要Merge时，执行combine操作</td>
</tr>
<tr>
<td>mapred.compress.map.output</td>
<td>boolean</td>
<td>false</td>
<td>map中间数据是否采用压缩</td>
</tr>
<tr>
<td>mapred.map.output.compression.codec</td>
<td>String</td>
<td>.</td>
<td>压缩算法</td>
</tr>
</tbody>
</table>
<img src="/images/201702/mr_optimize_2.png">
<table>
<thead>
<tr>
<th>选项</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>mapreduce.reduce.memory.mb</td>
<td>int</td>
<td>1024</td>
<td>reduce使用的内存</td>
</tr>
<tr>
<td>mapred.reduce.parallel.copies</td>
<td>int</td>
<td>5</td>
<td>每个reduce去map中拿数据的并行数</td>
</tr>
<tr>
<td>mapred.reduce.copy.backoff</td>
<td>int</td>
<td>300</td>
<td>获取map数据最大超时时间</td>
</tr>
<tr>
<td>mapred.job.shuffle.input.buffer.percent</td>
<td>float</td>
<td>0.7</td>
<td>buffer大小占reduce可用内存的比例</td>
</tr>
<tr>
<td>mapred.child.java.opts</td>
<td>String</td>
<td>.</td>
<td>-Xmx1024m设置reduce可用内存为1g</td>
</tr>
<tr>
<td>mapred.job.shuffle.merge.percent</td>
<td>float</td>
<td>0.66</td>
<td>buffer中的数据达到多少比例开始写入磁盘</td>
</tr>
<tr>
<td>mapred.job.reduce.input.buffer.percent</td>
<td>float</td>
<td>0.0</td>
<td>指定多少比例的内存用来存放buffer中的数据</td>
</tr>
</tbody>
</table>
<p>一个通用的原则是给shuffle过程分配尽可能大的内存。<br>运行map和reduce任务的JVM，内存通过mapred.child.java.opts属性来设置，尽可能设大内存。<br>容器的内存大小通过mapreduce.map.memory.mb和mapreduce.reduce.memory.mb来设置，默认都是1024M。<br>Hadoop默认使用4KB作为缓冲，这个算是很小的，可以通过io.file.buffer.size来调高缓冲池大小。</p>
<p>Map Task和Reduce Task调优的一个原则就是<br>减少数据的传输量 =&gt; 预聚合combine<br>尽量使用内存 =&gt; 提高内存使用(1、map环形缓冲区 2、reduce的Merge阶段)<br>减少磁盘IO的次数 =&gt; 增加Spill大小<br>增大任务并行数 =&gt; Reduce数量，Map数量</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/27/hive优化简单总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/27/hive优化简单总结/" itemprop="url">hive优化简单总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-27T22:31:08+08:00">
                2017-02-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="合理控制Map和Reduce数"><a href="#合理控制Map和Reduce数" class="headerlink" title="合理控制Map和Reduce数"></a>合理控制Map和Reduce数</h3><h4 id="map数"><a href="#map数" class="headerlink" title="map数"></a>map数</h4><ul>
<li>Map数过大<br>1、Map阶段输出文件太小，产生大量小文件，reduce阶段在拉取数据的时候产生很大开销。<br>2、初始化和创建map的开销很大。</li>
<li>Map数过小<br>1、文件处理或查询并发度小，Job执行空间过长。<br>2、大量作业时，容易堵塞集群。</li>
</ul>
<p><strong>Map数过大过小解决办法</strong><br>一、过大，<strong>通过合并小文件</strong><br>有三个阶段可以合并文件<br>Map输入，Reduce输出，Map-only任务结束时<br>1、Map输入</p>
<ul>
<li>set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</li>
<li>set mapred.max.split.size=100000000 表示合并后文件大小大于100M，可以合并下一个</li>
<li>set mapred.min.split.size.per.node=100000000 表示文件小于100M，需要被合并</li>
</ul>
<p>2、 Reduce输出:<br>set hive.merge.mapredfiles = true(默认false)<br>3、 Map-only任务结束时:<br>set hive.merge.mapfiles=true(默认true)</p>
<p>二、 过小，<strong>通过设置mapred.map.tasks</strong><br><a href="https://xiwu1994.github.io/2017/02/14/Hadoop%E8%AE%A1%E7%AE%97Map%E6%95%B0/" target="_blank" rel="external">Map数量是如何计算的参考文档</a></p>
<h4 id="Reduce数"><a href="#Reduce数" class="headerlink" title="Reduce数"></a>Reduce数</h4><ul>
<li>Reduce数过大<br>1、最终生成了很多个小文件，如果作为下一个Job输入，会出现上面说的Map数过多的问题。<br>2、启动和初始化reduce也会消耗大量的时间和资源</li>
<li>Reduce数过小<br>1、每个文件很大，执行耗时。<br>2、可能出现数据领斜。</li>
</ul>
<p><strong>默认计算方法</strong><br>Hive分配reduce数基于以下参数：<br>参数1：hive.exec.reducers.bytes.per.reducer(默认是1G)<br>参数2：hive.exec.reducers.max(最大reduce数，默认为999)<br>计算Reduce数的公式：<br>N=min(参数2，总输入数据量/参数1)<br>PS. 注意总输入数据量是Map的输入量，而不是Map的输出量。所以这点不是很好，因此要预估Map的输出量来手动设置mapred.reduce.tasks<br><strong>即默认一个reduce处理1G数据量</strong></p>
<p><strong>解决办法:通过设置Reduce数</strong><br>参数mapred.reduce.tasks 默认是1<br>set mapred.reduce.tasks=XX</p>
<h3 id="数据倾斜-Join-Or-GroupBy"><a href="#数据倾斜-Join-Or-GroupBy" class="headerlink" title="数据倾斜(Join Or GroupBy)"></a>数据倾斜(Join Or GroupBy)</h3><h4 id="参数调节"><a href="#参数调节" class="headerlink" title="参数调节"></a>参数调节</h4><ul>
<li><strong>增加Shuffle并行度(Reduce个数)</strong><br>set hive.exec.reducers.max=200;<br>set mapred.reduce.tasks= 200; –增大Reduce个数</li>
<li><strong>Group By</strong><br>set hive.groupby.mapaggr.checkinterval=100000; –这个是group的键对应的记录条数超过这个值则会进行分拆,值根据具体数据量设置<br>set hive.groupby.skewindata=true; –如果是 <strong>Group By</strong> 过程出现倾斜 应该设置为true</li>
<li><strong>Join</strong><br>set hive.skewjoin.key=100000; –这个是join的键对应的记录条数超过这个值则会进行分拆,值根据具体数据量设置<br>set hive.optimize.skewjoin=true; –如果是 <strong>Join</strong> 过程出现倾斜 应该设置为true</li>
</ul>
<h4 id="SQL语句调节"><a href="#SQL语句调节" class="headerlink" title="SQL语句调节"></a>SQL语句调节</h4><ul>
<li>Join操作<br>1、<strong>若其中有一个表很小使用map join /*+ MAPJOIN(table) */</strong>，否则使用普通的reduce join<br>2、<strong>使用普通reduce join时 将条目少的表/子查询放在 Join 操作符的 左边</strong>（位于 Join 操作符左边的表的内容会被加载进内存）</li>
</ul>
<p>PS. 熟练运用 <strong>union all和 创建临时表insert overwrite table</strong> 优化SQL语句</p>
<h4 id="常见数据倾斜场景"><a href="#常见数据倾斜场景" class="headerlink" title="常见数据倾斜场景"></a>常见数据倾斜场景</h4><ul>
<li><p>空值产生的数据倾斜<br>解决办法：赋予空值一个随机值</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> * <span class="keyword">from</span> A a</div><div class="line"><span class="keyword">left</span> <span class="keyword">join</span> B b</div><div class="line"><span class="keyword">on</span> <span class="keyword">case</span> <span class="keyword">when</span> a.id <span class="keyword">is</span> <span class="literal">null</span> <span class="keyword">then</span> <span class="keyword">concat</span>(<span class="string">'hive'</span>, <span class="keyword">rand</span>()) <span class="keyword">else</span> a.id <span class="keyword">end</span> = b.id</div></pre></td></tr></table></figure>
</li>
<li><p>不同数据类型关联产生数据倾斜<br>解决方法：把数字类型转换成字符串类型</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> * <span class="keyword">from</span> A a</div><div class="line"><span class="keyword">left</span> <span class="keyword">join</span> B b</div><div class="line"><span class="keyword">on</span> a.id = <span class="keyword">cast</span>(b.id <span class="keyword">as</span> <span class="keyword">string</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>小表不小不大，用map join不好解决<br>抽出业务中的小数据源，作为map join中的小表。 进行多次的map join<br>例如业务：A表有大表，但是id的去重后的量少。 B表是小表，但是也比较大</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> <span class="comment">/*+mapjoin(c)*/</span> c.*</div><div class="line"><span class="keyword">from</span></div><div class="line">(</div><div class="line">  <span class="keyword">select</span> <span class="comment">/*+mapjoin(a)*/</span> b.* </div><div class="line">  <span class="keyword">from</span> (<span class="keyword">select</span> <span class="keyword">distinct</span> <span class="keyword">id</span> <span class="keyword">from</span> A) a</div><div class="line">  <span class="keyword">join</span> B b</div><div class="line">  <span class="keyword">on</span> a.id = b.id</div><div class="line">)c</div><div class="line"><span class="keyword">join</span> A d</div><div class="line"><span class="keyword">on</span> c.id = d.id</div></pre></td></tr></table></figure>
</li>
</ul>
<p>参考文档：<br><a href="http://www.cnblogs.com/smartloli/p/4356660.html" target="_blank" rel="external">http://www.cnblogs.com/smartloli/p/4356660.html</a><br><a href="http://www.cnblogs.com/xd502djj/p/3799432.html" target="_blank" rel="external">http://www.cnblogs.com/xd502djj/p/3799432.html</a><br><a href="http://blog.csdn.net/scgaliguodong123_/article/details/45477323" target="_blank" rel="external">http://blog.csdn.net/scgaliguodong123_/article/details/45477323</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/21/Hadoop2的Hdfs框架/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/21/Hadoop2的Hdfs框架/" itemprop="url">Hadoop2.x的Hdfs框架</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-21T17:09:38+08:00">
                2017-02-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="早期Hdfs改进的原因"><a href="#早期Hdfs改进的原因" class="headerlink" title="早期Hdfs改进的原因"></a>早期Hdfs改进的原因</h3><p>早期的hadoop版本，NameNode是HDFS集群的单点故障点，每一个集群只有一个NameNode,如果这个机器或进程不可用，整个集群就无法使用。</p>
<h3 id="SPOF方案回顾-single-point-of-failure单点故障"><a href="#SPOF方案回顾-single-point-of-failure单点故障" class="headerlink" title="SPOF方案回顾(single point of failure单点故障)"></a>SPOF方案回顾(single point of failure单点故障)</h3><ol>
<li>Secondary NameNode：<strong>它不是HA</strong>，它只是阶段性的合并edits和fsimage，以缩短集群启动的时间。当NN失效的时候，Secondary NN并无法立刻提供服务，Secondary NN甚至无法保证数据完整性：如果NN数据丢失的话，在上一次合并后的文件系统的改动会丢失</li>
<li>Backup NameNode：它在内存中复制了NN的当前状态，算是Warm Standby，可也就仅限于此，并没有 <strong>failover(故障自动处理)</strong> 等。它同样是阶段性的做checkpoint，也无法保证数据完整性</li>
<li>手动把<strong>name.dir指向NFS</strong>（Network File System），这是安全的Cold Standby，可以保证元数据不丢失，但集群的恢复则完全靠手动</li>
<li>Facebook AvatarNode：Facebook有强大的运维做后盾，所以Avatarnode只是Hot Standby，并没有自动切换，当主NN失效的时候，需要管理员确认，然后手动把对外提供服务的虚拟IP映射到Standby NN，这样做的好处是确保不会发生脑裂的场景。</li>
</ol>
<ul>
<li>Facebook AvatarNode 原理示例图</li>
<li><img src="/images/201702/hdfs2_1.png"></li>
<li>PrimaryNN与StandbyNN之间通过NFS来共享FsEdits、FsImage文件，这样主备NN之间就拥有了一致的目录树和block信息；而block的位置信息，可以根据DN向两个NN上报的信息过程中构建起来。这样再辅以虚IP，可以较好达到主备NN快速热切的目的。但是显然，这里的<em>NFS又引入了新的SPOF</em></li>
</ul>
<h3 id="HDFS-NameNode-高可用整体架构"><a href="#HDFS-NameNode-高可用整体架构" class="headerlink" title="HDFS NameNode 高可用整体架构"></a>HDFS NameNode 高可用整体架构</h3><img src="/images/201702/hdfs2_2.png">
<p>NameNode 的高可用架构主要分为下面几个部分：</p>
<ul>
<li>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。</li>
<li>主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。</li>
<li>Zookeeper 集群：为主备切换控制器提供主备选举支持。</li>
<li>共享存储系统：<strong>共享存储系统是实现NameNode的高可用最为关键的部分</strong>，共享存储系统保存了NameNode在运行过程中所产生的 HDFS 的元数据。主NameNode和备NameNode通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。</li>
<li>DataNode 节点：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。DataNode 会<strong>同时</strong>向主 NameNode 和备 NameNode 上报数据块的位置信息。</li>
</ul>
<h4 id="共享存储系统简单分析原理"><a href="#共享存储系统简单分析原理" class="headerlink" title="共享存储系统简单分析原理"></a>共享存储系统简单分析原理</h4><p>QJM/Qurom Journal Manager，这是一个基于Paxos算法实现的HDFS HA方案<br><img src="/images/201702/hdfs2_3.png"></p>
<ul>
<li>基本原理就是用2N+1台 JournalNode 存储EditLog，每次写数据操作有大多数（&gt;=N+1）返回成功时即认为该次写成功，数据不会丢失了。当然这个算法所能容忍的是最多有N台机器挂掉，如果多于N台挂掉，这个算法就失效了。</li>
<li>在HA架构里面SecondaryNameNode这个冷备角色已经不存在了，为了保持standby NN时时的与主Active NN的元数据保持一致，他们之间交互通过一系列守护的轻量级进程JournalNode</li>
<li>任何修改操作在 Active NN上执行时，JN进程同时也会记录修改log到至少半数以上的JN中，这时 Standby NN 监测到JN 里面的同步log发生变化了会读取 JN 里面的修改log，然后同步到自己的的目录镜像树里面，如下图：</li>
<li><img src="/images/201702/hdfs2_4.png"></li>
<li>当发生故障时，Active的 NN 挂掉后，Standby NN 会在它成为Active NN 前，读取所有的JN里面的修改日志，这样就能高可靠的保证与挂掉的NN的目录镜像树一致，然后无缝的接替它的职责，维护来自客户端请求，从而达到一个高可用的目的</li>
<li>QJM方式来实现HA的主要优势：</li>
</ul>
<ol>
<li>不需要配置额外的高共享存储，降低了复杂度和维护成本</li>
<li>消除spof</li>
<li>系统健壮性的程度是可配置</li>
<li>JN不会因为其中一台的延迟而影响整体的延迟，而且也不会因为JN的数量增多而影响性能（因为NN向JN发送日志是并行的）</li>
</ol>
<h4 id="NameNode的主备切换实现"><a href="#NameNode的主备切换实现" class="headerlink" title="NameNode的主备切换实现"></a>NameNode的主备切换实现</h4><p>NameNode 主备切换主要由 ZKFailoverController、HealthMonitor 和 ActiveStandbyElector 这 3 个组件来协同实现</p>
<ul>
<li>ZKFailoverController 启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。</li>
<li>HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调 ZKFailoverController 的相应方法进行自动的主备选举。</li>
<li>ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</li>
</ul>
<p>NameNode 实现主备切换的流程如下图所示:<br><img src="/images/201702/hdfs2_5.png"></p>
<ol>
<li>HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。</li>
<li>HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会回调 ZKFailoverController 注册的相应方法进行处理。</li>
<li>如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。</li>
<li>ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。</li>
<li>ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。</li>
<li>ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。</li>
</ol>
<p>参考文档:<br><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/" target="_blank" rel="external">https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/</a><br><a href="http://www.cnblogs.com/tgzhu/p/5790565.html" target="_blank" rel="external">http://www.cnblogs.com/tgzhu/p/5790565.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/20/Hadoop1的Hdfs框架/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/20/Hadoop1的Hdfs框架/" itemprop="url">Hadoop1.x的Hdfs框架</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-20T22:10:18+08:00">
                2017-02-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>hdfs是一个分布式文件系统。它以文件分块的形式实现对大文件安全的、可靠的以及可快速（高吞吐量）访问的分布式存储。</p>
<h2 id="HDFS架构图"><a href="#HDFS架构图" class="headerlink" title="HDFS架构图"></a>HDFS架构图</h2><img src="/images/201702/hdfs1_1.png">
<h2 id="HDFS一些概念"><a href="#HDFS一些概念" class="headerlink" title="HDFS一些概念"></a>HDFS一些概念</h2><ul>
<li>Block数据块</li>
<li>NameNode</li>
<li>DataNode</li>
<li>Secondary NameNode</li>
</ul>
<h3 id="Block数据块"><a href="#Block数据块" class="headerlink" title="Block数据块"></a>Block数据块</h3><p>HDFS中的所有文件都是<strong>分割成块</strong>存储在Datanode上的，每个块默认64M。每个块都有多个副本存储在不同的机器上：默认有3个副本，3个副本不可能存放在同一个机器上。<br>HDFS副本存放策略:<br><img src="/images/201702/hdfs1_2.png"></p>
<h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><p>NameNode是Hdfs中的master节点<br>主要功能:</p>
<ul>
<li>管理整个文件系统的<strong>命名空间</strong>和控制着客户端对文件的访问。(它不保存文件的内容，而是保存着文件的元数据: <strong>文件名称，所在目录，文件权限，文件拥有者，文件有多少块，每个块有多少副本，块都存在哪些节点上</strong>)</li>
<li>NameNode也负责维护所有这些<strong>文件或目录的打开、关闭、移动、重命名</strong>等操作。(对于实际文件数据的保存与操作，都是由DataNode负责。当一个客户端请求数据时，它仅仅是从NameNode中获取文件的元信息，而具体的数据传输不需要经过NameNode，是由客户端直接与相应的DataNode进行交互)</li>
</ul>
<p>PS. NameNode元信息<em>并不包含每个块的位置信息</em>，这些信息会在NameNode启动时从各个DataNode获取并保存在内存中</p>
<h4 id="fsimage"><a href="#fsimage" class="headerlink" title="fsimage"></a>fsimage</h4><p>fsimage是元数据镜像文件: NameNode启动后，fsimage被加载到内存中</p>
<h4 id="editslog"><a href="#editslog" class="headerlink" title="editslog"></a>editslog</h4><p>editslog是元数据操作日志文件: 客户端要对文件进行读写操作，在这些操作产生的日志就存在了editslog文件中</p>
<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><p>DataNode是Hdfs中的worker节点<br>主要功能:</p>
<ul>
<li>存储数据块</li>
<li>为客户端提供数据块的读写服务</li>
<li>根据NameNode的指示来进行创建、删除、和复制等操作</li>
<li>通过心跳定期向NameNode发送所存储文件块列表信息</li>
</ul>
<h3 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h3><p>NameNode作为Hdfs中的master，不能负载太高，所以需要一个助手来分担压力<br>主要功能:</p>
<ul>
<li>镜像备份（当NameNode出现故障后，通过备份的镜像能挽回一些损失）</li>
<li>日志editslog与镜像fsimage的定期合并(分担NameNode工作)</li>
</ul>
<h4 id="日志editslog与镜像fsimage的定期合并过程"><a href="#日志editslog与镜像fsimage的定期合并过程" class="headerlink" title="日志editslog与镜像fsimage的定期合并过程"></a>日志editslog与镜像fsimage的定期合并过程</h4><p>1、合并之前告知NameNode把所有的操作写到新的edites文件并将其命名为edits.new。<br>2、SecondaryNameNode从NameNode请求fsimage和edits文件<br>3、SecondaryNameNode把fsimage和edits文件合并成新的fsimage文件<br>4、NameNode从SecondaryNameNode获取合并好的新的fsimage并将旧的替换掉，并把edits用第一步创建的edits.new文件替换掉<br>5、更新fstime文件中的检查点</p>
<p>再总结一下整个过程中涉及到NameNode中的相关文件</p>
<ul>
<li>fsimage ：保存的是上个检查点的HDFS的元信息</li>
<li>edits ：保存的是从上个检查点开始发生的HDFS元信息状态改变信息</li>
<li>fstime：保存了最后一个检查点的时间戳</li>
</ul>
<h2 id="HDFS读写操作"><a href="#HDFS读写操作" class="headerlink" title="HDFS读写操作"></a>HDFS读写操作</h2><h3 id="读"><a href="#读" class="headerlink" title="读"></a>读</h3><ol>
<li>客户端发起读请求</li>
<li>客户端与NameNode得到文件的块及位置信息列表</li>
<li>客户端直接和DataNode交互读取数据</li>
<li>读取完成关闭连接</li>
</ol>
<img src="/images/201702/hdfs1_3.png">
<p>在上图中3步骤中，客户端通过网络拓扑，选择最优的DataNode去读取数据<br>网络拓扑简单理解(按照优先级排序):</p>
<ol>
<li>同一节点中的进程</li>
<li>同一机架上的不同节点</li>
<li>同一数据中心不同机架</li>
<li>不同数据中心的节点</li>
</ol>
<h3 id="写"><a href="#写" class="headerlink" title="写"></a>写</h3><ol>
<li>客户端在向NameNode请求之前先写入文件数据到本地文件系统的一个 <strong>临时文件</strong> </li>
<li>待临时文件 <strong>达到块大小</strong> 时开始向NameNode请求DataNode信息</li>
<li>NameNode在文件系统中创建文件并返回给客户端一个数据块及其对应DataNode的地址列表（列表中包含副本存放的地址）</li>
<li>客户端通过上一步得到的信息把创建临时文件块flush到列表中的第一个DataNode</li>
<li>当文件关闭，NameNode会提交这次文件创建，此时，文件在文件系统中可见</li>
</ol>
<p>上面第四步描述的flush过程实际处理过程比较负杂，现在单独描述一下:</p>
<ol>
<li>首先，第一个DataNode是以数据包(数据包一般4KB)的形式从客户端接收数据的，DataNode在把数据包写入到本地磁盘的 <strong>同时</strong> 会向第二个DataNode（作为副本节点）传送数据。</li>
<li>在第二个DataNode把接收到的数据包写入本地磁盘时会向第三个DataNode发送数据包</li>
<li>第三个DataNode开始向本地磁盘写入数据包。此时，数据包以流水线的形式被写入和备份到所有DataNode节点</li>
<li>传送管道中的每个DataNode节点在收到数据后都会向前面那个DataNode发送一个ACK,最终，第一个DataNode会向客户端发回一个ACK</li>
<li>当客户端收到数据块的确认之后，数据块被认为已经持久化到所有节点。然后，客户端会向NameNode发送一个确认</li>
<li>如果管道中的任何一个DataNode失败，管道会被关闭。数据将会继续写到剩余的DataNode中。同时NameNode会被告知待备份状态，NameNode会继续备份数据到新的可用的节点</li>
<li>数据块都会通过计算校验和来检测数据的完整性，校验和以隐藏文件的形式被单独存放在hdfs中，供读取时进行完整性校验</li>
</ol>
<img src="/images/201702/hdfs1_4.png">
<h2 id="HDFS的优缺点"><a href="#HDFS的优缺点" class="headerlink" title="HDFS的优缺点"></a>HDFS的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>高容错性<br>数据自动保存多个副本<br>副本丢失后，自动恢复</li>
<li>适合批处理<br>移动计算而非数据<br>数据位置暴露给计算框架</li>
<li>适合大数据处理<br>GB、TB、甚至PB级数据<br>百万规模以上的文件数量<br>10K+节点规模</li>
<li>流式文件访问<br>一次性写入，多次读取<br>保证数据一致性</li>
<li>可构建在廉价机器上<br>通过多副本提高可靠性<br>提供了容错和恢复机制<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3></li>
<li>低延迟与高吞吐率的数据访问</li>
<li>小文件存取<br>占用NameNode大量内存<br>寻道时间超过读取时间</li>
<li>并发写入、文件随机修改<br>一个文件同一个时间只能有一个写者 </li>
</ul>
<img src="/images/201702/hdfs1_5.png">
<p>参考文档:<br><a href="http://blog.csdn.net/suifeng3051/article/details/48548341" target="_blank" rel="external">http://blog.csdn.net/suifeng3051/article/details/48548341</a><br><a href="http://www.cnblogs.com/meet/p/5439805.html" target="_blank" rel="external">http://www.cnblogs.com/meet/p/5439805.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/19/一致性Hash/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/19/一致性Hash/" itemprop="url">一致性Hash</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-19T19:19:15+08:00">
                2017-02-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="环形Hash空间"><a href="#环形Hash空间" class="headerlink" title="环形Hash空间"></a>环形Hash空间</h4><p>按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图<br><img src="/images/201702/hashCode_1.png"></p>
<h4 id="把数据通过一定的hash算法处理后映射到环上"><a href="#把数据通过一定的hash算法处理后映射到环上" class="headerlink" title="把数据通过一定的hash算法处理后映射到环上"></a>把数据通过一定的hash算法处理后映射到环上</h4><p>现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。<br>Hash(object1) = key1；<br>Hash(object2) = key2；<br>Hash(object3) = key3；<br>Hash(object4) = key4；<br>如下图：<br><img src="/images/201702/hashCode_2.png"></p>
<h4 id="将机器通过hash算法映射到环上"><a href="#将机器通过hash算法映射到环上" class="headerlink" title="将机器通过hash算法映射到环上"></a>将机器通过hash算法映射到环上</h4><p>在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。<br>假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中<br>Hash(NODE1) = KEY1;<br>Hash(NODE2) = KEY2;<br>Hash(NODE3) = KEY3;<br>其示意图如下：<br><img src="/images/201702/hashCode_3.png"></p>
<h4 id="机器的删除与添加"><a href="#机器的删除与添加" class="headerlink" title="机器的删除与添加"></a>机器的删除与添加</h4><p>普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。</p>
<ol>
<li>节点（机器）的删除<br>以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图：<img src="/images/201702/hashCode_4.png"></li>
<li>节点（机器）的添加<br>如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图：<img src="/images/201702/hashCode_5.png">
通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。<h4 id="解决平衡性问题"><a href="#解决平衡性问题" class="headerlink" title="解决平衡性问题"></a>解决平衡性问题</h4>根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。<br>——“虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。<br>以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下：<img src="/images/201702/hashCode_6.png">
根据上图可知对象的映射关系：object1-&gt;NODE1-1，object2-&gt;NODE1-2，object3-&gt;NODE3-2，object4-&gt;NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。</li>
</ol>
<p><strong>PS. 判定哈希算法好坏的四个定义：</strong></p>
<ul>
<li>平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</li>
<li>单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 </li>
<li>分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 </li>
<li>负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</li>
</ul>
<p>参考文档:<br><a href="http://blog.csdn.net/cywosp/article/details/23397179/" target="_blank" rel="external">http://blog.csdn.net/cywosp/article/details/23397179/</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/18/一个hive优化的例子/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/18/一个hive优化的例子/" itemprop="url">一个Hive优化的例子</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-18T09:04:32+08:00">
                2017-02-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="表结构和需求"><a href="#表结构和需求" class="headerlink" title="表结构和需求"></a>表结构和需求</h3><h4 id="表"><a href="#表" class="headerlink" title="表"></a>表</h4><p>TableName: <strong>logFile</strong></p>
<table>
<thead>
<tr>
<th>id</th>
<th>city1</th>
<th>city2</th>
<th>city3</th>
<th>action</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>BeiJing</td>
<td>ShangHai</td>
<td>ShenZhen</td>
<td>Dance</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<p>TableName: <strong>City</strong></p>
<table>
<thead>
<tr>
<th>id</th>
<th>CityName</th>
<th>CityCode</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>BeiJing</td>
<td>Jing</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<h4 id="需求按照传统SQL语句"><a href="#需求按照传统SQL语句" class="headerlink" title="需求按照传统SQL语句:"></a>需求按照传统SQL语句:</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> b.action, a.CityCode, <span class="keyword">count</span>(<span class="number">1</span>)</div><div class="line"><span class="keyword">from</span> City a</div><div class="line"><span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line"><span class="keyword">on</span> (b.city1=a.CityName <span class="keyword">or</span> b.city2=a.CityName <span class="keyword">or</span> b.city3=a.CityName)</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> b.action, a.CityCode;</div></pre></td></tr></table></figure>
<h4 id="具体表和sql操作结果"><a href="#具体表和sql操作结果" class="headerlink" title="具体表和sql操作结果:"></a>具体表和sql操作结果:</h4><img src="/images/201702/hive_ex_1.png">
<h3 id="把SQL复制到Hive中执行-—-gt-笛卡尔积"><a href="#把SQL复制到Hive中执行-—-gt-笛卡尔积" class="headerlink" title="把SQL复制到Hive中执行 —&gt; 笛卡尔积"></a>把SQL复制到Hive中执行 —&gt; 笛卡尔积</h3><p><strong>报错!</strong> 这是因为 hive 受限于 MapReduce 算法模型，只支持 equi-joins（等值join），要实现上述的非等值 join，可以采用笛卡儿积(full Cartesian product)来实现：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> b.action, a.CityCode, <span class="keyword">count</span>(<span class="number">1</span>)</div><div class="line"><span class="keyword">from</span> City a</div><div class="line"><span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line"><span class="keyword">where</span> (b.city1=a.CityName <span class="keyword">or</span> b.city2=a.CityName <span class="keyword">or</span> b.city3=a.CityName)</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> b.action, a.CityCode;</div></pre></td></tr></table></figure></p>
<h3 id="笛卡尔积占用资源太大-—-gt-union-all"><a href="#笛卡尔积占用资源太大-—-gt-union-all" class="headerlink" title="笛卡尔积占用资源太大 —&gt; union all"></a>笛卡尔积占用资源太大 —&gt; union all</h3><p><strong>笛卡尔积默认不让执行</strong><br>既然不允许非等值 join，采用多个子查询union all，然后汇总(假设logFile表中每一行的三个city都不一样)<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> tmp.action, tmp.CityCode, <span class="keyword">count</span>(<span class="number">1</span>)</div><div class="line"><span class="keyword">from</span></div><div class="line">(</div><div class="line">    <span class="keyword">select</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city1</div><div class="line">    <span class="keyword">union</span> all</div><div class="line">    <span class="keyword">select</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city2</div><div class="line">    <span class="keyword">union</span> all</div><div class="line">    <span class="keyword">select</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city3</div><div class="line">)tmp</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">action</span>, CityCode</div></pre></td></tr></table></figure></p>
<h3 id="优化：map-side-join"><a href="#优化：map-side-join" class="headerlink" title="优化：map side join"></a>优化：map side join</h3><p>如果City是一张小表<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> tmp.action, tmp.CityCode, <span class="keyword">count</span>(<span class="number">1</span>)</div><div class="line"><span class="keyword">from</span></div><div class="line">(</div><div class="line">    <span class="keyword">select</span> <span class="comment">/*+ MAPJOIN(a) */</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city1</div><div class="line">    <span class="keyword">union</span> all</div><div class="line">    <span class="keyword">select</span> <span class="comment">/*+ MAPJOIN(a) */</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city2</div><div class="line">    <span class="keyword">union</span> all</div><div class="line">    <span class="keyword">select</span> <span class="comment">/*+ MAPJOIN(a) */</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city3</div><div class="line">)tmp</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">action</span>, CityCode</div></pre></td></tr></table></figure></p>
<h2 id="开启-parallel"><a href="#开启-parallel" class="headerlink" title="开启 parallel"></a>开启 parallel</h2><p>三个 union 语句之间没有依赖关系，其实是可以并行执行的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> hive.exec.parallel=<span class="literal">true</span>;</div></pre></td></tr></table></figure></p>
<p>参考文档:<br><a href="https://my.oschina.net/leejun2005/blog/307812" target="_blank" rel="external">https://my.oschina.net/leejun2005/blog/307812</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/17/hive的join操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/17/hive的join操作/" itemprop="url">Hive的join操作</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-17T11:26:04+08:00">
                2017-02-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="join类型"><a href="#join类型" class="headerlink" title="join类型"></a>join类型</h2><ul>
<li>内关联（JOIN）</li>
<li>左外关联（LEFT [OUTER] JOIN)</li>
<li>右外关联（RIGHT [OUTER] JOIN）</li>
<li>全外关联（FULL [OUTER] JOIN）</li>
<li>LEFT SEMI JOIN</li>
<li>笛卡尔积关联（CROSS JOIN）</li>
</ul>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>TableName: <strong>Name</strong></p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>zhangsan</td>
</tr>
<tr>
<td>2</td>
<td>lisi</td>
</tr>
<tr>
<td>3</td>
<td>wangwu</td>
</tr>
</tbody>
</table>
<p>TableName: <strong>Age</strong></p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>30</td>
</tr>
<tr>
<td>2</td>
<td>29</td>
</tr>
<tr>
<td>4</td>
<td>21</td>
</tr>
</tbody>
</table>
<h2 id="内关联（JOIN）"><a href="#内关联（JOIN）" class="headerlink" title="内关联（JOIN）"></a>内关联（JOIN）</h2><p>返回能关联上的结果<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a</div><div class="line"><span class="keyword">join</span> Age b</div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">--执行结果</span></div><div class="line">1       zhangsan    30</div><div class="line">2       lisi        29</div></pre></td></tr></table></figure></p>
<h2 id="左外关联（LEFT-OUTER-JOIN）"><a href="#左外关联（LEFT-OUTER-JOIN）" class="headerlink" title="左外关联（LEFT [OUTER] JOIN）"></a>左外关联（LEFT [OUTER] JOIN）</h2><p>以LEFT [OUTER] JOIN关键字 <strong>前面的表</strong> 作为主表，和其他表进行关联，返回记录和主表的记录数一致，关联不上的字段置为NULL。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">left</span> <span class="keyword">join</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1   zhangsan   30</div><div class="line">2   lisi       29</div><div class="line">3   wangwu     NULL</div></pre></td></tr></table></figure></p>
<h2 id="右外关联（RIGHT-OUTER-JOIN）"><a href="#右外关联（RIGHT-OUTER-JOIN）" class="headerlink" title="右外关联（RIGHT [OUTER] JOIN）"></a>右外关联（RIGHT [OUTER] JOIN）</h2><p>和左外关联相反，以RIGTH [OUTER] JOIN关键词 <strong>后面的表</strong> 作为主表，和前面的表做关联，返回记录数和主表一致，关联不上的字段为NULL。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">RIGHT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1          zhangsan    30</div><div class="line">2          lisi        29</div><div class="line">NULL       NULL        21</div></pre></td></tr></table></figure></p>
<h2 id="全外关联（FULL-OUTER-JOIN）"><a href="#全外关联（FULL-OUTER-JOIN）" class="headerlink" title="全外关联（FULL [OUTER] JOIN）"></a>全外关联（FULL [OUTER] JOIN）</h2><p>以两个表的记录为基准，返回两个表的记录去重之和，关联不上的字段为NULL。<br><em>注意：FULL JOIN时候，Hive不会使用MapJoin来优化。</em><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1       zhangsan        30</div><div class="line">2       lisi            29</div><div class="line">3       wangwu          NULL</div><div class="line">NULL    NULL            21</div></pre></td></tr></table></figure></p>
<h2 id="LEFT-SEMI-JOIN"><a href="#LEFT-SEMI-JOIN" class="headerlink" title="LEFT SEMI JOIN"></a>LEFT SEMI JOIN</h2><p>以LEFT SEMI JOIN关键字 <strong>前面的表</strong> 为主表，返回主表的KEY也在副表中的记录 <em>(相当于mysql中的 <strong>in</strong> 操作)。</em><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">LEFT</span> SEMI <span class="keyword">JOIN</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1       zhangsan</div><div class="line">2       lisi</div><div class="line"> </div><div class="line"><span class="comment">--等价于：</span></div><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">WHERE</span> a.id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> Age);</div><div class="line"> </div><div class="line"> </div><div class="line"><span class="comment">--也等价于：</span></div><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">join</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--也等价于：</span></div><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">WHERE</span> <span class="keyword">EXISTS</span> (<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">FROM</span> Age b <span class="keyword">WHERE</span> a.id = b.id);</div></pre></td></tr></table></figure></p>
<p>PS. LEFT SEMI JOIN 和 JOIN的区别:<br><strong>当B表出现重复数据的时候</strong>LEFT SEMI JOIN是在B表上产生符合条件之后就返回,不会再继续查找B表记录了，而JOIN是会遍历完整个B表,返回所有符合条件的纪录</p>
<h2 id="笛卡尔积关联（CROSS-JOIN）"><a href="#笛卡尔积关联（CROSS-JOIN）" class="headerlink" title="笛卡尔积关联（CROSS JOIN）"></a>笛卡尔积关联（CROSS JOIN）</h2><p>返回两个表的笛卡尔积结果，不需要指定关联键。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> lxw1234_a a </div><div class="line"><span class="keyword">CROSS</span> <span class="keyword">JOIN</span> lxw1234_b b;</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1       zhangsan        30</div><div class="line">1       zhangsan        29</div><div class="line">1       zhangsan        21</div><div class="line">2       lisi            30</div><div class="line">2       lisi            29</div><div class="line">2       lisi            21</div><div class="line">3       wangwu          30</div><div class="line">3       wangwu          29</div><div class="line">3       wangwu          21</div></pre></td></tr></table></figure></p>
<h2 id="map-site-JOIN"><a href="#map-site-JOIN" class="headerlink" title="map-site JOIN"></a>map-site JOIN</h2><p>如果所有表中只有一张表是小表，那么可以在最大的表通过Mapper的时候将小标完全放倒内存中。Hive可以在map端执行连接过程（称为map-site join）。这样做的优点：</p>
<ul>
<li>小表加入内存，省去常规连接操作所需要的reduce过程</li>
<li>同时减少map过程的执行步骤</li>
</ul>
<h3 id="方法一-直接通过SQL声明"><a href="#方法一-直接通过SQL声明" class="headerlink" title="方法一:直接通过SQL声明"></a>方法一:直接通过SQL声明</h3><p>select /<em>+mapjoin(a)</em>/ a.col1,b.col2<br>from table_a a join table_b b on a.col1=b.col1</p>
<h3 id="方法二-Hive配置来启用，用户也可以配置能够使用这个优化的小表大小"><a href="#方法二-Hive配置来启用，用户也可以配置能够使用这个优化的小表大小" class="headerlink" title="方法二:Hive配置来启用，用户也可以配置能够使用这个优化的小表大小"></a>方法二:Hive配置来启用，用户也可以配置能够使用这个优化的小表大小</h3><p>set hive.auto.convert.join=true;<br>set hive.mapjoin.smalltable.filesize=250000;<br>select a.col1,b.col2<br>from table_a a join table_b b on a.col1=b.col1</p>
<h3 id="mapjoin-还有一个很大的好处是能够进行不等连接的join操作"><a href="#mapjoin-还有一个很大的好处是能够进行不等连接的join操作" class="headerlink" title="mapjoin 还有一个很大的好处是能够进行不等连接的join操作"></a>mapjoin 还有一个很大的好处是能够进行不等连接的join操作</h3><p>如果将不等条件写在where中，那么mapreduce过程中会进行笛卡尔积，运行效率特别低，如果使用mapjoin操作，在map的过程中就完成了不等值的join操作，效率会高很多。<br>例子：<br>select A.a ,A.b from A join B where A.a&gt;B.a</p>
<h3 id="mapjoin的使用场景："><a href="#mapjoin的使用场景：" class="headerlink" title="mapjoin的使用场景："></a>mapjoin的使用场景：</h3><ul>
<li>关联操作中有一张表非常小</li>
<li>不等值的链接操作</li>
</ul>
<p>参考文档：<br><a href="http://lxw1234.com/archives/2015/06/315.htm" target="_blank" rel="external">http://lxw1234.com/archives/2015/06/315.htm</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/16/MapReduce自定义二次排序/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/16/MapReduce自定义二次排序/" itemprop="url">MapReduce自定义二次排序</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-16T20:14:34+08:00">
                2017-02-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="具体需求"><a href="#具体需求" class="headerlink" title="具体需求"></a>具体需求</h2><p>1、输入数据：<br>sort1    1<br>sort2    3<br>sort2    77<br>sort2    54<br>sort1    2<br>sort6    22<br>sort6    221<br>sort6    20<br>2、目标输出<br>sort1 1,2<br>sort2 3,54,77<br>sort6 20,22,221</p>
<h2 id="二次排序解决思路"><a href="#二次排序解决思路" class="headerlink" title="二次排序解决思路"></a>二次排序解决思路</h2><p>MapReduce框架不管是默认排序或者是自定义排序都只是对Key值进行排序，现在的情况是这些数据不是key值，怎么办？其实我们可以将原始数据的Key值和其对应的数据组合成一个新的Key值，然后新的Key值对应的还是之前的数字。那么我们就可以将原始数据的map输出变成类似下面的数据结构：<br>{[sort1,1],1}<br>{[sort2,3],3}<br>{[sort2,77],77}<br>{[sort2,54],54}<br>{[sort1,2],2}<br>{[sort6,22],22}<br>{[sort6,221],221}<br>{[sort6,20],20}<br>那么我们只需要对[]里面的新key值进行排序就ok了。然后我们需要自定义一个分区处理器，因为我的目标不是想将新key相同的传到同一个reduce中，而是想将新key中的第一个字段相同的才放到同一个reduce中进行分组合并，所以我们需要根据新key值中的第一个字段来自定义一个分区处理器。通过分区操作后，得到的数据流如下：<br>Partition1:{[sort1,1],1}、{[sort1,2],2}<br>Partition2:{[sort2,3],3}、{[sort2,77],77}、{[sort2,54],54}<br>Partition3:{[sort6,22],22}、{[sort6,221],221}、{[sort6,20],20}</p>
<h2 id="MR的运行流程简单说明"><a href="#MR的运行流程简单说明" class="headerlink" title="MR的运行流程简单说明"></a>MR的运行流程简单说明</h2><img src="/images/201702/map.png">
<img src="/images/201702/reduce.png">
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><img src="/images/201702/map_secondSort.png">
<img src="/images/201702/reduce_secondSort.png">
<h3 id="自定义组合键-更改key结构"><a href="#自定义组合键-更改key结构" class="headerlink" title="自定义组合键(更改key结构)"></a>自定义组合键(更改key结构)</h3><p>自定义组合键的时候，我们需要特别注意，一定要实现WritableComparable接口，并且实现compareTo方法的比较策略。这个用于mapreduce的第一次默认排序，也就是发生在map阶段的sort小阶段，发生地点为环形缓冲区(可以通过io.sort.mb进行大小调整)，但是其对我们最终的二次排序结果是没有影响的。我们二次排序的最终结果是由我们的自定义比较器决定的。</p>
<h3 id="自定义分区器"><a href="#自定义分区器" class="headerlink" title="自定义分区器"></a>自定义分区器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//默认的Hash分区</span></div><div class="line">key.hashCode()&amp;Integer.MAX_VALUE)%numPartitions</div><div class="line"><span class="comment">//自定义分区</span></div><div class="line">key.getFirstKey().hashCode()&amp;Integer.MAX_VALUE)%numPartitions</div></pre></td></tr></table></figure>
<h3 id="自定义比较器"><a href="#自定义比较器" class="headerlink" title="自定义比较器"></a>自定义比较器</h3><p>自定义比较器决定了我们二次排序的结果。自定义比较器需要继承WritableComparator类，并且重写compare方法实现自己的比较策略。</p>
<h3 id="自定义分组策略"><a href="#自定义分组策略" class="headerlink" title="自定义分组策略"></a>自定义分组策略</h3><p>将组合键中第一个值相同的分在一组<br>PS. 每处理完一个分组数据就会去调用一次的reduce函对这个分组来进行处理和输出</p>
<p>JAVA代码在下面参考资料(PS. 因为不会JAVA，所以我的重点在理解)<br>参考资料：<br><a href="http://zengzhaozheng.blog.51cto.com/8219051/1379271" target="_blank" rel="external">http://zengzhaozheng.blog.51cto.com/8219051/1379271</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/15/MapReduce的Shuffle过程/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/15/MapReduce的Shuffle过程/" itemprop="url">MapReduce的Shuffle过程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-15T11:12:32+08:00">
                2017-02-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>官网上Shuffle过程的图:<br><img src="/images/201702/mr_1.png"></p>
<p>举例(WordCount)：<br>File 1 内容：</p>
<blockquote>
<p>My name is Tony<br>My company is pivotal</p>
</blockquote>
<p>File 2 内容：</p>
<blockquote>
<p>My name is Lisa<br>My company is EMC</p>
</blockquote>
<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>Map端数据的处理详细过程如下图：<br><img src="/images/201702/mr_2.png"></p>
<ul>
<li>从磁盘上读取数据</li>
<li>执行map函数</li>
<li>Partition分区(放进内存)</li>
<li>Sort排序(内存排序)</li>
<li>Combine结果(内存预聚合)</li>
<li>将结果写到本地的磁盘上</li>
<li>Merge(对磁盘上的文件合并)</li>
</ul>
<h3 id="执行map函数后"><a href="#执行map函数后" class="headerlink" title="执行map函数后"></a>执行map函数后</h3><p>执行用户编写的map函数<br>接着上面例子:<br><strong>split 0</strong></p>
<blockquote>
<p>My       1<br>name    1<br>is         1<br>Tony     1<br>My          1<br>company     1<br>is       1<br>Pivotal   1</p>
</blockquote>
<p><strong>split 1</strong></p>
<blockquote>
<p>My       1<br>name    1<br>is       1<br>Lisa     1<br>My       1<br>company  1<br>is       1<br>EMC   　　1</p>
</blockquote>
<h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><p>为什么要分区？ 因为有时候会有多个Reducer, Partition就是提前对输入进行处理， 根据将来的Reducer进行分区. 到时候Reducer处理的时候，只需要处理分给自己的数据就可以了。<br>MR自带了一个默认的分区类，HashPartitioner<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K key, V value, <span class="keyword">int</span> numReduceTasks)</span> </span>&#123; </div><div class="line">    <span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks; </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>PS.  numReduceTasks(reduceTask的数量)是用户在提交前设定的，默认为1</p>
<p>结合例子，假设有两个Reducer, 前面两个split做完Partition的结果就会如下：<br><strong>split 0</strong></p>
<blockquote>
<p>Partition 1:<br>company    1<br>is    1<br>is    1</p>
<p>Partition 2:<br>My    1<br>My    1<br>name    1<br>Pivotal    1<br>Tony    1</p>
</blockquote>
<p><strong>split 1</strong></p>
<blockquote>
<p>Partition 1:<br>company    1<br>is    1<br>is    1<br>EMC    1</p>
<p>Partition 2:<br>My    1<br>My    1<br>name    1<br>Lisa    1</p>
</blockquote>
<p>key/value对以及Partition的结果(属于哪个reduce)都会被写入缓冲区。写入之前，key与value 值都会被序列化成字节数组</p>
<h3 id="Sort"><a href="#Sort" class="headerlink" title="Sort"></a>Sort</h3><p>作用：把内存缓冲区中的数据写入到本地磁盘，在写入本地磁盘时先按照partition、再按照key进行排序（quick sort）<br>1、这个spill是由另外单独的线程来完成，不影响往缓冲区写map结果的线程；<br>内存缓冲区默认大小限制为100MB，它有个溢写比例（spill.percent），默认为0.8，当缓冲区的数据达到阈值时，溢写线程就会启动，先锁定这80MB的内存，执行溢写过程，maptask的输出结果还可以往剩下的20MB内存中写，互不影响。然后再重新利用这块缓冲区，因此Map的内存缓冲区又叫做环形缓冲区（两个指针的方向不会变，下面会详述）；<br>2、在将数据写入磁盘之前，先要对要写入磁盘的数据进行一次排序操作，先按<key,value,partition>中的partition分区号排序，然后再按key排序，这个就是sort操作，最后溢出的小文件是分区的，且同一个分区内是保证key有序的；</key,value,partition></p>
<p>接着例子说明(split文件里格式: key,value,partition)：<br><strong>split 0</strong></p>
<blockquote>
<p>company    1    1<br>is    1    1<br>is    1    1<br>My    1    2<br>My    1    2<br>name    1    2<br>Pivotal    1    2<br>Tony    1    2</p>
</blockquote>
<p><strong>split 1</strong></p>
<blockquote>
<p>company    1    1<br>is    1    1<br>is    1    1<br>EMC    1    1<br>My    1    2<br>My    1    2<br>name    1    2<br>Lisa    1    2</p>
</blockquote>
<h3 id="Combine"><a href="#Combine" class="headerlink" title="Combine"></a>Combine</h3><p>combine：执行combine操作要求开发者必须在程序中设置了combine（程序中通过job.setCombinerClass(myCombine.class)自定义combine操作)<br>程序中有<strong>两个阶段</strong>可能会执行combine操作：<br>1、map输出数据根据分区排序完成后，在写入文件之前会执行一次combine操作<br>2、(下面merge过程)如果map输出比较大，溢出文件个数大于  <strong>3</strong>  （此值可以通过属性min.num.spills.for.combine配置）时，在merge的过程（多个spill文件合并为一个大文件）中还会执行combine操作<br>combine主要是把形如<aa,1>,<aa,2>这样的key值相同的数据进行计算，计算规则与reduce一致，比如：当前计算是求key对应的值求和，则combine操作后得到<aa,3>这样的结果</aa,3></aa,2></aa,1></p>
<p>接着例子说明:<br><strong>split 0</strong></p>
<blockquote>
<p>company    1    1<br>is    2    1<br>My    2    2<br>name    1    2<br>Pivotal    1    2<br>Tony    1    2</p>
</blockquote>
<p><strong>split 1</strong></p>
<blockquote>
<p>company    1    1<br>EMC    1    1<br>is    2    1<br>name    1    2<br>Lisa    1    2<br>My    2    2</p>
</blockquote>
<h3 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h3><p>merge过程：当map很大时，每次溢写会产生一个spill_file，这样会有多个spill_file，而最终的一个map task输出只有一个文件，因此，最终的结果输出之前会对多个中间过程进行多次溢写文件（spill_file）的合并，此过程就是merge过程。也即是，待Map Task任务的所有数据都处理完后，会对任务产生的所有中间数据文件做一次合并操作，以确保一个Map Task最终只生成一个中间数据文件。<br>注意：<br>1、如果生成的文件太多，可能会执行多次合并，每次最多能合并的文件数默认为  <strong>10</strong>  ，可以通过属性min.num.spills.for.combine配置；<br>2、多个溢出文件合并时，会进行一次排序，排序算法是多路归并排序<br>3、最终生成的文件格式与单个溢出文件一致，也是按分区顺序存储，并且输出文件会有一个对应的索引文件，记录每个分区数据的起始位置，长度以及压缩长度，这个索引文件名叫做file.out.index</p>
<p>例子没有Merge过程，所以省略</p>
<h2 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h2><img src="/images/201702/mr_3.png">
<h3 id="Copy"><a href="#Copy" class="headerlink" title="Copy"></a>Copy</h3><p>作用：拉取数据<br>过程：Reduce进程启动一些数据copy线程(Fetcher)，通过HTTP方式请求map task所在的TaskTracker获取map task的输出文件。因为这时map task早已结束，这些文件就归TaskTracker管理在本地磁盘中<br>默认情况下，当整个MapReduce作业的所有已执行完成的Map Task任务数超过Map Task总数的5%后，JobTracker便会开始调度执行Reduce Task任务。然后Reduce Task任务默认启动mapred.reduce.parallel.copies(默认为5）个MapOutputCopier线程到已完成的Map Task任务节点上分别copy一份属于自己的数据。 这些copy的数据会首先保存的内存缓冲区中，当内冲缓冲区的使用率达到一定阀值后，则写到磁盘上</p>
<p>接着上面例子：<br><strong>Reducer 节点 1</strong> 共包含两个文件:</p>
<blockquote>
<p>split 0:<br>company    1<br>is    2</p>
<p>split 1:<br>company    1<br>EMC    1<br>is    2</p>
</blockquote>
<p><strong>Reducer 节点 2</strong> 共包含两个文件:</p>
<blockquote>
<p>split 0:<br>name    1<br>Pivotal    1<br>Tony    1<br>My    2</p>
<p>split 1:<br>name    1<br>Lisa    1<br>My    2</p>
</blockquote>
<h3 id="Merge-1"><a href="#Merge-1" class="headerlink" title="Merge"></a>Merge</h3><p>Copy过来的数据会先放入内存缓冲区中，因为 Shuffle 阶段 Reducer 不运行，所以应该把绝大部分的内存都给 Shuffle 用<br>merge 有三种形式：1)内存到内存 2)内存到磁盘 3)磁盘到磁盘。默认情况下第一种形式是不启用的。当内存中的数据量到达一定阈值，就启动内存到磁盘的 merge（图中的第一个merge，之所以进行merge是因为reduce端在从多个map端copy数据的时候，并没有进行sort，只是把它们加载到内存，当达到阈值写入磁盘时，需要进行merge） 。这和map端的很类似，这实际上就是溢写的过程，在这个过程中如果你设置有Combiner，它也是会启用的，然后在磁盘中生成了众多的溢写文件，这种merge方式一直在运行，直到没有 map 端的数据时才结束，然后才会启动第三种磁盘到磁盘的 merge （图中的第二个merge）方式生成最终的那个文件。<br>在远程copy数据的同时(一边Copy一边Merge)，Reduce Task在后台启动了两个后台线程对内存和磁盘上的数据文件做合并操作，以防止内存使用过多或磁盘生的文件过多。</p>
<p>接着上面例子：<br><strong>Reducer 节点 1</strong></p>
<blockquote>
<p>company    1<br>is    2<br>company    1<br>EMC    1<br>is    2</p>
</blockquote>
<p><strong>Reducer 节点 2</strong></p>
<blockquote>
<p>name    1<br>Pivotal    1<br>Tony    1<br>My    2<br>name    1<br>Lisa    1<br>My    2</p>
</blockquote>
<p>参考博客：<br><a href="http://wangzzu.github.io/2016/03/02/hadoop-shuffle/" target="_blank" rel="external">http://wangzzu.github.io/2016/03/02/hadoop-shuffle/</a><br><a href="https://my.oschina.net/dataRunner/blog/611293" target="_blank" rel="external">https://my.oschina.net/dataRunner/blog/611293</a><br><a href="http://www.cnblogs.com/npumenglei/p/3631244.html" target="_blank" rel="external">http://www.cnblogs.com/npumenglei/p/3631244.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="xiwu1212@163.com" />
          <p class="site-author-name" itemprop="name">xiwu1212@163.com</p>
           
              <p class="site-description motion-element" itemprop="description">学无止境</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">40</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">tags</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiwu1212@163.com</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  

  

  

  

  

</body>
</html>
