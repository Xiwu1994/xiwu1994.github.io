<!doctype html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="Refrain">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Refrain">
<meta property="og:description" content="学无止境">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Refrain">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title> Refrain </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Refrain</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/08/Mongodb安装和简单使用/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/08/Mongodb安装和简单使用/" itemprop="url">
                  Mongodb安装和简单使用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-08T14:20:03+08:00">
                2017-02-08
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Mongodb-下载安装"><a href="#Mongodb-下载安装" class="headerlink" title="Mongodb 下载安装"></a>Mongodb 下载安装</h2><p>下载地址：<a href="http://www.mongodb.org/downloads" target="_blank" rel="external">http://www.mongodb.org/downloads</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -xzvf mongodb-osx-ssl-x86_64-3.4.2.tgz</div><div class="line">mv mongodb-osx-x86_64-3.4.2 /opt</div></pre></td></tr></table></figure></p>
<p>MongoDB 的可执行文件位于 bin 目录下，所以可以将其添加到 PATH 路径中：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> PATH=&lt;mongodb-install-directory&gt;/bin:<span class="variable">$PATH</span></div></pre></td></tr></table></figure></p>
<p><mongodb-install-directory> 为你 MongoDB 的安装路径。如本文的 /opt/mongodb-osx-x86_64-3.4.2</mongodb-install-directory></p>
<h2 id="创建数据库目录并启动"><a href="#创建数据库目录并启动" class="headerlink" title="创建数据库目录并启动"></a>创建数据库目录并启动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /data/mongodb_data</div><div class="line">mongod --dbpath /data/mongodb_data</div></pre></td></tr></table></figure>
<p>PS./data/db 是MongoDB默认启动的数据库目录<br>MongoDB 提供了简单的HTTP用户界面，启用该功能需要在启动的时候指定参数–rest<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mongod --dbpath /data/mongodb_data --rest</div></pre></td></tr></table></figure></p>
<p>登录<a href="http://localhost:28017/可查看" target="_blank" rel="external">http://localhost:28017/可查看</a><br><img src="/images/201702/mongodb_1.png"></p>
<h2 id="概念简单说明"><a href="#概念简单说明" class="headerlink" title="概念简单说明"></a>概念简单说明</h2><p>mongodb中基本的概念是文档、集合、数据库<br><img src="/images/201702/mongodb_2.png"></p>
<h2 id="简单shell操作"><a href="#简单shell操作" class="headerlink" title="简单shell操作"></a>简单shell操作</h2><p>之前启动了mongodb服务<br>在本机使用mongo命令进入客户端<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mongo</div></pre></td></tr></table></figure></p>
<h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">use DATABASE_NAME</div></pre></td></tr></table></figure>
<p>如果数据库不存在，则创建数据库，否则切换到指定数据库。<br><img src="/images/201702/mongodb_3.png"></p>
<h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">use DATABASE_NAME</div><div class="line">db.dropDatabase()</div></pre></td></tr></table></figure>
<p>先切换数据库，再使用删除命令<br><img src="/images/201702/mongodb_4.png"></p>
<h3 id="插入文档"><a href="#插入文档" class="headerlink" title="插入文档"></a>插入文档</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.COLLECTION_NAME.insert(document)</div></pre></td></tr></table></figure>
<p>例如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.insert(&#123;title: &apos;mongodbTest&apos;, tags: [&apos;mongodb&apos;, &apos;nosql&apos;]&#125;)</div></pre></td></tr></table></figure></p>
<p>以上实例中test1是我们的集合名，如果该集合不在该数据库中，MongoDB 会自动创建该集合并插入文档。<br>查看已插入文档：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.find()</div></pre></td></tr></table></figure></p>
<h3 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h3><h4 id="update"><a href="#update" class="headerlink" title="update"></a>update</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">db.collection.update(</div><div class="line">   &lt;query&gt;,</div><div class="line">   &lt;update&gt;,</div><div class="line">   &#123;</div><div class="line">     upsert: &lt;boolean&gt;,</div><div class="line">     multi: &lt;boolean&gt;,</div><div class="line">     writeConcern: &lt;document&gt;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<p>参数说明：<br>query : update的查询条件，类似sql update查询内where后面的。<br>update : update的对象和一些更新的操作符（如$,$inc…）等，也可以理解为sql update查询内set后面的<br>upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。<br>multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。<br>writeConcern :可选，抛出异常的级别。<br>例子:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.update(&#123;&apos;title&apos;:&apos;mongodbTest&apos;&#125;,&#123;$set:&#123;&apos;title&apos;:&apos;MongoDB&apos;&#125;&#125;)</div></pre></td></tr></table></figure></p>
<img src="/images/201702/mongodb_5.png">
<h4 id="save"><a href="#save" class="headerlink" title="save"></a>save</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">db.collection.save(</div><div class="line">   &lt;document&gt;,</div><div class="line">   &#123;</div><div class="line">     writeConcern: &lt;document&gt;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<p>参数说明：<br>document : 文档数据。<br>writeConcern :可选，抛出异常的级别。<br>例子:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.save(&#123;&quot;_id&quot; : ObjectId(&quot;589d38f38d1f1dec8daa9d27&quot;),&quot;title&quot; : &quot;mongodb&quot;,&quot;tags&quot; : [&quot;mongodb&quot;,&quot;NoSQL&quot;, &quot;database&quot;]&#125;)</div></pre></td></tr></table></figure></p>
<img src="/images/201702/mongodb_6.png">
<h3 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.collection.remove(</div><div class="line">   &lt;query&gt;,</div><div class="line">   &#123;</div><div class="line">     justOne: &lt;boolean&gt;,</div><div class="line">     writeConcern: &lt;document&gt;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<p>参数说明：<br>query :（可选）删除的文档的条件。<br>justOne : （可选）如果设为 true 或 1，则只删除一个文档。<br>writeConcern :（可选）抛出异常的级别。<br>例:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.remove(&#123;&apos;title&apos;:&apos;mongodb&apos;&#125;)</div></pre></td></tr></table></figure></p>
<h3 id="查询文档"><a href="#查询文档" class="headerlink" title="查询文档"></a>查询文档</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.collection.find(&#123;key1:value1, key2:value2&#125;).pretty()</div></pre></td></tr></table></figure>
<p>例:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.find(&#123;&apos;title&apos;:&apos;mongodb&apos;&#125;).pretty()</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/04/数据库简单总结/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/04/数据库简单总结/" itemprop="url">
                  关系型数据库和非关系型数据库简单总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-04T13:24:03+08:00">
                2017-02-04
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h2><h3 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h3><p>关系型数据库，采用了关系模型来组织数据的数据库。<br>关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>容易理解：二维表结构是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型来说更容易理解<br>使用方便：通用的SQL语言使得操作关系型数据库非常方便<br>易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率</p>
<h3 id="非关系型数据库"><a href="#非关系型数据库" class="headerlink" title="非关系型数据库"></a>非关系型数据库</h3><p>非关系型数据库产品是传统关系型数据库的功能阉割版本(去除ACID)，通过减少用不到或很少用的功能，来大幅度提高产品性能。</p>
<h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><p>以下的这几种情况下比较适用：<br>1、数据模型比较简单<br>2、需要灵活性更强的IT系统<br>3、对数据库性能要求较高<br>4、不需要高度的数据一致性<br>5、对于给定key，比较容易映射复杂值的环境</p>
<h4 id="常见的Nosql"><a href="#常见的Nosql" class="headerlink" title="常见的Nosql"></a>常见的Nosql</h4><p>高性能并发读写的key-value数据库:Redis,Tokyo<br>列存储数据库:HBase,Cassandra<br>文档型数据库:MongoDB,CouchDB<br>图形(Graph)数据库:Neo4J, InfoGrid</p>
<h2 id="主要优势"><a href="#主要优势" class="headerlink" title="主要优势"></a>主要优势</h2><p>非关系型数据库:操作的扩展性和大数据量处理<br>关系型数据库:事务的一致性(安全性能高)和复杂SQL查询</p>
<h2 id="分布式一些比较"><a href="#分布式一些比较" class="headerlink" title="分布式一些比较"></a>分布式一些比较</h2><img src="/images/201702/database_1.png">

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/28/c/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/28/c/" itemprop="url">
                  c
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-28T21:31:55+08:00">
                2017-01-28
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/27/大数据面试总结-1/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/27/大数据面试总结-1/" itemprop="url">
                  大数据面试总结-1
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-27T22:36:35+08:00">
                2017-01-27
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Spark比Hadoop快的原因"><a href="#Spark比Hadoop快的原因" class="headerlink" title="Spark比Hadoop快的原因"></a>Spark比Hadoop快的原因</h2><h3 id="一、shuffle后中间结果可以存入内存而不是直接写入到disk"><a href="#一、shuffle后中间结果可以存入内存而不是直接写入到disk" class="headerlink" title="一、shuffle后中间结果可以存入内存而不是直接写入到disk"></a>一、shuffle后中间结果可以存入内存而不是直接写入到disk</h3><h3 id="二、减少shuffle阶段，因为DAG的优化-（待深入）"><a href="#二、减少shuffle阶段，因为DAG的优化-（待深入）" class="headerlink" title="二、减少shuffle阶段，因为DAG的优化..（待深入）"></a>二、减少shuffle阶段，因为DAG的优化..（待深入）</h3><h2 id="Spark通过yarn提交任务时，Yarn-client和Yarn-cluster的区别"><a href="#Spark通过yarn提交任务时，Yarn-client和Yarn-cluster的区别" class="headerlink" title="Spark通过yarn提交任务时，Yarn-client和Yarn-cluster的区别"></a>Spark通过yarn提交任务时，Yarn-client和Yarn-cluster的区别</h2><p>1、Yarn-cluster—生产环境，Yarn-client—交互和调试<br>2、Yarn-cluster模式,Driver运行在AM(Application Master)中，它负责向Yarn申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在Yarn上运行。<br>Yarn-client模式,AM仅仅向Yarn请求executor,client会和请求的container通信来调度他们的工作<br>yarn-cluster:<br><img src="/images/201702/yarn-cluster.png"><br>yarn-client:<br><img src="/images/201702/yarn-client.png"></p>
<h2 id="MapReduce调优"><a href="#MapReduce调优" class="headerlink" title="MapReduce调优"></a>MapReduce调优</h2><h3 id="管理员"><a href="#管理员" class="headerlink" title="管理员"></a>管理员</h3><h4 id="JVM参数调优"><a href="#JVM参数调优" class="headerlink" title="JVM参数调优"></a>JVM参数调优</h4><p>通过调整JVM FLAGS和JVM垃圾回收机制提高Hadoop性能</p>
<h4 id="Hadoop参数调优"><a href="#Hadoop参数调优" class="headerlink" title="Hadoop参数调优"></a>Hadoop参数调优</h4><p>合理规划资源，调整心跳配置，磁盘块配置(I/O密集型，增加磁盘块)，启用批量任务调度，选择合适的压缩算法，启用预读取机制</p>
<h3 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h3><h4 id="应用程序编写规范"><a href="#应用程序编写规范" class="headerlink" title="应用程序编写规范"></a>应用程序编写规范</h4><p>1、设置Combiner(对于大批MR程序)<br>2、选择合理的Writable类型</p>
<h4 id="作业级别参数调优"><a href="#作业级别参数调优" class="headerlink" title="作业级别参数调优"></a>作业级别参数调优</h4><p>规划合理的任务数目，增加文件副本数，启用推测执行机制，适当打开JVM重用功能，设置任务超时时间</p>
<h4 id="任务级别参数调优"><a href="#任务级别参数调优" class="headerlink" title="任务级别参数调优"></a>任务级别参数调优</h4><p>Map Task调优, Reduce Task调优</p>
<h2 id="Hive调优"><a href="#Hive调优" class="headerlink" title="Hive调优"></a>Hive调优</h2><h3 id="配置角度优化"><a href="#配置角度优化" class="headerlink" title="配置角度优化"></a>配置角度优化</h3><p>列裁剪, 分区裁剪, join(小表放前), group by(Map端部分聚合,负载均衡), 合并小文件<br>reduce的内存和数量配置</p>
<h3 id="程序角度优化"><a href="#程序角度优化" class="headerlink" title="程序角度优化"></a>程序角度优化</h3><p>GROUP BY替代COUNT(DISTINCT), 不同数据类型关联产生的倾斜问题, 无效ID在关联时的数据倾斜问题</p>
<p>转载:<br><a href="http://jaydenwang.blog.51cto.com/6033165/1845247" target="_blank" rel="external">http://jaydenwang.blog.51cto.com/6033165/1845247</a><br><a href="http://www.cnblogs.com/smartloli/p/4356660.html" target="_blank" rel="external">http://www.cnblogs.com/smartloli/p/4356660.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/26/Spark运行框架/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/26/Spark运行框架/" itemprop="url">
                  Spark运行框架
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-26T12:00:43+08:00">
                2017-01-26
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Spark官网展示了如下的集群运行架构"><a href="#Spark官网展示了如下的集群运行架构" class="headerlink" title="Spark官网展示了如下的集群运行架构"></a>Spark官网展示了如下的集群运行架构</h3><img src="/images/201701/Spark_Frame_1.png">
<h3 id="Spark-Standalone-Client-Mode-运行流程示意图"><a href="#Spark-Standalone-Client-Mode-运行流程示意图" class="headerlink" title="Spark Standalone Client Mode 运行流程示意图"></a>Spark Standalone Client Mode 运行流程示意图</h3><img src="/images/201701/Spark_Frame_2.png">
<h3 id="Spark-YARN-Cluster-Mode-运行流程示意图"><a href="#Spark-YARN-Cluster-Mode-运行流程示意图" class="headerlink" title="Spark YARN Cluster Mode 运行流程示意图"></a>Spark YARN Cluster Mode 运行流程示意图</h3><img src="/images/201701/Spark_Frame_3.png">
<p>转载: <a href="http://blog.csdn.net/bigdata_wang/article/details/48245581" target="_blank" rel="external">http://blog.csdn.net/bigdata_wang/article/details/48245581</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/25/supervisor使用/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/25/supervisor使用/" itemprop="url">
                  Supervisor简单使用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-25T15:52:23+08:00">
                2017-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="下载安装Supervisor"><a href="#下载安装Supervisor" class="headerlink" title="下载安装Supervisor"></a>下载安装Supervisor</h3><p>pip install supervisor<br>如果在命令行中输入echo_supervisord_conf没有找到命令，那么需要在环境变量PATH添加Python的bin目录路径</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>echo_supervisord_conf &gt; /etc/supervisord.conf<br>vim /etc/supervisord.conf<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">[unix_http_server]</div><div class="line">file=/tmp/supervisor.sock   ; UNIX socket 文件，supervisorctl 会使用</div><div class="line">;chmod=0700                 ; socket 文件的 mode，默认是 0700</div><div class="line">;chown=nobody:nogroup       ; socket 文件的 owner，格式： uid:gid</div><div class="line"> </div><div class="line">[inet_http_server]         ; HTTP 服务器，提供 web 管理界面</div><div class="line">port=127.0.0.1:9001        ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性</div><div class="line">username=user              ; 登录管理后台的用户名</div><div class="line">password=123               ; 登录管理后台的密码</div><div class="line"> </div><div class="line">[supervisord]</div><div class="line">logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log</div><div class="line">logfile_maxbytes=50MB        ; 日志文件大小，超出会 rotate，默认 50MB</div><div class="line">logfile_backups=10           ; 日志文件保留备份数量默认 10</div><div class="line">loglevel=info                ; 日志级别，默认 info，其它: debug,warn,trace</div><div class="line">pidfile=/tmp/supervisord.pid ; pid 文件</div><div class="line">nodaemon=false               ; 是否在前台启动，默认是 false，即以 daemon 的方式启动</div><div class="line">minfds=1024                  ; 可以打开的文件描述符的最小值，默认 1024</div><div class="line">minprocs=200                 ; 可以打开的进程数的最小值，默认 200</div><div class="line"> </div><div class="line">; the below section must remain in the config file for RPC</div><div class="line">; (supervisorctl/web interface) to work, additional interfaces may be</div><div class="line">; added by defining them in separate rpcinterface: sections</div><div class="line">[rpcinterface:supervisor]</div><div class="line">supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface</div><div class="line"> </div><div class="line">[supervisorctl]</div><div class="line">serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致</div><div class="line">;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord</div><div class="line"> </div><div class="line">; 包含其他的配置文件</div><div class="line">[include]</div><div class="line">files = /etc/supervisor/*.ini    ; 可以是 *.conf 或 *.ini</div></pre></td></tr></table></figure></p>
<h3 id="启动supervisor"><a href="#启动supervisor" class="headerlink" title="启动supervisor"></a>启动supervisor</h3><p>supervisord -c /etc/supervisord.conf<br>登录127.0.0.1:9001查看supervisor<br><img src="/images/201701/Supervisor_1.png"></p>
<h3 id="添加监控的脚本"><a href="#添加监控的脚本" class="headerlink" title="添加监控的脚本"></a>添加监控的脚本</h3><p>例如在vim /etc/supervisor/test.ini<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[program:<span class="built_in">test</span>]</div><div class="line">directory = /Users/liebaomac ; 程序的启动目录</div><div class="line"><span class="built_in">command</span> = python test.py ; 启动命令，可以看出与手动在命令行启动的命令是一样的</div><div class="line">autostart = <span class="literal">true</span>     ; 在 supervisord 启动的时候也自动启动</div><div class="line">startsecs = 5        ; 启动 5 秒后没有异常退出，就当作已经正常启动了</div><div class="line">autorestart = <span class="literal">true</span>   ; 程序异常退出后自动重启</div><div class="line">startretries = 3     ; 启动失败自动重试次数，默认是 3</div><div class="line">user = liebaomac          ; 用哪个用户启动</div><div class="line">redirect_stderr = <span class="literal">true</span>  ; 把 stderr 重定向到 stdout，默认 <span class="literal">false</span></div><div class="line">; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）</div><div class="line">stdout_logfile = /data/logs/test.log</div><div class="line">stdout_logfile_maxbytes = 20MB  ; stdout 日志文件大小，默认 50MB</div><div class="line">stdout_logfile_backups = 20     ; stdout 日志文件备份数</div></pre></td></tr></table></figure></p>
<p>vim /Users/liebaomac/test.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">"a"</span></div><div class="line"><span class="keyword">print</span> a</div></pre></td></tr></table></figure></p>
<h3 id="更新supervisor监控"><a href="#更新supervisor监控" class="headerlink" title="更新supervisor监控"></a>更新supervisor监控</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">supervisorctl update</div></pre></td></tr></table></figure>
<img src="/images/201701/Supervisor_2.png">
<p>日志如下图所示<br><img src="/images/201701/Supervisor_3.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/24/Spark性能调优简单总结/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/24/Spark性能调优简单总结/" itemprop="url">
                  Spark性能调优简单总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-24T14:00:44+08:00">
                2017-01-24
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="spark性能调优：初级-开发调优、资源调优-高级-数据倾斜调优、shuffle调优"><a href="#spark性能调优：初级-开发调优、资源调优-高级-数据倾斜调优、shuffle调优" class="headerlink" title="spark性能调优：初级(开发调优、资源调优) 高级(数据倾斜调优、shuffle调优)"></a>spark性能调优：初级(开发调优、资源调优) 高级(数据倾斜调优、shuffle调优)</h2><h3 id="开发调优"><a href="#开发调优" class="headerlink" title="开发调优"></a>开发调优</h3><p>RDD lineage设计、算子的合理使用、特殊操作的优化<br>原则一：避免创建重复的RDD<br>原则二：尽可能复用同一个RDD<br>原则三：对多次使用的RDD进行持久化<br>原则四：尽量避免使用shuffle类算子<br>原则五：使用map-side预聚合的shuffle操作 (reduceByKey优于groupByKey)<br>原则六：使用高性能的算子<br>    使用reduceByKey/aggregateByKey替代groupByKey<br>    使用mapPartitions替代普通map(mapPartitions单次函数调用就要处理掉一个partition所有的数据,很可能出现OOM异常)<br>    使用foreachPartitions替代foreach<br>    使用filter之后进行coalesce操作(重新分区，但是不用排序)<br>    使用repartitionAndSortWithinPartitions替代repartition与sort类操作<br>原则七：广播大变量(大变量存储转变 task-&gt;executor)<br>原则八：使用Kryo优化序列化性能<br>原则九：优化数据结构(内存使用  集合类型&gt;数组 对象&gt;字符串&gt;原始类型)</p>
<h3 id="资源调优"><a href="#资源调优" class="headerlink" title="资源调优"></a>资源调优</h3><p>num-executors = 总共要用多少个Executor进程来执行<br>executor-memory = 每个Executor进程的内存<br>executor-cores = 每个Executor进程的CPU core数量<br>driver-memory = Driver进程的内存<br>spark.default.parallelism = 每个stage的task数量(默认根据底层HDFS的block数量来设置task的数量,Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适)<br>spark.storage.memoryFraction = RDD持久化数据在Executor内存占比，默认是0.6<br>spark.shuffle.memoryFraction = shuffle过程在Executor内存占比，默认是0.2<br><img src="/images/201701/Spark_Performance_1.png"></p>
<h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><p>数据倾斜-&gt;shuffle key量大</p>
<h4 id="数据倾斜的原因"><a href="#数据倾斜的原因" class="headerlink" title="数据倾斜的原因"></a>数据倾斜的原因</h4><p>进行shuffle(操作有distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition)的时候，<br>必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，可能出现某一个key的量特别的大</p>
<h4 id="数据倾斜的定位"><a href="#数据倾斜的定位" class="headerlink" title="数据倾斜的定位"></a>数据倾斜的定位</h4><p>1、WebUI或者log日志可以告诉我们哪些个stage(task)运行的数据量大小<br>2、分析代码，重点看有shuffle操作关键代码，定位到具体造成倾斜的操作</p>
<h4 id="数据倾斜的解决方案"><a href="#数据倾斜的解决方案" class="headerlink" title="数据倾斜的解决方案"></a>数据倾斜的解决方案</h4><p>一：提高shuffle操作的并行度(最简单，但是解决不了某个key的量特别大，因为同一个key必须放到一个task下)<br>提高shuffle算子执行时shuffle read task的数量<br>1、对RDD执行shuffle算子时，给shuffle算子传入一个参数，设置reduceByKey(1000)<br>2、对于Spark SQL中的shuffle类语句，group by、join等，设置spark.sql.shuffle.partitions<br>二：使用Hive ETL预处理数据<br>对数据倾斜的数据进行清洗后，供spark程序使用<br>三：过滤少数导致倾斜的key<br>先通过sample算子对数据进行采样，计算每个key对应的数量，再用filter过滤掉这些key<br>四、两阶段聚合，局部聚合+全局聚合<br>适用场景：只对聚合类操作reduceByKey有效，对join操作无效<br>先局部聚合，先给每个key都打上一个随机数(比如10以内的随机数，目的是打散巨大的key)，再执行reduceByKey<br>再全局聚合，将各个key的前缀给去掉，再次进行全局聚合操作<br>五、将reduce join转为map join<br>适用场景：对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小<br>解决办法：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作<br>六：采样倾斜key并分拆join操作<br>适用场景：因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀<br>将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。<br>七：使用随机前缀和扩容RDD进行join<br>使用场景：如果在进行join操作时，RDD中有大量的key导致数据倾斜<br>和方案六差不多，只不过不拆分RDD了，对整体RDD进行扩容(对内存消耗很大)<br><img src="/images/201701/Spark_Performance_2.png"></p>
<h3 id="shuffle调优"><a href="#shuffle调优" class="headerlink" title="shuffle调优"></a>shuffle调优</h3><p>影响一个Spark作业性能的因素，主要还是代码开发、资源参数以 及数据倾斜 shuffle调优只能在整个Spark的性能调优中占到一小部分而已</p>
<p>以下是Shffule过程中的一些主要参数，这里详细讲解了各个参数的功能、默认值以及基于实践经验给出的调优建议。</p>
<p>spark.shuffle.file.buffer</p>
<ul>
<li>默认值：32k</li>
<li>参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>spark.reducer.maxSizeInFlight</p>
<ul>
<li>默认值：48m</li>
<li>参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>spark.shuffle.io.maxRetries</p>
<ul>
<li>默认值：3</li>
<li>参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取 还是没有成功，就可能会导致作业执行失败。</li>
<li>调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定 性。</li>
</ul>
<p>spark.shuffle.io.retryWait</p>
<ul>
<li>默认值：5s</li>
<li>参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。</li>
<li>调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</li>
</ul>
<p>spark.shuffle.memoryFraction</p>
<ul>
<li>默认值：0.2</li>
<li>参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。</li>
<li>调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升10%左右。</li>
</ul>
<p>spark.shuffle.manager</p>
<ul>
<li>默认值：sort</li>
<li>参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。tungsten-sort与sort类似，但是使用了tungsten计划中的 堆外内存管理机制，内存使用效率更高。</li>
<li>调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的 SortShuffleManager就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的 HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，tungsten-sort要慎用，因为之前发现了 一些相应的bug。</li>
</ul>
<p>spark.shuffle.sort.bypassMergeThreshold</p>
<ul>
<li>默认值：200</li>
<li>参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临 时磁盘文件都合并成一个文件，并会创建单独的索引文件。</li>
<li>调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁 盘文件，因此shuffle write性能有待提高。</li>
</ul>
<p>spark.shuffle.consolidateFiles</p>
<ul>
<li>默认值：false</li>
<li>参数说明：如果使用HashShuffleManager，该参数有效。如果设置为true，那么就会开启consolidate机制，会大幅度 合并shuffle write的输出文件，对于shuffle read task数量特别多的情况下，这种方法可以极大地减少磁盘IO开销，提升性能。</li>
<li>调优建议：如果的确不需要SortShuffleManager的排序机制，那么除了使用bypass机制，还可以尝试将 spark.shffle.manager参数手动指定为hash，使用HashShuffleManager，同时开启consolidate机制。在 实践中尝试过，发现其性能比开启了bypass机制的SortShuffleManager要高出10%~30%。</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/23/SparkSQL初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/23/SparkSQL初体验/" itemprop="url">
                  SparkSQL初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-23T13:57:04+08:00">
                2017-01-23
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkSQL输入源"><a href="#SparkSQL输入源" class="headerlink" title="SparkSQL输入源"></a>SparkSQL输入源</h2><p>Hive、Parquet、JSON、基于RDD(需要隐式转换)<br>因为还没有搭好Hive且没有使用过Parquet，下面主要将JSON和基于RDD的输入源<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</div><div class="line"><span class="comment">// Create the DataFrame (From JSON)</span></div><div class="line"><span class="keyword">val</span> df1 = sqlContext.read.json(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.json"</span>)</div><div class="line"></div><div class="line"><span class="comment">// Create the DataFrame (From RDD) 方法一</span></div><div class="line"><span class="comment">// 利用反射机制，推导包含某种类型的RDD，通过反射将其转换为指定类型的DataFrame，</span></div><div class="line"><span class="comment">// 适用于提前知道RDD的schema</span></div><div class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>) <span class="title">//放在main函数外面</span></span></div><div class="line"><span class="keyword">import</span> sqlContext.implicits._</div><div class="line"><span class="keyword">val</span> df2 = sc.textFile(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line">    .map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Person</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim.toInt)).toDF()</div><div class="line"></div><div class="line"><span class="comment">// Create the DataFrame (From RDD) 方法二</span></div><div class="line"><span class="comment">// 当case class不能提前定义好时，通过编程接口与RDD进行交互获取schema，</span></div><div class="line"><span class="comment">// 并动态创建DataFrame，在运行时决定列及其类型。</span></div><div class="line"><span class="keyword">val</span> people = sc.textFile(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line"><span class="keyword">val</span> schemaString = <span class="string">"name age"</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span>;</div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>,<span class="type">StructField</span>,<span class="type">StringType</span>&#125;;</div><div class="line"><span class="keyword">val</span> schema =</div><div class="line">  <span class="type">StructType</span>(schemaString.split(<span class="string">" "</span>).map(fieldName =&gt; <span class="type">StructField</span>(fieldName,</div><div class="line">  <span class="type">StringType</span>, <span class="literal">true</span>))) <span class="comment">//基于structType类型创建schema</span></div><div class="line"><span class="keyword">val</span> rowRDD = people.map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Row</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim)) <span class="comment">//与创建的RDD相匹配</span></div><div class="line"><span class="comment">// 通过SQLContext的createDataFrame方法对rowRDD应用schema</span></div><div class="line"><span class="keyword">val</span> df3 = sqlContext.createDataFrame(rowRDD, schema)</div></pre></td></tr></table></figure></p>
<p>上面代码df1、df2、df3都是DataFrame类型</p>
<p>DataFrame类型的一些常见的api操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Show the content of the DataFrame</span></div><div class="line">df.show()</div><div class="line"></div><div class="line"><span class="comment">// Print the schema in a tree format</span></div><div class="line">df.printSchema()</div><div class="line"></div><div class="line"><span class="comment">// Select only the "name" column</span></div><div class="line">df.select(<span class="string">"name"</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Select everybody, but increment the age by 1</span></div><div class="line">df.select(df(<span class="string">"name"</span>), df(<span class="string">"age"</span>) + <span class="number">1</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Select people older than 21</span></div><div class="line">df.filter(df(<span class="string">"age"</span>) &gt; <span class="number">21</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Count people by age</span></div><div class="line">df.groupBy(<span class="string">"age"</span>).count().show()</div></pre></td></tr></table></figure></p>
<p>下面是简单的sql操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 注册输入的DataFrame</span></div><div class="line">df2.registerTempTable(<span class="string">"people"</span>)</div><div class="line"></div><div class="line"><span class="comment">// SQL statements can be run by using the sql methods provided by sqlContext.</span></div><div class="line"><span class="keyword">val</span> teenagers = sqlContext.sql(<span class="string">"SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19"</span>)</div><div class="line"></div><div class="line"><span class="comment">// The results of SQL queries are DataFrames and support all the normal RDD operations.</span></div><div class="line"><span class="comment">// The columns of a row in the result can be accessed by field index:</span></div><div class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t(<span class="number">0</span>)).collect().foreach(println)</div><div class="line"></div><div class="line"><span class="comment">// or by field name:</span></div><div class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t.getAs[<span class="type">String</span>](<span class="string">"name"</span>)).collect().foreach(println)</div><div class="line"></div><div class="line"><span class="comment">// row.getValuesMap[T] retrieves multiple columns at once into a Map[String, T]</span></div><div class="line">teenagers.map(_.getValuesMap[<span class="type">Any</span>](<span class="type">List</span>(<span class="string">"name"</span>, <span class="string">"age"</span>))).collect().foreach(println)</div></pre></td></tr></table></figure></p>
<p>测试数据:<br>spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Michael, 29</div><div class="line">Andy, 30</div><div class="line">Justin, 19</div></pre></td></tr></table></figure></p>
<p>测试结果如图：<br><img src="/images/201701/SparkSql_1.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/22/SparkStreaming初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/22/SparkStreaming初体验/" itemprop="url">
                  SparkStreaming初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-22T15:53:39+08:00">
                2017-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkStreaming简单介绍"><a href="#SparkStreaming简单介绍" class="headerlink" title="SparkStreaming简单介绍"></a>SparkStreaming简单介绍</h2><p>Spark Streaming是建立在Spark上的实时计算框架<br>输入和输出概览：<br><img src="/images/201701/SparkStreaming_1.png"><br>Spark Streaming把实时输入数据流以时间片(如1秒)为单位切分成块。SparkStreaming会把每块数据作为一个RDD，并使用RDD操作处理每一小块数据<br><img src="/images/201701/SparkStreaming_2.png"></p>
<h2 id="例子-从kafka输入源-读取数据后-直接输出"><a href="#例子-从kafka输入源-读取数据后-直接输出" class="headerlink" title="例子:从kafka输入源 读取数据后 直接输出"></a>例子:从kafka输入源 读取数据后 直接输出</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</div><div class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">process_58_data</span> </span>&#123;</div><div class="line">  <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">ERROR</span>)</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> masterUrl = <span class="string">"local[2]"</span> <span class="comment">//不能local，需要两个核以上</span></div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(masterUrl).setAppName(<span class="string">"58_data"</span>)</div><div class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</div><div class="line">    <span class="keyword">val</span> topics = <span class="type">Set</span>(<span class="string">"58_data"</span>) <span class="comment">//kafka的topic</span></div><div class="line">    <span class="keyword">val</span> brokers = <span class="string">"master:9092,worker1:9092,worker2:9092"</span> <span class="comment">//kafka端口</span></div><div class="line">    <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">"metadata.broker.list"</span> -&gt; brokers)</div><div class="line">    <span class="keyword">val</span> kafkaStream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](ssc, kafkaParams, topics) <span class="comment">//调用Kafka工具包创建DSteam</span></div><div class="line">    kafkaStream.foreachRDD(rdd =&gt;&#123;</div><div class="line">      rdd.foreachPartition(iter =&gt; &#123;</div><div class="line">        iter.foreach( x =&gt;</div><div class="line">          println(x._2)</div><div class="line">        )</div><div class="line">      &#125;)</div><div class="line">    &#125;)</div><div class="line">    ssc.start() <span class="comment">//启动流计算环境StreamingContext</span></div><div class="line">    ssc.awaitTermination() <span class="comment">//等待作业完成</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之前写过简单的爬虫用来抓取网页信息，将数据放入kafka中，配合SparkStreaming，最后输出结果如下:<br><img src="/images/201701/SparkStreaming_3.png"></p>
<h2 id="SparkStreaming中DSteam转化操作"><a href="#SparkStreaming中DSteam转化操作" class="headerlink" title="SparkStreaming中DSteam转化操作"></a>SparkStreaming中DSteam转化操作</h2><h3 id="无状态："><a href="#无状态：" class="headerlink" title="无状态："></a>无状态：</h3><p>SparkStreaming是建立在Spark，所以很多RDD转化操作都适用于Dsteam.<br>例如: map, flatMap, filter, repartition, join, reduceByKey<br>(注: 针对键值对的Dsteam转化操作需要import StreamingContext._)</p>
<h3 id="有状态-SparkStreaming特有的操作-："><a href="#有状态-SparkStreaming特有的操作-：" class="headerlink" title="有状态(SparkStreaming特有的操作)："></a>有状态(SparkStreaming特有的操作)：</h3><p>滑动窗口和updateStateByKey<br>滑动窗口使用详情可以参考：<a href="http://blog.csdn.net/legotime/article/details/51836040" target="_blank" rel="external">http://blog.csdn.net/legotime/article/details/51836040</a></p>
<p>参考文档：<br><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a><br>《Spark快速大数据分析》</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/21/spark机器学习初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/21/spark机器学习初体验/" itemprop="url">
                  spark机器学习初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-21T18:19:48+08:00">
                2017-01-21
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="垃圾邮件分类例子"><a href="#垃圾邮件分类例子" class="headerlink" title="垃圾邮件分类例子"></a>垃圾邮件分类例子</h2><h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><p>垃圾邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">spam.txt</div><div class="line">Dear sir, I am a Prince in a far kingdom you have not heard of.  I want to send you money via wire transfer so please ...</div><div class="line">Get Viagra real cheap!  Send money right away to ...</div><div class="line">Oh my gosh you can be really strong too with these drugs found in the rainforest. Get them cheap right now ...</div><div class="line">YOUR COMPUTER HAS BEEN INFECTED!  YOU MUST RESET YOUR PASSWORD.  Reply to this email with your password and SSN ...</div><div class="line">THIS IS NOT A SCAM!  Send money and get access to awesome stuff really cheap and never have to ...</div></pre></td></tr></table></figure></p>
<p>正常邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ham.txt</div><div class="line">Dear Spark Learner, Thanks so much for attending the Spark Summit 2014!  Check out videos of talks from the summit at ...</div><div class="line">Hi Mom, Apologies for being late about emailing and forgetting to send you the package.  I hope you and bro have been ...</div><div class="line">Wow, hey Fred, just heard about the Spark petabyte sort.  I think we need to take time to try it out immediately ...</div><div class="line">Hi Spark user list, This is my first question to this list, so thanks in advance for your help!  I tried running ...</div><div class="line">Thanks Tom for your email.  I need to refer you to Alice for this one.  I haven&apos;t yet figured out that part either ...</div><div class="line">Good job yesterday!  I was attending your talk, and really enjoyed it.  I want to try out GraphX ...</div><div class="line">Summit demo got whoops from audience!  Had to let you know. --Joe</div></pre></td></tr></table></figure></p>
<h3 id="Scala代码"><a href="#Scala代码" class="headerlink" title="Scala代码"></a>Scala代码</h3><p>这个程序使用了MLlib两个函数：HashingTF(从文本数据构建 词频特征向量)和LogisticRegressionWithSGD(随机体度下降法实现逻辑回归)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.<span class="type">LogisticRegressionWithSGD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.feature.<span class="type">HashingTF</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">MLlib</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">s"Book example: Scala"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line"></div><div class="line">    <span class="comment">// Load 2 types of emails from text files: spam and ham (non-spam).</span></div><div class="line">    <span class="comment">// Each line has text from one email.</span></div><div class="line">    <span class="keyword">val</span> spam = sc.textFile(<span class="string">"files/spam.txt"</span>)</div><div class="line">    <span class="keyword">val</span> ham = sc.textFile(<span class="string">"files/ham.txt"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Create a HashingTF instance to map email text to vectors of 100 features.</span></div><div class="line">    <span class="keyword">val</span> tf = <span class="keyword">new</span> <span class="type">HashingTF</span>(numFeatures = <span class="number">100</span>)</div><div class="line">    <span class="comment">// Each email is split into words, and each word is mapped to one feature.</span></div><div class="line">    <span class="comment">// 1、特征提取</span></div><div class="line">    <span class="keyword">val</span> spamFeatures = spam.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line">    <span class="keyword">val</span> hamFeatures = ham.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line"></div><div class="line">    <span class="comment">// Create LabeledPoint datasets for positive (spam) and negative (ham) examples.</span></div><div class="line">    <span class="comment">// 2、将文本数据转换为数值特征，返回LabeledPoint类型RDD(包含一个特质向量和一个标签)</span></div><div class="line">    <span class="keyword">val</span> positiveExamples = spamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">1</span>, features))</div><div class="line">    <span class="keyword">val</span> negativeExamples = hamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">0</span>, features))</div><div class="line">    <span class="keyword">val</span> trainingData = positiveExamples ++ negativeExamples</div><div class="line">    trainingData.cache() <span class="comment">// Cache data since Logistic Regression is an iterative algorithm.</span></div><div class="line"></div><div class="line">    <span class="comment">// Create a Logistic Regression learner which uses the LBFGS optimizer.</span></div><div class="line">    <span class="comment">// 3、调用分类算法，返回模型对象</span></div><div class="line">    <span class="keyword">val</span> lrLearner = <span class="keyword">new</span> <span class="type">LogisticRegressionWithSGD</span>()</div><div class="line">    <span class="comment">// Run the actual learning algorithm on the training data.</span></div><div class="line">    <span class="keyword">val</span> model = lrLearner.run(trainingData)</div><div class="line"></div><div class="line">    <span class="comment">// Test on a positive example (spam) and a negative one (ham).</span></div><div class="line">    <span class="comment">// First apply the same HashingTF feature transformation used on the training data.</span></div><div class="line">    <span class="keyword">val</span> posTestExample = tf.transform(<span class="string">"O M G GET cheap stuff by sending money to ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="keyword">val</span> negTestExample = tf.transform(<span class="string">"Hi Dad, I started studying Spark the other ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="comment">// Now use the learned model to predict spam/ham for new emails.</span></div><div class="line">    println(<span class="string">s"Prediction for positive test example: <span class="subst">$&#123;model.predict(posTestExample)&#125;</span>"</span>)</div><div class="line">    println(<span class="string">s"Prediction for negative test example: <span class="subst">$&#123;model.predict(negTestExample)&#125;</span>"</span>)</div><div class="line"></div><div class="line">    sc.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>运行结果如果所示：<br><img src="/images/201701/SparkML_1.png"></p>
<h2 id="机器学习流水线中典型步骤"><a href="#机器学习流水线中典型步骤" class="headerlink" title="机器学习流水线中典型步骤"></a>机器学习流水线中典型步骤</h2><p>源数据ETL-&gt;数据预处理-&gt;特征提取(返回MLlib的数据类型，比如上例的LabeledPoint类型)-&gt;训练(返回模型)-&gt;模型评估</p>
<h2 id="简单理解"><a href="#简单理解" class="headerlink" title="简单理解"></a>简单理解</h2><p>确定模型—-训练模型—-使用模型<br>模型简单说可以理解为函数。<br>确定模型是说自己认为这些数据的特征符合哪个函数(应该使用什么模型)<br>训练模型就是用已有的数据，通过一些方法（最优化或者其他方法）确定函数的参数，参数确定后的函数就是训练的结果<br>使用模型就是把新的数据代入函数求值</p>
<p>参考文档：<br>《Spark快速大数据分析》<br><a href="https://www.zhihu.com/question/29271217?sort=created" target="_blank" rel="external">https://www.zhihu.com/question/29271217?sort=created</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="xiwu1212@163.com" />
          <p class="site-author-name" itemprop="name">xiwu1212@163.com</p>
          <p class="site-description motion-element" itemprop="description">学无止境</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">29</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiwu1212@163.com</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  




  
  

  

  

  

  


</body>
</html>
