<!doctype html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="Refrain">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Refrain">
<meta property="og:description" content="学无止境">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Refrain">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title> Refrain </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Refrain</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/04/数据库简单总结/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/04/数据库简单总结/" itemprop="url">
                  关系型数据库和非关系型数据库简单总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-04T13:24:03+08:00">
                2017-02-04
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h2><h3 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h3><p>关系型数据库，采用了关系模型来组织数据的数据库。<br>关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>容易理解：二维表结构是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型来说更容易理解<br>使用方便：通用的SQL语言使得操作关系型数据库非常方便<br>易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率</p>
<h3 id="非关系型数据库"><a href="#非关系型数据库" class="headerlink" title="非关系型数据库"></a>非关系型数据库</h3><p>非关系型数据库产品是传统关系型数据库的功能阉割版本(去除ACID)，通过减少用不到或很少用的功能，来大幅度提高产品性能。</p>
<h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><p>以下的这几种情况下比较适用：<br>1、数据模型比较简单<br>2、需要灵活性更强的IT系统<br>3、对数据库性能要求较高<br>4、不需要高度的数据一致性<br>5、对于给定key，比较容易映射复杂值的环境</p>
<h4 id="常见的Nosql"><a href="#常见的Nosql" class="headerlink" title="常见的Nosql"></a>常见的Nosql</h4><p>高性能并发读写的key-value数据库:Redis,Tokyo<br>列存储数据库:HBase,Cassandra<br>文档型数据库:MongoDB,CouchDB<br>图形(Graph)数据库:Neo4J, InfoGrid</p>
<h2 id="主要优势"><a href="#主要优势" class="headerlink" title="主要优势"></a>主要优势</h2><p>非关系型数据库:操作的扩展性和大数据量处理<br>关系型数据库:事务的一致性(安全性能高)和复杂SQL查询</p>
<h2 id="分布式一些比较"><a href="#分布式一些比较" class="headerlink" title="分布式一些比较"></a>分布式一些比较</h2><img src="/images/201702/database_1.png">

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/28/c/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/28/c/" itemprop="url">
                  c
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-28T21:31:55+08:00">
                2017-01-28
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/27/大数据面试总结-1/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/27/大数据面试总结-1/" itemprop="url">
                  大数据面试总结-1
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-27T22:36:35+08:00">
                2017-01-27
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Spark比Hadoop快的原因"><a href="#Spark比Hadoop快的原因" class="headerlink" title="Spark比Hadoop快的原因"></a>Spark比Hadoop快的原因</h2><h3 id="一、shuffle后中间结果可以存入内存而不是直接写入到disk"><a href="#一、shuffle后中间结果可以存入内存而不是直接写入到disk" class="headerlink" title="一、shuffle后中间结果可以存入内存而不是直接写入到disk"></a>一、shuffle后中间结果可以存入内存而不是直接写入到disk</h3><h3 id="二、减少shuffle阶段，因为DAG的优化-（待深入）"><a href="#二、减少shuffle阶段，因为DAG的优化-（待深入）" class="headerlink" title="二、减少shuffle阶段，因为DAG的优化..（待深入）"></a>二、减少shuffle阶段，因为DAG的优化..（待深入）</h3><h2 id="Spark通过yarn提交任务时，Yarn-client和Yarn-cluster的区别"><a href="#Spark通过yarn提交任务时，Yarn-client和Yarn-cluster的区别" class="headerlink" title="Spark通过yarn提交任务时，Yarn-client和Yarn-cluster的区别"></a>Spark通过yarn提交任务时，Yarn-client和Yarn-cluster的区别</h2><p>1、Yarn-cluster—生产环境，Yarn-client—交互和调试<br>2、Yarn-cluster模式,Driver运行在AM(Application Master)中，它负责向Yarn申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在Yarn上运行。<br>Yarn-client模式,AM仅仅向Yarn请求executor,client会和请求的container通信来调度他们的工作<br>yarn-cluster:<br><img src="/images/201702/yarn-cluster.png"><br>yarn-client:<br><img src="/images/201702/yarn-client.png"></p>
<h2 id="MapReduce调优"><a href="#MapReduce调优" class="headerlink" title="MapReduce调优"></a>MapReduce调优</h2><h3 id="管理员"><a href="#管理员" class="headerlink" title="管理员"></a>管理员</h3><h4 id="JVM参数调优"><a href="#JVM参数调优" class="headerlink" title="JVM参数调优"></a>JVM参数调优</h4><p>通过调整JVM FLAGS和JVM垃圾回收机制提高Hadoop性能</p>
<h4 id="Hadoop参数调优"><a href="#Hadoop参数调优" class="headerlink" title="Hadoop参数调优"></a>Hadoop参数调优</h4><p>合理规划资源，调整心跳配置，磁盘块配置(I/O密集型，增加磁盘块)，启用批量任务调度，选择合适的压缩算法，启用预读取机制</p>
<h3 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h3><h4 id="应用程序编写规范"><a href="#应用程序编写规范" class="headerlink" title="应用程序编写规范"></a>应用程序编写规范</h4><p>1、设置Combiner(对于大批MR程序)<br>2、选择合理的Writable类型</p>
<h4 id="作业级别参数调优"><a href="#作业级别参数调优" class="headerlink" title="作业级别参数调优"></a>作业级别参数调优</h4><p>规划合理的任务数目，增加文件副本数，启用推测执行机制，适当打开JVM重用功能，设置任务超时时间</p>
<h4 id="任务级别参数调优"><a href="#任务级别参数调优" class="headerlink" title="任务级别参数调优"></a>任务级别参数调优</h4><p>Map Task调优, Reduce Task调优</p>
<h2 id="Hive调优"><a href="#Hive调优" class="headerlink" title="Hive调优"></a>Hive调优</h2><h3 id="配置角度优化"><a href="#配置角度优化" class="headerlink" title="配置角度优化"></a>配置角度优化</h3><p>列裁剪, 分区裁剪, join(小表放前), group by(Map端部分聚合,负载均衡), 合并小文件<br>reduce的内存和数量配置</p>
<h3 id="程序角度优化"><a href="#程序角度优化" class="headerlink" title="程序角度优化"></a>程序角度优化</h3><p>GROUP BY替代COUNT(DISTINCT), 不同数据类型关联产生的倾斜问题, 无效ID在关联时的数据倾斜问题</p>
<p>转载:<br><a href="http://jaydenwang.blog.51cto.com/6033165/1845247" target="_blank" rel="external">http://jaydenwang.blog.51cto.com/6033165/1845247</a><br><a href="http://www.cnblogs.com/smartloli/p/4356660.html" target="_blank" rel="external">http://www.cnblogs.com/smartloli/p/4356660.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/26/Spark运行框架/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/26/Spark运行框架/" itemprop="url">
                  Spark运行框架
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-26T12:00:43+08:00">
                2017-01-26
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Spark官网展示了如下的集群运行架构"><a href="#Spark官网展示了如下的集群运行架构" class="headerlink" title="Spark官网展示了如下的集群运行架构"></a>Spark官网展示了如下的集群运行架构</h3><img src="/images/201701/Spark_Frame_1.png">
<h3 id="Spark-Standalone-Client-Mode-运行流程示意图"><a href="#Spark-Standalone-Client-Mode-运行流程示意图" class="headerlink" title="Spark Standalone Client Mode 运行流程示意图"></a>Spark Standalone Client Mode 运行流程示意图</h3><img src="/images/201701/Spark_Frame_2.png">
<h3 id="Spark-YARN-Cluster-Mode-运行流程示意图"><a href="#Spark-YARN-Cluster-Mode-运行流程示意图" class="headerlink" title="Spark YARN Cluster Mode 运行流程示意图"></a>Spark YARN Cluster Mode 运行流程示意图</h3><img src="/images/201701/Spark_Frame_3.png">
<p>转载: <a href="http://blog.csdn.net/bigdata_wang/article/details/48245581" target="_blank" rel="external">http://blog.csdn.net/bigdata_wang/article/details/48245581</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/25/supervisor使用/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/25/supervisor使用/" itemprop="url">
                  Supervisor简单使用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-25T15:52:23+08:00">
                2017-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="下载安装Supervisor"><a href="#下载安装Supervisor" class="headerlink" title="下载安装Supervisor"></a>下载安装Supervisor</h3><p>pip install supervisor<br>如果在命令行中输入echo_supervisord_conf没有找到命令，那么需要在环境变量PATH添加Python的bin目录路径</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>echo_supervisord_conf &gt; /etc/supervisord.conf<br>vim /etc/supervisord.conf<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">[unix_http_server]</div><div class="line">file=/tmp/supervisor.sock   ; UNIX socket 文件，supervisorctl 会使用</div><div class="line">;chmod=0700                 ; socket 文件的 mode，默认是 0700</div><div class="line">;chown=nobody:nogroup       ; socket 文件的 owner，格式： uid:gid</div><div class="line"> </div><div class="line">[inet_http_server]         ; HTTP 服务器，提供 web 管理界面</div><div class="line">port=127.0.0.1:9001        ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性</div><div class="line">username=user              ; 登录管理后台的用户名</div><div class="line">password=123               ; 登录管理后台的密码</div><div class="line"> </div><div class="line">[supervisord]</div><div class="line">logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log</div><div class="line">logfile_maxbytes=50MB        ; 日志文件大小，超出会 rotate，默认 50MB</div><div class="line">logfile_backups=10           ; 日志文件保留备份数量默认 10</div><div class="line">loglevel=info                ; 日志级别，默认 info，其它: debug,warn,trace</div><div class="line">pidfile=/tmp/supervisord.pid ; pid 文件</div><div class="line">nodaemon=false               ; 是否在前台启动，默认是 false，即以 daemon 的方式启动</div><div class="line">minfds=1024                  ; 可以打开的文件描述符的最小值，默认 1024</div><div class="line">minprocs=200                 ; 可以打开的进程数的最小值，默认 200</div><div class="line"> </div><div class="line">; the below section must remain in the config file for RPC</div><div class="line">; (supervisorctl/web interface) to work, additional interfaces may be</div><div class="line">; added by defining them in separate rpcinterface: sections</div><div class="line">[rpcinterface:supervisor]</div><div class="line">supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface</div><div class="line"> </div><div class="line">[supervisorctl]</div><div class="line">serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致</div><div class="line">;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord</div><div class="line"> </div><div class="line">; 包含其他的配置文件</div><div class="line">[include]</div><div class="line">files = /etc/supervisor/*.ini    ; 可以是 *.conf 或 *.ini</div></pre></td></tr></table></figure></p>
<h3 id="启动supervisor"><a href="#启动supervisor" class="headerlink" title="启动supervisor"></a>启动supervisor</h3><p>supervisord -c /etc/supervisord.conf<br>登录127.0.0.1:9001查看supervisor<br><img src="/images/201701/Supervisor_1.png"></p>
<h3 id="添加监控的脚本"><a href="#添加监控的脚本" class="headerlink" title="添加监控的脚本"></a>添加监控的脚本</h3><p>例如在vim /etc/supervisor/test.ini<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[program:<span class="built_in">test</span>]</div><div class="line">directory = /Users/liebaomac ; 程序的启动目录</div><div class="line"><span class="built_in">command</span> = python test.py ; 启动命令，可以看出与手动在命令行启动的命令是一样的</div><div class="line">autostart = <span class="literal">true</span>     ; 在 supervisord 启动的时候也自动启动</div><div class="line">startsecs = 5        ; 启动 5 秒后没有异常退出，就当作已经正常启动了</div><div class="line">autorestart = <span class="literal">true</span>   ; 程序异常退出后自动重启</div><div class="line">startretries = 3     ; 启动失败自动重试次数，默认是 3</div><div class="line">user = liebaomac          ; 用哪个用户启动</div><div class="line">redirect_stderr = <span class="literal">true</span>  ; 把 stderr 重定向到 stdout，默认 <span class="literal">false</span></div><div class="line">; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）</div><div class="line">stdout_logfile = /data/logs/test.log</div><div class="line">stdout_logfile_maxbytes = 20MB  ; stdout 日志文件大小，默认 50MB</div><div class="line">stdout_logfile_backups = 20     ; stdout 日志文件备份数</div></pre></td></tr></table></figure></p>
<p>vim /Users/liebaomac/test.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">"a"</span></div><div class="line"><span class="keyword">print</span> a</div></pre></td></tr></table></figure></p>
<h3 id="更新supervisor监控"><a href="#更新supervisor监控" class="headerlink" title="更新supervisor监控"></a>更新supervisor监控</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">supervisorctl update</div></pre></td></tr></table></figure>
<img src="/images/201701/Supervisor_2.png">
<p>日志如下图所示<br><img src="/images/201701/Supervisor_3.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/24/Spark性能调优简单总结/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/24/Spark性能调优简单总结/" itemprop="url">
                  Spark性能调优简单总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-24T14:00:44+08:00">
                2017-01-24
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="spark性能调优：初级-开发调优、资源调优-高级-数据倾斜调优、shuffle调优"><a href="#spark性能调优：初级-开发调优、资源调优-高级-数据倾斜调优、shuffle调优" class="headerlink" title="spark性能调优：初级(开发调优、资源调优) 高级(数据倾斜调优、shuffle调优)"></a>spark性能调优：初级(开发调优、资源调优) 高级(数据倾斜调优、shuffle调优)</h2><h3 id="开发调优"><a href="#开发调优" class="headerlink" title="开发调优"></a>开发调优</h3><p>RDD lineage设计、算子的合理使用、特殊操作的优化<br>原则一：避免创建重复的RDD<br>原则二：尽可能复用同一个RDD<br>原则三：对多次使用的RDD进行持久化<br>原则四：尽量避免使用shuffle类算子<br>原则五：使用map-side预聚合的shuffle操作 (reduceByKey优于groupByKey)<br>原则六：使用高性能的算子<br>    使用reduceByKey/aggregateByKey替代groupByKey<br>    使用mapPartitions替代普通map(mapPartitions单次函数调用就要处理掉一个partition所有的数据,很可能出现OOM异常)<br>    使用foreachPartitions替代foreach<br>    使用filter之后进行coalesce操作(重新分区，但是不用排序)<br>    使用repartitionAndSortWithinPartitions替代repartition与sort类操作<br>原则七：广播大变量(大变量存储转变 task-&gt;executor)<br>原则八：使用Kryo优化序列化性能<br>原则九：优化数据结构(内存使用  集合类型&gt;数组 对象&gt;字符串&gt;原始类型)</p>
<h3 id="资源调优"><a href="#资源调优" class="headerlink" title="资源调优"></a>资源调优</h3><p>num-executors = 总共要用多少个Executor进程来执行<br>executor-memory = 每个Executor进程的内存<br>executor-cores = 每个Executor进程的CPU core数量<br>driver-memory = Driver进程的内存<br>spark.default.parallelism = 每个stage的task数量(默认根据底层HDFS的block数量来设置task的数量,Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适)<br>spark.storage.memoryFraction = RDD持久化数据在Executor内存占比，默认是0.6<br>spark.shuffle.memoryFraction = shuffle过程在Executor内存占比，默认是0.2<br><img src="/images/201701/Spark_Performance_1.png"></p>
<h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><p>数据倾斜-&gt;shuffle key量大</p>
<h4 id="数据倾斜的原因"><a href="#数据倾斜的原因" class="headerlink" title="数据倾斜的原因"></a>数据倾斜的原因</h4><p>进行shuffle(操作有distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition)的时候，<br>必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，可能出现某一个key的量特别的大</p>
<h4 id="数据倾斜的定位"><a href="#数据倾斜的定位" class="headerlink" title="数据倾斜的定位"></a>数据倾斜的定位</h4><p>1、WebUI或者log日志可以告诉我们哪些个stage(task)运行的数据量大小<br>2、分析代码，重点看有shuffle操作关键代码，定位到具体造成倾斜的操作</p>
<h4 id="数据倾斜的解决方案"><a href="#数据倾斜的解决方案" class="headerlink" title="数据倾斜的解决方案"></a>数据倾斜的解决方案</h4><p>一：提高shuffle操作的并行度(最简单，但是解决不了某个key的量特别大，因为同一个key必须放到一个task下)<br>提高shuffle算子执行时shuffle read task的数量<br>1、对RDD执行shuffle算子时，给shuffle算子传入一个参数，设置reduceByKey(1000)<br>2、对于Spark SQL中的shuffle类语句，group by、join等，设置spark.sql.shuffle.partitions<br>二：使用Hive ETL预处理数据<br>对数据倾斜的数据进行清洗后，供spark程序使用<br>三：过滤少数导致倾斜的key<br>先通过sample算子对数据进行采样，计算每个key对应的数量，再用filter过滤掉这些key<br>四、两阶段聚合，局部聚合+全局聚合<br>适用场景：只对聚合类操作reduceByKey有效，对join操作无效<br>先局部聚合，先给每个key都打上一个随机数(比如10以内的随机数，目的是打散巨大的key)，再执行reduceByKey<br>再全局聚合，将各个key的前缀给去掉，再次进行全局聚合操作<br>五、将reduce join转为map join<br>适用场景：对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小<br>解决办法：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作<br>六：采样倾斜key并分拆join操作<br>适用场景：因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀<br>将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。<br>七：使用随机前缀和扩容RDD进行join<br>使用场景：如果在进行join操作时，RDD中有大量的key导致数据倾斜<br>和方案六差不多，只不过不拆分RDD了，对整体RDD进行扩容(对内存消耗很大)<br><img src="/images/201701/Spark_Performance_2.png"></p>
<h3 id="shuffle调优"><a href="#shuffle调优" class="headerlink" title="shuffle调优"></a>shuffle调优</h3><p>影响一个Spark作业性能的因素，主要还是代码开发、资源参数以 及数据倾斜 shuffle调优只能在整个Spark的性能调优中占到一小部分而已</p>
<p>以下是Shffule过程中的一些主要参数，这里详细讲解了各个参数的功能、默认值以及基于实践经验给出的调优建议。</p>
<p>spark.shuffle.file.buffer</p>
<ul>
<li>默认值：32k</li>
<li>参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>spark.reducer.maxSizeInFlight</p>
<ul>
<li>默认值：48m</li>
<li>参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>spark.shuffle.io.maxRetries</p>
<ul>
<li>默认值：3</li>
<li>参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取 还是没有成功，就可能会导致作业执行失败。</li>
<li>调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定 性。</li>
</ul>
<p>spark.shuffle.io.retryWait</p>
<ul>
<li>默认值：5s</li>
<li>参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。</li>
<li>调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</li>
</ul>
<p>spark.shuffle.memoryFraction</p>
<ul>
<li>默认值：0.2</li>
<li>参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。</li>
<li>调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升10%左右。</li>
</ul>
<p>spark.shuffle.manager</p>
<ul>
<li>默认值：sort</li>
<li>参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。tungsten-sort与sort类似，但是使用了tungsten计划中的 堆外内存管理机制，内存使用效率更高。</li>
<li>调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的 SortShuffleManager就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的 HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，tungsten-sort要慎用，因为之前发现了 一些相应的bug。</li>
</ul>
<p>spark.shuffle.sort.bypassMergeThreshold</p>
<ul>
<li>默认值：200</li>
<li>参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临 时磁盘文件都合并成一个文件，并会创建单独的索引文件。</li>
<li>调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁 盘文件，因此shuffle write性能有待提高。</li>
</ul>
<p>spark.shuffle.consolidateFiles</p>
<ul>
<li>默认值：false</li>
<li>参数说明：如果使用HashShuffleManager，该参数有效。如果设置为true，那么就会开启consolidate机制，会大幅度 合并shuffle write的输出文件，对于shuffle read task数量特别多的情况下，这种方法可以极大地减少磁盘IO开销，提升性能。</li>
<li>调优建议：如果的确不需要SortShuffleManager的排序机制，那么除了使用bypass机制，还可以尝试将 spark.shffle.manager参数手动指定为hash，使用HashShuffleManager，同时开启consolidate机制。在 实践中尝试过，发现其性能比开启了bypass机制的SortShuffleManager要高出10%~30%。</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/23/SparkSQL初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/23/SparkSQL初体验/" itemprop="url">
                  SparkSQL初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-23T13:57:04+08:00">
                2017-01-23
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkSQL输入源"><a href="#SparkSQL输入源" class="headerlink" title="SparkSQL输入源"></a>SparkSQL输入源</h2><p>Hive、Parquet、JSON、基于RDD(需要隐式转换)<br>因为还没有搭好Hive且没有使用过Parquet，下面主要将JSON和基于RDD的输入源<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</div><div class="line"><span class="comment">// Create the DataFrame (From JSON)</span></div><div class="line"><span class="keyword">val</span> df1 = sqlContext.read.json(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.json"</span>)</div><div class="line"></div><div class="line"><span class="comment">// Create the DataFrame (From RDD) 方法一</span></div><div class="line"><span class="comment">// 利用反射机制，推导包含某种类型的RDD，通过反射将其转换为指定类型的DataFrame，</span></div><div class="line"><span class="comment">// 适用于提前知道RDD的schema</span></div><div class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>) <span class="title">//放在main函数外面</span></span></div><div class="line"><span class="keyword">import</span> sqlContext.implicits._</div><div class="line"><span class="keyword">val</span> df2 = sc.textFile(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line">    .map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Person</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim.toInt)).toDF()</div><div class="line"></div><div class="line"><span class="comment">// Create the DataFrame (From RDD) 方法二</span></div><div class="line"><span class="comment">// 当case class不能提前定义好时，通过编程接口与RDD进行交互获取schema，</span></div><div class="line"><span class="comment">// 并动态创建DataFrame，在运行时决定列及其类型。</span></div><div class="line"><span class="keyword">val</span> people = sc.textFile(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line"><span class="keyword">val</span> schemaString = <span class="string">"name age"</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span>;</div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>,<span class="type">StructField</span>,<span class="type">StringType</span>&#125;;</div><div class="line"><span class="keyword">val</span> schema =</div><div class="line">  <span class="type">StructType</span>(schemaString.split(<span class="string">" "</span>).map(fieldName =&gt; <span class="type">StructField</span>(fieldName,</div><div class="line">  <span class="type">StringType</span>, <span class="literal">true</span>))) <span class="comment">//基于structType类型创建schema</span></div><div class="line"><span class="keyword">val</span> rowRDD = people.map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Row</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim)) <span class="comment">//与创建的RDD相匹配</span></div><div class="line"><span class="comment">// 通过SQLContext的createDataFrame方法对rowRDD应用schema</span></div><div class="line"><span class="keyword">val</span> df3 = sqlContext.createDataFrame(rowRDD, schema)</div></pre></td></tr></table></figure></p>
<p>上面代码df1、df2、df3都是DataFrame类型</p>
<p>DataFrame类型的一些常见的api操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Show the content of the DataFrame</span></div><div class="line">df.show()</div><div class="line"></div><div class="line"><span class="comment">// Print the schema in a tree format</span></div><div class="line">df.printSchema()</div><div class="line"></div><div class="line"><span class="comment">// Select only the "name" column</span></div><div class="line">df.select(<span class="string">"name"</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Select everybody, but increment the age by 1</span></div><div class="line">df.select(df(<span class="string">"name"</span>), df(<span class="string">"age"</span>) + <span class="number">1</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Select people older than 21</span></div><div class="line">df.filter(df(<span class="string">"age"</span>) &gt; <span class="number">21</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Count people by age</span></div><div class="line">df.groupBy(<span class="string">"age"</span>).count().show()</div></pre></td></tr></table></figure></p>
<p>下面是简单的sql操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 注册输入的DataFrame</span></div><div class="line">df2.registerTempTable(<span class="string">"people"</span>)</div><div class="line"></div><div class="line"><span class="comment">// SQL statements can be run by using the sql methods provided by sqlContext.</span></div><div class="line"><span class="keyword">val</span> teenagers = sqlContext.sql(<span class="string">"SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19"</span>)</div><div class="line"></div><div class="line"><span class="comment">// The results of SQL queries are DataFrames and support all the normal RDD operations.</span></div><div class="line"><span class="comment">// The columns of a row in the result can be accessed by field index:</span></div><div class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t(<span class="number">0</span>)).collect().foreach(println)</div><div class="line"></div><div class="line"><span class="comment">// or by field name:</span></div><div class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t.getAs[<span class="type">String</span>](<span class="string">"name"</span>)).collect().foreach(println)</div><div class="line"></div><div class="line"><span class="comment">// row.getValuesMap[T] retrieves multiple columns at once into a Map[String, T]</span></div><div class="line">teenagers.map(_.getValuesMap[<span class="type">Any</span>](<span class="type">List</span>(<span class="string">"name"</span>, <span class="string">"age"</span>))).collect().foreach(println)</div></pre></td></tr></table></figure></p>
<p>测试数据:<br>spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Michael, 29</div><div class="line">Andy, 30</div><div class="line">Justin, 19</div></pre></td></tr></table></figure></p>
<p>测试结果如图：<br><img src="/images/201701/SparkSql_1.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/22/SparkStreaming初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/22/SparkStreaming初体验/" itemprop="url">
                  SparkStreaming初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-22T15:53:39+08:00">
                2017-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkStreaming简单介绍"><a href="#SparkStreaming简单介绍" class="headerlink" title="SparkStreaming简单介绍"></a>SparkStreaming简单介绍</h2><p>Spark Streaming是建立在Spark上的实时计算框架<br>输入和输出概览：<br><img src="/images/201701/SparkStreaming_1.png"><br>Spark Streaming把实时输入数据流以时间片(如1秒)为单位切分成块。SparkStreaming会把每块数据作为一个RDD，并使用RDD操作处理每一小块数据<br><img src="/images/201701/SparkStreaming_2.png"></p>
<h2 id="例子-从kafka输入源-读取数据后-直接输出"><a href="#例子-从kafka输入源-读取数据后-直接输出" class="headerlink" title="例子:从kafka输入源 读取数据后 直接输出"></a>例子:从kafka输入源 读取数据后 直接输出</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</div><div class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">process_58_data</span> </span>&#123;</div><div class="line">  <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">ERROR</span>)</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> masterUrl = <span class="string">"local[2]"</span> <span class="comment">//不能local，需要两个核以上</span></div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(masterUrl).setAppName(<span class="string">"58_data"</span>)</div><div class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</div><div class="line">    <span class="keyword">val</span> topics = <span class="type">Set</span>(<span class="string">"58_data"</span>) <span class="comment">//kafka的topic</span></div><div class="line">    <span class="keyword">val</span> brokers = <span class="string">"master:9092,worker1:9092,worker2:9092"</span> <span class="comment">//kafka端口</span></div><div class="line">    <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">"metadata.broker.list"</span> -&gt; brokers)</div><div class="line">    <span class="keyword">val</span> kafkaStream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](ssc, kafkaParams, topics) <span class="comment">//调用Kafka工具包创建DSteam</span></div><div class="line">    kafkaStream.foreachRDD(rdd =&gt;&#123;</div><div class="line">      rdd.foreachPartition(iter =&gt; &#123;</div><div class="line">        iter.foreach( x =&gt;</div><div class="line">          println(x._2)</div><div class="line">        )</div><div class="line">      &#125;)</div><div class="line">    &#125;)</div><div class="line">    ssc.start() <span class="comment">//启动流计算环境StreamingContext</span></div><div class="line">    ssc.awaitTermination() <span class="comment">//等待作业完成</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之前写过简单的爬虫用来抓取网页信息，将数据放入kafka中，配合SparkStreaming，最后输出结果如下:<br><img src="/images/201701/SparkStreaming_3.png"></p>
<h2 id="SparkStreaming中DSteam转化操作"><a href="#SparkStreaming中DSteam转化操作" class="headerlink" title="SparkStreaming中DSteam转化操作"></a>SparkStreaming中DSteam转化操作</h2><h3 id="无状态："><a href="#无状态：" class="headerlink" title="无状态："></a>无状态：</h3><p>SparkStreaming是建立在Spark，所以很多RDD转化操作都适用于Dsteam.<br>例如: map, flatMap, filter, repartition, join, reduceByKey<br>(注: 针对键值对的Dsteam转化操作需要import StreamingContext._)</p>
<h3 id="有状态-SparkStreaming特有的操作-："><a href="#有状态-SparkStreaming特有的操作-：" class="headerlink" title="有状态(SparkStreaming特有的操作)："></a>有状态(SparkStreaming特有的操作)：</h3><p>滑动窗口和updateStateByKey<br>滑动窗口使用详情可以参考：<a href="http://blog.csdn.net/legotime/article/details/51836040" target="_blank" rel="external">http://blog.csdn.net/legotime/article/details/51836040</a></p>
<p>参考文档：<br><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a><br>《Spark快速大数据分析》</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/21/spark机器学习初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/21/spark机器学习初体验/" itemprop="url">
                  spark机器学习初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-21T18:19:48+08:00">
                2017-01-21
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="垃圾邮件分类例子"><a href="#垃圾邮件分类例子" class="headerlink" title="垃圾邮件分类例子"></a>垃圾邮件分类例子</h2><h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><p>垃圾邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">spam.txt</div><div class="line">Dear sir, I am a Prince in a far kingdom you have not heard of.  I want to send you money via wire transfer so please ...</div><div class="line">Get Viagra real cheap!  Send money right away to ...</div><div class="line">Oh my gosh you can be really strong too with these drugs found in the rainforest. Get them cheap right now ...</div><div class="line">YOUR COMPUTER HAS BEEN INFECTED!  YOU MUST RESET YOUR PASSWORD.  Reply to this email with your password and SSN ...</div><div class="line">THIS IS NOT A SCAM!  Send money and get access to awesome stuff really cheap and never have to ...</div></pre></td></tr></table></figure></p>
<p>正常邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ham.txt</div><div class="line">Dear Spark Learner, Thanks so much for attending the Spark Summit 2014!  Check out videos of talks from the summit at ...</div><div class="line">Hi Mom, Apologies for being late about emailing and forgetting to send you the package.  I hope you and bro have been ...</div><div class="line">Wow, hey Fred, just heard about the Spark petabyte sort.  I think we need to take time to try it out immediately ...</div><div class="line">Hi Spark user list, This is my first question to this list, so thanks in advance for your help!  I tried running ...</div><div class="line">Thanks Tom for your email.  I need to refer you to Alice for this one.  I haven&apos;t yet figured out that part either ...</div><div class="line">Good job yesterday!  I was attending your talk, and really enjoyed it.  I want to try out GraphX ...</div><div class="line">Summit demo got whoops from audience!  Had to let you know. --Joe</div></pre></td></tr></table></figure></p>
<h3 id="Scala代码"><a href="#Scala代码" class="headerlink" title="Scala代码"></a>Scala代码</h3><p>这个程序使用了MLlib两个函数：HashingTF(从文本数据构建 词频特征向量)和LogisticRegressionWithSGD(随机体度下降法实现逻辑回归)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.<span class="type">LogisticRegressionWithSGD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.feature.<span class="type">HashingTF</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">MLlib</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">s"Book example: Scala"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line"></div><div class="line">    <span class="comment">// Load 2 types of emails from text files: spam and ham (non-spam).</span></div><div class="line">    <span class="comment">// Each line has text from one email.</span></div><div class="line">    <span class="keyword">val</span> spam = sc.textFile(<span class="string">"files/spam.txt"</span>)</div><div class="line">    <span class="keyword">val</span> ham = sc.textFile(<span class="string">"files/ham.txt"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Create a HashingTF instance to map email text to vectors of 100 features.</span></div><div class="line">    <span class="keyword">val</span> tf = <span class="keyword">new</span> <span class="type">HashingTF</span>(numFeatures = <span class="number">100</span>)</div><div class="line">    <span class="comment">// Each email is split into words, and each word is mapped to one feature.</span></div><div class="line">    <span class="comment">// 1、特征提取</span></div><div class="line">    <span class="keyword">val</span> spamFeatures = spam.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line">    <span class="keyword">val</span> hamFeatures = ham.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line"></div><div class="line">    <span class="comment">// Create LabeledPoint datasets for positive (spam) and negative (ham) examples.</span></div><div class="line">    <span class="comment">// 2、将文本数据转换为数值特征，返回LabeledPoint类型RDD(包含一个特质向量和一个标签)</span></div><div class="line">    <span class="keyword">val</span> positiveExamples = spamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">1</span>, features))</div><div class="line">    <span class="keyword">val</span> negativeExamples = hamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">0</span>, features))</div><div class="line">    <span class="keyword">val</span> trainingData = positiveExamples ++ negativeExamples</div><div class="line">    trainingData.cache() <span class="comment">// Cache data since Logistic Regression is an iterative algorithm.</span></div><div class="line"></div><div class="line">    <span class="comment">// Create a Logistic Regression learner which uses the LBFGS optimizer.</span></div><div class="line">    <span class="comment">// 3、调用分类算法，返回模型对象</span></div><div class="line">    <span class="keyword">val</span> lrLearner = <span class="keyword">new</span> <span class="type">LogisticRegressionWithSGD</span>()</div><div class="line">    <span class="comment">// Run the actual learning algorithm on the training data.</span></div><div class="line">    <span class="keyword">val</span> model = lrLearner.run(trainingData)</div><div class="line"></div><div class="line">    <span class="comment">// Test on a positive example (spam) and a negative one (ham).</span></div><div class="line">    <span class="comment">// First apply the same HashingTF feature transformation used on the training data.</span></div><div class="line">    <span class="keyword">val</span> posTestExample = tf.transform(<span class="string">"O M G GET cheap stuff by sending money to ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="keyword">val</span> negTestExample = tf.transform(<span class="string">"Hi Dad, I started studying Spark the other ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="comment">// Now use the learned model to predict spam/ham for new emails.</span></div><div class="line">    println(<span class="string">s"Prediction for positive test example: <span class="subst">$&#123;model.predict(posTestExample)&#125;</span>"</span>)</div><div class="line">    println(<span class="string">s"Prediction for negative test example: <span class="subst">$&#123;model.predict(negTestExample)&#125;</span>"</span>)</div><div class="line"></div><div class="line">    sc.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>运行结果如果所示：<br><img src="/images/201701/SparkML_1.png"></p>
<h2 id="机器学习流水线中典型步骤"><a href="#机器学习流水线中典型步骤" class="headerlink" title="机器学习流水线中典型步骤"></a>机器学习流水线中典型步骤</h2><p>源数据ETL-&gt;数据预处理-&gt;特征提取(返回MLlib的数据类型，比如上例的LabeledPoint类型)-&gt;训练(返回模型)-&gt;模型评估</p>
<h2 id="简单理解"><a href="#简单理解" class="headerlink" title="简单理解"></a>简单理解</h2><p>确定模型—-训练模型—-使用模型<br>模型简单说可以理解为函数。<br>确定模型是说自己认为这些数据的特征符合哪个函数(应该使用什么模型)<br>训练模型就是用已有的数据，通过一些方法（最优化或者其他方法）确定函数的参数，参数确定后的函数就是训练的结果<br>使用模型就是把新的数据代入函数求值</p>
<p>参考文档：<br>《Spark快速大数据分析》<br><a href="https://www.zhihu.com/question/29271217?sort=created" target="_blank" rel="external">https://www.zhihu.com/question/29271217?sort=created</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/20/spark源码浅析-提交Task到Executor/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/20/spark源码浅析-提交Task到Executor/" itemprop="url">
                  spark源码浅析：提交Task到Executor
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-20T16:15:23+08:00">
                2017-01-20
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="从DAGScheduler-submitMissingTasks-开始追源码"><a href="#从DAGScheduler-submitMissingTasks-开始追源码" class="headerlink" title="从DAGScheduler.submitMissingTasks 开始追源码"></a>从DAGScheduler.submitMissingTasks 开始追源码</h2><p>DAGScheduler.submitMissingTasks主要功能<br>1、找到RDD中需要计算的partition<br>2、获取Task的最佳计算位置<br>3、序列化Task的Binary，并进行广播<br>4、根据stage的不同类型创建，为stage的每个分区创建创建task,并封装成TaskSet<br>5、调用TaskScheduler的submitTasks，提交TaskSet<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** Called when stage's parents are available and we can now do its task. */</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>) &#123;</div><div class="line">  logDebug(<span class="string">"submitMissingTasks("</span> + stage + <span class="string">")"</span>)</div><div class="line">  <span class="comment">// Get our pending tasks and remember them in our pendingTasks entry</span></div><div class="line">  stage.pendingPartitions.clear()</div><div class="line"></div><div class="line">  <span class="comment">// First figure out the indexes of partition ids to compute.</span></div><div class="line">  <span class="comment">// 1、找到RDD中需要计算的partition</span></div><div class="line">  <span class="comment">// 对于Shuffle类型的Stage，需要判断stage中是否缓存了该结果</span></div><div class="line">  <span class="comment">// 对于Result类型的Stage，则判断计算Job中该partition是否已经计算完成</span></div><div class="line">  <span class="keyword">val</span> partitionsToCompute: <span class="type">Seq</span>[<span class="type">Int</span>] = stage.findMissingPartitions()</div><div class="line"></div><div class="line">  <span class="comment">// Create internal accumulators if the stage has no accumulators initialized.</span></div><div class="line">  <span class="comment">// Reset internal accumulators only if this stage is not partially submitted</span></div><div class="line">  <span class="comment">// Otherwise, we may override existing accumulator values from some tasks</span></div><div class="line">  <span class="keyword">if</span> (stage.internalAccumulators.isEmpty || stage.numPartitions == partitionsToCompute.size) &#123;</div><div class="line">    stage.resetInternalAccumulators()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Use the scheduling pool, job group, description, etc. from an ActiveJob associated</span></div><div class="line">  <span class="comment">// with this Stage</span></div><div class="line">  <span class="keyword">val</span> properties = jobIdToActiveJob(jobId).properties</div><div class="line"></div><div class="line">  runningStages += stage</div><div class="line">  <span class="comment">// SparkListenerStageSubmitted should be posted before testing whether tasks are</span></div><div class="line">  <span class="comment">// serializable. If tasks are not serializable, a SparkListenerStageCompleted event</span></div><div class="line">  <span class="comment">// will be posted, which should always come after a corresponding SparkListenerStageSubmitted</span></div><div class="line">  <span class="comment">// event.</span></div><div class="line">  stage <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - <span class="number">1</span>)</div><div class="line">    <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</div><div class="line">      outputCommitCoordinator.stageStart(</div><div class="line">        stage = s.id, maxPartitionId = s.rdd.partitions.length - <span class="number">1</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 2、获取Task的最佳计算位置</span></div><div class="line">  <span class="comment">// 根据RDD的数据信息得到task的最佳计算位置，从而获取较好的数据本地性</span></div><div class="line">  <span class="keyword">val</span> taskIdToLocations: <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">TaskLocation</span>]] = <span class="keyword">try</span> &#123;</div><div class="line">    stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap</div><div class="line">      <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="keyword">val</span> job = s.activeJob.get</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> p = s.partitions(id)</div><div class="line">          (id, getPreferredLocs(stage.rdd, p))</div><div class="line">        &#125;.toMap</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      stage.makeNewStageAttempt(partitionsToCompute.size)</div><div class="line">      listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</div><div class="line">      abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)</div><div class="line">  listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</div><div class="line"></div><div class="line">  <span class="comment">// <span class="doctag">TODO:</span> Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.</span></div><div class="line">  <span class="comment">// Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast</span></div><div class="line">  <span class="comment">// the serialized copy of the RDD and for each task we will deserialize it, which means each</span></div><div class="line">  <span class="comment">// task gets a different copy of the RDD. This provides stronger isolation between tasks that</span></div><div class="line">  <span class="comment">// might modify state of objects referenced in their closures. This is necessary in Hadoop</span></div><div class="line">  <span class="comment">// where the JobConf/Configuration object is not thread-safe.</span></div><div class="line">  <span class="comment">// 3、序列化Task的Binary，并进行广播</span></div><div class="line">  <span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).</span></div><div class="line">    <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).</span></div><div class="line">    <span class="keyword">val</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>).array()</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">        closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>).array()</div><div class="line">    &#125;</div><div class="line">    taskBinary = sc.broadcast(taskBinaryBytes)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="comment">// In the case of a failure during serialization, abort the stage.</span></div><div class="line">    <span class="keyword">case</span> e: <span class="type">NotSerializableException</span> =&gt;</div><div class="line">      abortStage(stage, <span class="string">"Task not serializable: "</span> + e.toString, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line"></div><div class="line">      <span class="comment">// Abort execution</span></div><div class="line">      <span class="keyword">return</span></div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      abortStage(stage, <span class="string">s"Task serialization failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 4、根据stage的不同类型创建，为stage的每个分区创建创建task,并封装成TaskSet</span></div><div class="line">  <span class="comment">// Stage分两种类型ShuffleMapStage生成ShuffleMapTask，ResultStage生成ResultTask</span></div><div class="line">  <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</div><div class="line">    stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">          <span class="keyword">val</span> part = stage.rdd.partitions(id)</div><div class="line">          <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">            taskBinary, part, locs, stage.internalAccumulators)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="keyword">val</span> job = stage.activeJob.get</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</div><div class="line">          <span class="keyword">val</span> part = stage.rdd.partitions(p)</div><div class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">          <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">            taskBinary, part, locs, id, stage.internalAccumulators)</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</div><div class="line">    logInfo(<span class="string">"Submitting "</span> + tasks.size + <span class="string">" missing tasks from "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">")"</span>)</div><div class="line">    stage.pendingPartitions ++= tasks.map(_.partitionId)</div><div class="line">    logDebug(<span class="string">"New pending partitions: "</span> + stage.pendingPartitions)</div><div class="line">    <span class="comment">// 5、调用TaskScheduler的submitTasks，提交TaskSet</span></div><div class="line">    taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</div><div class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))</div><div class="line">    stage.latestInfo.submissionTime = <span class="type">Some</span>(clock.getTimeMillis())</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// Because we posted SparkListenerStageSubmitted earlier, we should mark</span></div><div class="line">    <span class="comment">// the stage as completed here in case there are no tasks to run</span></div><div class="line">    markStageAsFinished(stage, <span class="type">None</span>)</div><div class="line">    <span class="keyword">val</span> debugString = stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        <span class="string">s"Stage <span class="subst">$&#123;stage&#125;</span> is actually done; "</span> +</div><div class="line">          <span class="string">s"(available: <span class="subst">$&#123;stage.isAvailable&#125;</span>,"</span> +</div><div class="line">          <span class="string">s"available outputs: <span class="subst">$&#123;stage.numAvailableOutputs&#125;</span>,"</span> +</div><div class="line">          <span class="string">s"partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)"</span></div><div class="line">      <span class="keyword">case</span> stage : <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="string">s"Stage <span class="subst">$&#123;stage&#125;</span> is actually done; (partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)"</span></div><div class="line">    &#125;</div><div class="line">    logDebug(debugString)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSchedulerImpl-submitTasks"><a href="#TaskSchedulerImpl-submitTasks" class="headerlink" title="TaskSchedulerImpl.submitTasks"></a>TaskSchedulerImpl.submitTasks</h2><p>TaskSchedulerImpl.submitTasks主要功能<br>1、创建TaskSetManager<br>2、将TaskSetManager加入rootPool调度池中，由schedulableBuilder决定调度顺序<br>3、调用SchedulerBackend的reviveOffers方法对Task进行调度，决定task具体运行在哪个Executor中<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.submitTasks</div><div class="line">  <span class="comment">/*</span></div><div class="line">  * 主要将任务加入调度池，最后调用了backend.reviveOffers()</div><div class="line">  * 这里的backend是CoarseGrainedSchedulerBackend一个Executor任务调度对象</div><div class="line">  */</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">submitTasks</span></span>(taskSet: <span class="type">TaskSet</span>) &#123;</div><div class="line">    <span class="keyword">val</span> tasks = taskSet.tasks</div><div class="line">    logInfo(<span class="string">"Adding task set "</span> + taskSet.id + <span class="string">" with "</span> + tasks.length + <span class="string">" tasks"</span>)</div><div class="line">    <span class="keyword">this</span>.synchronized &#123;</div><div class="line">      <span class="comment">// 1、创建TaskSetManager</span></div><div class="line">      <span class="comment">// TaskSetManager会负责task的失败重试；跟踪每个task的执行状态；处理locality-aware的调用。</span></div><div class="line">      <span class="keyword">val</span> manager = createTaskSetManager(taskSet, maxTaskFailures)</div><div class="line">      <span class="keyword">val</span> stage = taskSet.stageId</div><div class="line">      <span class="keyword">val</span> stageTaskSets =</div><div class="line">        taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">TaskSetManager</span>])</div><div class="line">      stageTaskSets(taskSet.stageAttemptId) = manager</div><div class="line">      <span class="keyword">val</span> conflictingTaskSet = stageTaskSets.exists &#123; <span class="keyword">case</span> (_, ts) =&gt;</div><div class="line">        ts.taskSet != taskSet &amp;&amp; !ts.isZombie</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (conflictingTaskSet) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"more than one active taskSet for stage <span class="subst">$stage</span>:"</span> +</div><div class="line">          <span class="string">s" <span class="subst">$&#123;stageTaskSets.toSeq.map&#123;_._2.taskSet.id&#125;</span>.mkString("</span>,<span class="string">")&#125;"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// 2、将TaskSetManager加入rootPool调度池中，由schedulableBuilder决定调度顺序</span></div><div class="line">      <span class="comment">// SchedulerBuilder有两个实现FIFOSchedulerBuilder和FairSchedulerBuilder，默认采用的是FIFO方式</span></div><div class="line">      schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!isLocal &amp;&amp; !hasReceivedTask) &#123;</div><div class="line">        starvationTimer.scheduleAtFixedRate(<span class="keyword">new</span> <span class="type">TimerTask</span>() &#123;</div><div class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">            <span class="keyword">if</span> (!hasLaunchedTask) &#123;</div><div class="line">              logWarning(<span class="string">"Initial job has not accepted any resources; "</span> +</div><div class="line">                <span class="string">"check your cluster UI to ensure that workers are registered "</span> +</div><div class="line">                <span class="string">"and have sufficient resources"</span>)</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">              <span class="keyword">this</span>.cancel()</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;, <span class="type">STARVATION_TIMEOUT_MS</span>, <span class="type">STARVATION_TIMEOUT_MS</span>)</div><div class="line">      &#125;</div><div class="line">      hasReceivedTask = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 3、调用SchedulerBackend的reviveOffers方法对Task进行调度，决定task具体运行在哪个Executor中</span></div><div class="line">    backend.reviveOffers()</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>调用CoarseGrainedSchedulerBackend的reviveOffers方法，该方法给driverEndpoint发送ReviveOffer消息</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="type">CoarseGrainedSchedulerBackend</span>.reviveOffers</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>() &#123;</div><div class="line">    driverEndpoint.send(<span class="type">ReviveOffers</span>)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>driverEndpoint收到ReviveOffer消息后调用makeOffers方法</p>
<h2 id="CoarseGrainedSchedulerBackend-makeOffers"><a href="#CoarseGrainedSchedulerBackend-makeOffers" class="headerlink" title="CoarseGrainedSchedulerBackend.makeOffers"></a>CoarseGrainedSchedulerBackend.makeOffers</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="type">CoarseGrainedSchedulerBackend</span>.makeOffers</div><div class="line">    <span class="comment">// Make fake resource offers on all executor</span></div><div class="line">    <span class="comment">// makeOffers方法中，将Executor的信息集合与调度池中的Tasks封装成WokerOffers列表传给了 launchTasks</span></div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeOffers</span></span>() &#123;</div><div class="line">      <span class="comment">// Filter out executors under killing</span></div><div class="line">      <span class="comment">// 过滤出活跃状态的Executor</span></div><div class="line">      <span class="keyword">val</span> activeExecutors = executorDataMap.filterKeys(executorIsAlive)</div><div class="line">      <span class="comment">// 将Executor封装成WorkerOffer对象</span></div><div class="line">      <span class="keyword">val</span> workOffers = activeExecutors.map &#123; <span class="keyword">case</span> (id, executorData) =&gt;</div><div class="line">        <span class="keyword">new</span> <span class="type">WorkerOffer</span>(id, executorData.executorHost, executorData.freeCores)</div><div class="line">      &#125;.toSeq</div><div class="line">      launchTasks(scheduler.resourceOffers(workOffers))</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>注意：上面代码中的executorDataMap，在客户端向Master注册Application的时候，Master已经为Application分配并启动好Executor，然后注册给CoarseGrainedSchedulerBackend，注册信息就是存储在executorDataMap数据结构中。</p>
<h2 id="TaskSchedulerImpl-resourceOffers"><a href="#TaskSchedulerImpl-resourceOffers" class="headerlink" title="TaskSchedulerImpl.resourceOffers"></a>TaskSchedulerImpl.resourceOffers</h2><p>准备好计算资源后，接下来TaskSchedulerImpl基于这些计算资源为task分配Executor<br>看一下TaskSchedulerImpl的resourceOffers方法：<br>传递的参数offers表示worker提供的资源，该方法根据资源情况，结合待执行任务的优先级，将任务平衡的分配给executors<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.resourceOffers</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Called by cluster manager to offer resources on slaves. We respond by asking our active task</div><div class="line">   * sets for tasks in order of priority. We fill each node with tasks in a round-robin manner so</div><div class="line">   * that tasks are balanced across the cluster.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">resourceOffers</span></span>(offers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>]): <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]] = synchronized &#123;</div><div class="line">    <span class="comment">// Mark each slave as alive and remember its hostname</span></div><div class="line">    <span class="comment">// Also track if new executor is added</span></div><div class="line">    <span class="comment">// 激活所有slave节点，记录其hostname，并检查是否有新的executor加入</span></div><div class="line">    <span class="keyword">var</span> newExecAvail = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (o &lt;- offers) &#123;</div><div class="line">      executorIdToHost(o.executorId) = o.host</div><div class="line">      executorIdToTaskCount.getOrElseUpdate(o.executorId, <span class="number">0</span>)</div><div class="line">      <span class="keyword">if</span> (!executorsByHost.contains(o.host)) &#123;</div><div class="line">        executorsByHost(o.host) = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()</div><div class="line">        executorAdded(o.executorId, o.host)</div><div class="line">        newExecAvail = <span class="literal">true</span></div><div class="line">      &#125;</div><div class="line">      <span class="keyword">for</span> (rack &lt;- getRackForHost(o.host)) &#123;</div><div class="line">        hostsByRack.getOrElseUpdate(rack, <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()) += o.host</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Randomly shuffle offers to avoid always placing tasks on the same set of workers.</span></div><div class="line">    <span class="comment">// 随机打乱offers,避免总是前几个worker被分配到任务</span></div><div class="line">    <span class="keyword">val</span> shuffledOffers = <span class="type">Random</span>.shuffle(offers)</div><div class="line">    <span class="comment">// Build a list of tasks to assign to each worker.</span></div><div class="line">    <span class="comment">// 构建一个二维数组，保存每个Executor上将要分配的那些task</span></div><div class="line">    <span class="keyword">val</span> tasks = shuffledOffers.map(o =&gt; <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>](o.cores))</div><div class="line">    <span class="keyword">val</span> availableCpus = shuffledOffers.map(o =&gt; o.cores).toArray</div><div class="line">    <span class="comment">// 根据SchedulerBuilder的调度算法，给TaskManager排好序</span></div><div class="line">    <span class="keyword">val</span> sortedTaskSets = rootPool.getSortedTaskSetQueue</div><div class="line">    <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets) &#123;</div><div class="line">      logDebug(<span class="string">"parentName: %s, name: %s, runningTasks: %s"</span>.format(</div><div class="line">        taskSet.parent.name, taskSet.name, taskSet.runningTasks))</div><div class="line">      <span class="keyword">if</span> (newExecAvail) &#123;</div><div class="line">        taskSet.executorAdded()</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Take each TaskSet in our scheduling order, and then offer it each node in increasing order</span></div><div class="line">    <span class="comment">// of locality levels so that it gets a chance to launch local tasks on all of them.</span></div><div class="line">    <span class="comment">// <span class="doctag">NOTE:</span> the preferredLocality order: PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></div><div class="line">    <span class="comment">// 按照调度优先级顺序遍历TaskSet，在所有系统资源(WorkerOffer)上从最高Locality到最低Locality依次尝试执行最适合的task</span></div><div class="line">    <span class="comment">// 数据本地性级别顺序: PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></div><div class="line">    <span class="keyword">var</span> launchedTask = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets; maxLocality &lt;- taskSet.myLocalityLevels) &#123;</div><div class="line">      do &#123;</div><div class="line">        launchedTask = resourceOfferSingleTaskSet(</div><div class="line">            taskSet, maxLocality, shuffledOffers, availableCpus, tasks)</div><div class="line">      &#125; <span class="keyword">while</span> (launchedTask)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</div><div class="line">      hasLaunchedTask = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> tasks</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSchedulerImpl-resourceOfferSingleTaskSet"><a href="#TaskSchedulerImpl-resourceOfferSingleTaskSet" class="headerlink" title="TaskSchedulerImpl.resourceOfferSingleTaskSet"></a>TaskSchedulerImpl.resourceOfferSingleTaskSet</h2><p>下面再看看resourceOfferSingleTaskSet代码<br>用当前的数据本地性，调用TaskSetManager的resourceOffer方法，在当前executor上分配task<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.resourceOfferSingleTaskSet</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">resourceOfferSingleTaskSet</span></span>(</div><div class="line">      taskSet: <span class="type">TaskSetManager</span>,</div><div class="line">      maxLocality: <span class="type">TaskLocality</span>,</div><div class="line">      shuffledOffers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>],</div><div class="line">      availableCpus: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">      tasks: <span class="type">Seq</span>[<span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>]]) : <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">var</span> launchedTask = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until shuffledOffers.size) &#123;</div><div class="line">      <span class="keyword">val</span> execId = shuffledOffers(i).executorId</div><div class="line">      <span class="keyword">val</span> host = shuffledOffers(i).host</div><div class="line">      <span class="comment">// 判断executor是否有足够的CPU核数来运行task</span></div><div class="line">      <span class="keyword">if</span> (availableCpus(i) &gt;= <span class="type">CPUS_PER_TASK</span>) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="comment">// 真正调用的是TaskSetManager.resourceOffer方法</span></div><div class="line">          <span class="keyword">for</span> (task &lt;- taskSet.resourceOffer(execId, host, maxLocality)) &#123;</div><div class="line">            tasks(i) += task</div><div class="line">            <span class="keyword">val</span> tid = task.taskId</div><div class="line">            taskIdToTaskSetManager(tid) = taskSet</div><div class="line">            taskIdToExecutorId(tid) = execId</div><div class="line">            executorIdToTaskCount(execId) += <span class="number">1</span></div><div class="line">            executorsByHost(host) += execId</div><div class="line">            availableCpus(i) -= <span class="type">CPUS_PER_TASK</span></div><div class="line">            assert(availableCpus(i) &gt;= <span class="number">0</span>)</div><div class="line">            launchedTask = <span class="literal">true</span></div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="keyword">case</span> e: <span class="type">TaskNotSerializableException</span> =&gt;</div><div class="line">            logError(<span class="string">s"Resource offer failed, task set <span class="subst">$&#123;taskSet.name&#125;</span> was not serializable"</span>)</div><div class="line">            <span class="comment">// Do not offer resources for this task, but don't throw an error to allow other</span></div><div class="line">            <span class="comment">// task sets to be submitted.</span></div><div class="line">            <span class="keyword">return</span> launchedTask</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> launchedTask</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSetManager-resourceOffer"><a href="#TaskSetManager-resourceOffer" class="headerlink" title="TaskSetManager.resourceOffer"></a>TaskSetManager.resourceOffer</h2><p>TaskSetManager.resourceOffer方法的作用是为executor资源提供一个最符合数据本地性的任务<br>TaskLocality是枚举类，表示数据本地化的级别，其优先级为 PROCESS_LOCAL(最高) &lt; NODE_LOCAL &lt; NO_PREF &lt; RACK_LOCAL &lt; ANY(最低)<br>其中PROCESS_LOCAL，NODE_LOCAL，RACK_LOCAL可分别设置对应的延迟时间，默认值是3s<br>TaskSetManager内部维护了以下几个HashMap<br>1、pendingTasksForExecutor<br>2、pendingTasksForHost<br>3、pendingTasksForRack<br>4、pendingTasksWithNoPrefs<br>TaskSetManager在初始化时，若Task的preferredLocations不为空，则将Task添加到前三个pending队列；若为空，则加入pendingTasksWithNoPrefs<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// TaskSetManager.resourceOffer</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">resourceOffer</span></span>(</div><div class="line">    execId: <span class="type">String</span>,</div><div class="line">    host: <span class="type">String</span>,</div><div class="line">    maxLocality: <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span>)</div><div class="line">  : <span class="type">Option</span>[<span class="type">TaskDescription</span>] =</div><div class="line">&#123;</div><div class="line">  <span class="keyword">if</span> (!isZombie) &#123;</div><div class="line">    <span class="keyword">val</span> curTime = clock.getTimeMillis()</div><div class="line"></div><div class="line">    <span class="keyword">var</span> allowedLocality = maxLocality</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</div><div class="line">      <span class="comment">// 结合各Locality设置的延迟时间及上次成功在当前Locality级别提交任务的时间，获得能够允许的最高本地化级别的Locality级别</span></div><div class="line">      allowedLocality = getAllowedLocalityLevel(curTime)</div><div class="line">      <span class="comment">// 大于表示本地化级别更低</span></div><div class="line">      <span class="keyword">if</span> (allowedLocality &gt; maxLocality) &#123;</div><div class="line">        <span class="comment">// </span></div><div class="line">        allowedLocality = maxLocality</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// dequeueTask返回的是允许的Locality范围内Locality级别最高的Task的TaskDescription</span></div><div class="line">    dequeueTask(execId, host, allowedLocality) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>((index, taskLocality, speculative)) =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> task = tasks(index)</div><div class="line">        <span class="keyword">val</span> taskId = sched.newTaskId()</div><div class="line">        <span class="comment">// Do various bookkeeping</span></div><div class="line">        copiesRunning(index) += <span class="number">1</span></div><div class="line">        <span class="keyword">val</span> attemptNum = taskAttempts(index).size</div><div class="line">        <span class="keyword">val</span> info = <span class="keyword">new</span> <span class="type">TaskInfo</span>(taskId, index, attemptNum, curTime,</div><div class="line">          execId, host, taskLocality, speculative)</div><div class="line">        taskInfos(taskId) = info</div><div class="line">        taskAttempts(index) = info :: taskAttempts(index)</div><div class="line">        <span class="comment">// 除非Task的Locality级别为NO_PREF，否则更新当前Locality级别为该task的Locality，并更新lastLaunchTime</span></div><div class="line">        <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</div><div class="line">          currentLocalityIndex = getLocalityIndex(taskLocality)</div><div class="line">          lastLaunchTime = curTime</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 序列化task</span></div><div class="line">        <span class="keyword">val</span> startTime = clock.getTimeMillis()</div><div class="line">        <span class="keyword">val</span> serializedTask: <span class="type">ByteBuffer</span> = <span class="keyword">try</span> &#123;</div><div class="line">          <span class="type">Task</span>.serializeWithDependencies(task, sched.sc.addedFiles, sched.sc.addedJars, ser)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="comment">// 序列化出错没有重试的必要</span></div><div class="line">          <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">            <span class="keyword">val</span> msg = <span class="string">s"Failed to serialize task <span class="subst">$taskId</span>, not attempting to retry it."</span></div><div class="line">            logError(msg, e)</div><div class="line">            abort(<span class="string">s"<span class="subst">$msg</span> Exception during serialization: <span class="subst">$e</span>"</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">TaskNotSerializableException</span>(e)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 若task过大，则存在优化的必要</span></div><div class="line">        <span class="keyword">if</span> (serializedTask.limit &gt; <span class="type">TaskSetManager</span>.<span class="type">TASK_SIZE_TO_WARN_KB</span> * <span class="number">1024</span> &amp;&amp;</div><div class="line">            !emittedTaskSizeWarning) &#123;</div><div class="line">          emittedTaskSizeWarning = <span class="literal">true</span></div><div class="line">          logWarning(<span class="string">s"Stage <span class="subst">$&#123;task.stageId&#125;</span> contains a task of very large size "</span> +</div><div class="line">            <span class="string">s"(<span class="subst">$&#123;serializedTask.limit / 1024&#125;</span> KB). The maximum recommended task size is "</span> +</div><div class="line">            <span class="string">s"<span class="subst">$&#123;TaskSetManager.TASK_SIZE_TO_WARN_KB&#125;</span> KB."</span>)</div><div class="line">        &#125;</div><div class="line">        addRunningTask(taskId)</div><div class="line"></div><div class="line">        <span class="comment">// We used to log the time it takes to serialize the task, but task size is already</span></div><div class="line">        <span class="comment">// a good proxy to task serialization time.</span></div><div class="line">        <span class="comment">// val timeTaken = clock.getTime() - startTime</span></div><div class="line">        <span class="keyword">val</span> taskName = <span class="string">s"task <span class="subst">$&#123;info.id&#125;</span> in stage <span class="subst">$&#123;taskSet.id&#125;</span>"</span></div><div class="line">        logInfo(<span class="string">"Starting %s (TID %d, %s, %s, %d bytes)"</span>.format(</div><div class="line">            taskName, taskId, host, taskLocality, serializedTask.limit))</div><div class="line"></div><div class="line">        <span class="comment">// 通知DAGScheduler任务开始执行</span></div><div class="line">        sched.dagScheduler.taskStarted(task, info)</div><div class="line">        <span class="keyword">return</span> <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">TaskDescription</span>(taskId = taskId, attemptNumber = attemptNum, execId,</div><div class="line">          taskName, index, serializedTask))</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> _ =&gt;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="type">None</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSetManager-getAllowedLocalityLevel"><a href="#TaskSetManager-getAllowedLocalityLevel" class="headerlink" title="TaskSetManager.getAllowedLocalityLevel"></a>TaskSetManager.getAllowedLocalityLevel</h2><p>TaskSetManager.getAllowedLocalityLevel结合各Locality设置的延迟时间及上次成功在当前Locality级别提交任务的时间，获得能够允许的最高本地化级别的Locality级别<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// TaskSetManager.getAllowedLocalityLevel</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getAllowedLocalityLevel</span></span>(curTime: <span class="type">Long</span>): <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span> = &#123;</div><div class="line">  <span class="comment">// 移除已被调度或完成的task，采用的是lazy方式</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tasksNeedToBeScheduledFrom</span></span>(pendingTaskIds: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">var</span> indexOffset = pendingTaskIds.size</div><div class="line">    <span class="keyword">while</span> (indexOffset &gt; <span class="number">0</span>) &#123;</div><div class="line">      indexOffset -= <span class="number">1</span></div><div class="line">      <span class="keyword">val</span> index = pendingTaskIds(indexOffset)</div><div class="line">      <span class="keyword">if</span> (copiesRunning(index) == <span class="number">0</span> &amp;&amp; !successful(index)) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="literal">true</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        pendingTaskIds.remove(indexOffset)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="literal">false</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 遍历pendingTasks，移除已被调度的task，若仍有task待调度，返回true</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">moreTasksToRunIn</span></span>(pendingTasks: <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]]): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">val</span> emptyKeys = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">String</span>]</div><div class="line">    <span class="keyword">val</span> hasTasks = pendingTasks.exists &#123;</div><div class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, tasks: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]) =&gt;</div><div class="line">        <span class="keyword">if</span> (tasksNeedToBeScheduledFrom(tasks)) &#123;</div><div class="line">          <span class="literal">true</span></div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          emptyKeys += id</div><div class="line">          <span class="literal">false</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// The key could be executorId, host or rackId</span></div><div class="line">    emptyKeys.foreach(id =&gt; pendingTasks.remove(id))</div><div class="line">    hasTasks</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// currentLocalityIndex记录了当前运行在哪个TaskLocality</span></div><div class="line">  <span class="keyword">while</span> (currentLocalityIndex &lt; myLocalityLevels.length - <span class="number">1</span>) &#123;</div><div class="line">    <span class="keyword">val</span> moreTasks = myLocalityLevels(currentLocalityIndex) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">PROCESS_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForExecutor)</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">NODE_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForHost)</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span> =&gt; pendingTasksWithNoPrefs.nonEmpty</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">RACK_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForRack)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (!moreTasks) &#123;</div><div class="line">      <span class="comment">// 若当前Locality没有需要执行的task，则进入更低一级Locality，并更新lastLaunchTime</span></div><div class="line">      lastLaunchTime = curTime</div><div class="line">      logDebug(<span class="string">s"No tasks for locality level <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex)&#125;</span>, "</span> +</div><div class="line">        <span class="string">s"so moving to locality level <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex + 1)&#125;</span>"</span>)</div><div class="line">      currentLocalityIndex += <span class="number">1</span></div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curTime - lastLaunchTime &gt;= localityWaits(currentLocalityIndex)) &#123;</div><div class="line">      <span class="comment">// 若距离上次成功在此Locality级别提交任务的时间间隔超过了该Locality级别设定的延迟时间，则进入更低一级Locality，并更新lastLaunchTime</span></div><div class="line">      lastLaunchTime += localityWaits(currentLocalityIndex)</div><div class="line">      currentLocalityIndex += <span class="number">1</span></div><div class="line">      logDebug(<span class="string">s"Moving to <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex)&#125;</span> after waiting for "</span> +</div><div class="line">        <span class="string">s"<span class="subst">$&#123;localityWaits(currentLocalityIndex)&#125;</span>ms"</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> myLocalityLevels(currentLocalityIndex)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  myLocalityLevels(currentLocalityIndex)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>取得最适合运行的Task后，调用ScheduledBackend.launchTasks方法 将task在Executor上启动运行</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="http://www.cnblogs.com/zhouyf/p/5743382.html" target="_blank" rel="external">http://www.cnblogs.com/zhouyf/p/5743382.html</a><br><a href="http://blog.csdn.net/anzhsoft/article/details/40238111#comments" target="_blank" rel="external">http://blog.csdn.net/anzhsoft/article/details/40238111#comments</a><br><a href="http://blog.csdn.net/bigdata_wang/article/details/48846129" target="_blank" rel="external">http://blog.csdn.net/bigdata_wang/article/details/48846129</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="xiwu1212@163.com" />
          <p class="site-author-name" itemprop="name">xiwu1212@163.com</p>
          <p class="site-description motion-element" itemprop="description">学无止境</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">28</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiwu1212@163.com</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  




  
  

  

  

  

  


</body>
</html>
