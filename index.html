<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="Refrain">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Refrain">
<meta property="og:description" content="学无止境">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Refrain">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title> Refrain </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Refrain</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/28/c/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/28/c/" itemprop="url">
                  c
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-28T21:31:55+08:00">
                2017-01-28
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/27/b/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/27/b/" itemprop="url">
                  b
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-27T22:36:35+08:00">
                2017-01-27
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/26/Spark运行框架/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/26/Spark运行框架/" itemprop="url">
                  Spark运行框架
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-26T12:00:43+08:00">
                2017-01-26
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Spark官网展示了如下的集群运行架构"><a href="#Spark官网展示了如下的集群运行架构" class="headerlink" title="Spark官网展示了如下的集群运行架构"></a>Spark官网展示了如下的集群运行架构</h3><img src="/images/201701/Spark_Frame_1.png">
<h3 id="Spark-Standalone-Client-Mode-运行流程示意图"><a href="#Spark-Standalone-Client-Mode-运行流程示意图" class="headerlink" title="Spark Standalone Client Mode 运行流程示意图"></a>Spark Standalone Client Mode 运行流程示意图</h3><img src="/images/201701/Spark_Frame_2.png">
<h3 id="Spark-YARN-Cluster-Mode-运行流程示意图"><a href="#Spark-YARN-Cluster-Mode-运行流程示意图" class="headerlink" title="Spark YARN Cluster Mode 运行流程示意图"></a>Spark YARN Cluster Mode 运行流程示意图</h3><img src="/images/201701/Spark_Frame_3.png">
<p>转载: <a href="http://blog.csdn.net/bigdata_wang/article/details/48245581" target="_blank" rel="external">http://blog.csdn.net/bigdata_wang/article/details/48245581</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/25/supervisor使用/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/25/supervisor使用/" itemprop="url">
                  Supervisor简单使用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-25T15:52:23+08:00">
                2017-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="下载安装Supervisor"><a href="#下载安装Supervisor" class="headerlink" title="下载安装Supervisor"></a>下载安装Supervisor</h3><p>pip install supervisor<br>如果在命令行中输入echo_supervisord_conf没有找到命令，那么需要在环境变量PATH添加Python的bin目录路径</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>echo_supervisord_conf &gt; /etc/supervisord.conf<br>vim /etc/supervisord.conf<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">[unix_http_server]</div><div class="line">file=/tmp/supervisor.sock   ; UNIX socket 文件，supervisorctl 会使用</div><div class="line">;chmod=0700                 ; socket 文件的 mode，默认是 0700</div><div class="line">;chown=nobody:nogroup       ; socket 文件的 owner，格式： uid:gid</div><div class="line"> </div><div class="line">[inet_http_server]         ; HTTP 服务器，提供 web 管理界面</div><div class="line">port=127.0.0.1:9001        ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性</div><div class="line">username=user              ; 登录管理后台的用户名</div><div class="line">password=123               ; 登录管理后台的密码</div><div class="line"> </div><div class="line">[supervisord]</div><div class="line">logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log</div><div class="line">logfile_maxbytes=50MB        ; 日志文件大小，超出会 rotate，默认 50MB</div><div class="line">logfile_backups=10           ; 日志文件保留备份数量默认 10</div><div class="line">loglevel=info                ; 日志级别，默认 info，其它: debug,warn,trace</div><div class="line">pidfile=/tmp/supervisord.pid ; pid 文件</div><div class="line">nodaemon=false               ; 是否在前台启动，默认是 false，即以 daemon 的方式启动</div><div class="line">minfds=1024                  ; 可以打开的文件描述符的最小值，默认 1024</div><div class="line">minprocs=200                 ; 可以打开的进程数的最小值，默认 200</div><div class="line"> </div><div class="line">; the below section must remain in the config file for RPC</div><div class="line">; (supervisorctl/web interface) to work, additional interfaces may be</div><div class="line">; added by defining them in separate rpcinterface: sections</div><div class="line">[rpcinterface:supervisor]</div><div class="line">supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface</div><div class="line"> </div><div class="line">[supervisorctl]</div><div class="line">serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致</div><div class="line">;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord</div><div class="line"> </div><div class="line">; 包含其他的配置文件</div><div class="line">[include]</div><div class="line">files = /etc/supervisor/*.ini    ; 可以是 *.conf 或 *.ini</div></pre></td></tr></table></figure></p>
<h3 id="启动supervisor"><a href="#启动supervisor" class="headerlink" title="启动supervisor"></a>启动supervisor</h3><p>supervisord -c /etc/supervisord.conf<br>登录127.0.0.1:9001查看supervisor<br><img src="/images/201701/Supervisor_1.png"></p>
<h3 id="添加监控的脚本"><a href="#添加监控的脚本" class="headerlink" title="添加监控的脚本"></a>添加监控的脚本</h3><p>例如在vim /etc/supervisor/test.ini<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[program:<span class="built_in">test</span>]</div><div class="line">directory = /Users/liebaomac ; 程序的启动目录</div><div class="line"><span class="built_in">command</span> = python test.py ; 启动命令，可以看出与手动在命令行启动的命令是一样的</div><div class="line">autostart = <span class="literal">true</span>     ; 在 supervisord 启动的时候也自动启动</div><div class="line">startsecs = 5        ; 启动 5 秒后没有异常退出，就当作已经正常启动了</div><div class="line">autorestart = <span class="literal">true</span>   ; 程序异常退出后自动重启</div><div class="line">startretries = 3     ; 启动失败自动重试次数，默认是 3</div><div class="line">user = liebaomac          ; 用哪个用户启动</div><div class="line">redirect_stderr = <span class="literal">true</span>  ; 把 stderr 重定向到 stdout，默认 <span class="literal">false</span></div><div class="line">; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）</div><div class="line">stdout_logfile = /data/logs/test.log</div><div class="line">stdout_logfile_maxbytes = 20MB  ; stdout 日志文件大小，默认 50MB</div><div class="line">stdout_logfile_backups = 20     ; stdout 日志文件备份数</div></pre></td></tr></table></figure></p>
<p>vim /Users/liebaomac/test.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">"a"</span></div><div class="line"><span class="keyword">print</span> a</div></pre></td></tr></table></figure></p>
<h3 id="更新supervisor监控"><a href="#更新supervisor监控" class="headerlink" title="更新supervisor监控"></a>更新supervisor监控</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">supervisorctl update</div></pre></td></tr></table></figure>
<img src="/images/201701/Supervisor_2.png">
<p>日志如下图所示<br><img src="/images/201701/Supervisor_3.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/24/Spark性能调优简单总结/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/24/Spark性能调优简单总结/" itemprop="url">
                  Spark性能调优简单总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-24T14:00:44+08:00">
                2017-01-24
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="spark性能调优：初级-开发调优、资源调优-高级-数据倾斜调优、shuffle调优"><a href="#spark性能调优：初级-开发调优、资源调优-高级-数据倾斜调优、shuffle调优" class="headerlink" title="spark性能调优：初级(开发调优、资源调优) 高级(数据倾斜调优、shuffle调优)"></a>spark性能调优：初级(开发调优、资源调优) 高级(数据倾斜调优、shuffle调优)</h2><h3 id="开发调优"><a href="#开发调优" class="headerlink" title="开发调优"></a>开发调优</h3><p>RDD lineage设计、算子的合理使用、特殊操作的优化<br>原则一：避免创建重复的RDD<br>原则二：尽可能复用同一个RDD<br>原则三：对多次使用的RDD进行持久化<br>原则四：尽量避免使用shuffle类算子<br>原则五：使用map-side预聚合的shuffle操作 (reduceByKey优于groupByKey)<br>原则六：使用高性能的算子<br>    使用reduceByKey/aggregateByKey替代groupByKey<br>    使用mapPartitions替代普通map(mapPartitions单次函数调用就要处理掉一个partition所有的数据,很可能出现OOM异常)<br>    使用foreachPartitions替代foreach<br>    使用filter之后进行coalesce操作(重新分区，但是不用排序)<br>    使用repartitionAndSortWithinPartitions替代repartition与sort类操作<br>原则七：广播大变量(大变量存储转变 task-&gt;executor)<br>原则八：使用Kryo优化序列化性能<br>原则九：优化数据结构(内存使用  集合类型&gt;数组 对象&gt;字符串&gt;原始类型)</p>
<h3 id="资源调优"><a href="#资源调优" class="headerlink" title="资源调优"></a>资源调优</h3><p>num-executors = 总共要用多少个Executor进程来执行<br>executor-memory = 每个Executor进程的内存<br>executor-cores = 每个Executor进程的CPU core数量<br>driver-memory = Driver进程的内存<br>spark.default.parallelism = 每个stage的task数量(默认根据底层HDFS的block数量来设置task的数量,Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适)<br>spark.storage.memoryFraction = RDD持久化数据在Executor内存占比，默认是0.6<br>spark.shuffle.memoryFraction = shuffle过程在Executor内存占比，默认是0.2<br><img src="/images/201701/Spark_Performance_1.png"></p>
<h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><p>数据倾斜-&gt;shuffle key量大</p>
<h4 id="数据倾斜的原因"><a href="#数据倾斜的原因" class="headerlink" title="数据倾斜的原因"></a>数据倾斜的原因</h4><p>进行shuffle(操作有distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition)的时候，<br>必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，可能出现某一个key的量特别的大</p>
<h4 id="数据倾斜的定位"><a href="#数据倾斜的定位" class="headerlink" title="数据倾斜的定位"></a>数据倾斜的定位</h4><p>1、WebUI或者log日志可以告诉我们哪些个stage(task)运行的数据量大小<br>2、分析代码，重点看有shuffle操作关键代码，定位到具体造成倾斜的操作</p>
<h4 id="数据倾斜的解决方案"><a href="#数据倾斜的解决方案" class="headerlink" title="数据倾斜的解决方案"></a>数据倾斜的解决方案</h4><p>一：提高shuffle操作的并行度(最简单，但是解决不了某个key的量特别大，因为同一个key必须放到一个task下)<br>提高shuffle算子执行时shuffle read task的数量<br>1、对RDD执行shuffle算子时，给shuffle算子传入一个参数，设置reduceByKey(1000)<br>2、对于Spark SQL中的shuffle类语句，group by、join等，设置spark.sql.shuffle.partitions<br>二：使用Hive ETL预处理数据<br>对数据倾斜的数据进行清洗后，供spark程序使用<br>三：过滤少数导致倾斜的key<br>先通过sample算子对数据进行采样，计算每个key对应的数量，再用filter过滤掉这些key<br>四、两阶段聚合，局部聚合+全局聚合<br>适用场景：只对聚合类操作reduceByKey有效，对join操作无效<br>先局部聚合，先给每个key都打上一个随机数(比如10以内的随机数，目的是打散巨大的key)，再执行reduceByKey<br>再全局聚合，将各个key的前缀给去掉，再次进行全局聚合操作<br>五、将reduce join转为map join<br>适用场景：对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小<br>解决办法：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作<br>六：采样倾斜key并分拆join操作<br>适用场景：因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀<br>将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。<br>七：使用随机前缀和扩容RDD进行join<br>使用场景：如果在进行join操作时，RDD中有大量的key导致数据倾斜<br>和方案六差不多，只不过不拆分RDD了，对整体RDD进行扩容(对内存消耗很大)<br><img src="/images/201701/Spark_Performance_2.png"></p>
<h3 id="shuffle调优"><a href="#shuffle调优" class="headerlink" title="shuffle调优"></a>shuffle调优</h3><p>影响一个Spark作业性能的因素，主要还是代码开发、资源参数以 及数据倾斜 shuffle调优只能在整个Spark的性能调优中占到一小部分而已</p>
<p>以下是Shffule过程中的一些主要参数，这里详细讲解了各个参数的功能、默认值以及基于实践经验给出的调优建议。</p>
<p>spark.shuffle.file.buffer</p>
<ul>
<li>默认值：32k</li>
<li>参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>spark.reducer.maxSizeInFlight</p>
<ul>
<li>默认值：48m</li>
<li>参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>spark.shuffle.io.maxRetries</p>
<ul>
<li>默认值：3</li>
<li>参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取 还是没有成功，就可能会导致作业执行失败。</li>
<li>调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定 性。</li>
</ul>
<p>spark.shuffle.io.retryWait</p>
<ul>
<li>默认值：5s</li>
<li>参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。</li>
<li>调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</li>
</ul>
<p>spark.shuffle.memoryFraction</p>
<ul>
<li>默认值：0.2</li>
<li>参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。</li>
<li>调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升10%左右。</li>
</ul>
<p>spark.shuffle.manager</p>
<ul>
<li>默认值：sort</li>
<li>参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。tungsten-sort与sort类似，但是使用了tungsten计划中的 堆外内存管理机制，内存使用效率更高。</li>
<li>调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的 SortShuffleManager就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的 HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，tungsten-sort要慎用，因为之前发现了 一些相应的bug。</li>
</ul>
<p>spark.shuffle.sort.bypassMergeThreshold</p>
<ul>
<li>默认值：200</li>
<li>参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临 时磁盘文件都合并成一个文件，并会创建单独的索引文件。</li>
<li>调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁 盘文件，因此shuffle write性能有待提高。</li>
</ul>
<p>spark.shuffle.consolidateFiles</p>
<ul>
<li>默认值：false</li>
<li>参数说明：如果使用HashShuffleManager，该参数有效。如果设置为true，那么就会开启consolidate机制，会大幅度 合并shuffle write的输出文件，对于shuffle read task数量特别多的情况下，这种方法可以极大地减少磁盘IO开销，提升性能。</li>
<li>调优建议：如果的确不需要SortShuffleManager的排序机制，那么除了使用bypass机制，还可以尝试将 spark.shffle.manager参数手动指定为hash，使用HashShuffleManager，同时开启consolidate机制。在 实践中尝试过，发现其性能比开启了bypass机制的SortShuffleManager要高出10%~30%。</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/23/SparkSQL初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/23/SparkSQL初体验/" itemprop="url">
                  SparkSQL初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-23T13:57:04+08:00">
                2017-01-23
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkSQL输入源"><a href="#SparkSQL输入源" class="headerlink" title="SparkSQL输入源"></a>SparkSQL输入源</h2><p>Hive、Parquet、JSON、基于RDD(需要隐式转换)<br>因为还没有搭好Hive且没有使用过Parquet，下面主要将JSON和基于RDD的输入源<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</div><div class="line"><span class="comment">// Create the DataFrame (From JSON)</span></div><div class="line"><span class="keyword">val</span> df1 = sqlContext.read.json(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.json"</span>)</div><div class="line"></div><div class="line"><span class="comment">// Create the DataFrame (From RDD) 方法一</span></div><div class="line"><span class="comment">// 利用反射机制，推导包含某种类型的RDD，通过反射将其转换为指定类型的DataFrame，</span></div><div class="line"><span class="comment">// 适用于提前知道RDD的schema</span></div><div class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>) <span class="title">//放在main函数外面</span></span></div><div class="line"><span class="keyword">import</span> sqlContext.implicits._</div><div class="line"><span class="keyword">val</span> df2 = sc.textFile(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line">    .map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Person</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim.toInt)).toDF()</div><div class="line"></div><div class="line"><span class="comment">// Create the DataFrame (From RDD) 方法二</span></div><div class="line"><span class="comment">// 当case class不能提前定义好时，通过编程接口与RDD进行交互获取schema，</span></div><div class="line"><span class="comment">// 并动态创建DataFrame，在运行时决定列及其类型。</span></div><div class="line"><span class="keyword">val</span> people = sc.textFile(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line"><span class="keyword">val</span> schemaString = <span class="string">"name age"</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span>;</div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>,<span class="type">StructField</span>,<span class="type">StringType</span>&#125;;</div><div class="line"><span class="keyword">val</span> schema =</div><div class="line">  <span class="type">StructType</span>(schemaString.split(<span class="string">" "</span>).map(fieldName =&gt; <span class="type">StructField</span>(fieldName,</div><div class="line">  <span class="type">StringType</span>, <span class="literal">true</span>))) <span class="comment">//基于structType类型创建schema</span></div><div class="line"><span class="keyword">val</span> rowRDD = people.map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Row</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim)) <span class="comment">//与创建的RDD相匹配</span></div><div class="line"><span class="comment">// 通过SQLContext的createDataFrame方法对rowRDD应用schema</span></div><div class="line"><span class="keyword">val</span> df3 = sqlContext.createDataFrame(rowRDD, schema)</div></pre></td></tr></table></figure></p>
<p>上面代码df1、df2、df3都是DataFrame类型</p>
<p>DataFrame类型的一些常见的api操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Show the content of the DataFrame</span></div><div class="line">df.show()</div><div class="line"></div><div class="line"><span class="comment">// Print the schema in a tree format</span></div><div class="line">df.printSchema()</div><div class="line"></div><div class="line"><span class="comment">// Select only the "name" column</span></div><div class="line">df.select(<span class="string">"name"</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Select everybody, but increment the age by 1</span></div><div class="line">df.select(df(<span class="string">"name"</span>), df(<span class="string">"age"</span>) + <span class="number">1</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Select people older than 21</span></div><div class="line">df.filter(df(<span class="string">"age"</span>) &gt; <span class="number">21</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Count people by age</span></div><div class="line">df.groupBy(<span class="string">"age"</span>).count().show()</div></pre></td></tr></table></figure></p>
<p>下面是简单的sql操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 注册输入的DataFrame</span></div><div class="line">df2.registerTempTable(<span class="string">"people"</span>)</div><div class="line"></div><div class="line"><span class="comment">// SQL statements can be run by using the sql methods provided by sqlContext.</span></div><div class="line"><span class="keyword">val</span> teenagers = sqlContext.sql(<span class="string">"SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19"</span>)</div><div class="line"></div><div class="line"><span class="comment">// The results of SQL queries are DataFrames and support all the normal RDD operations.</span></div><div class="line"><span class="comment">// The columns of a row in the result can be accessed by field index:</span></div><div class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t(<span class="number">0</span>)).collect().foreach(println)</div><div class="line"></div><div class="line"><span class="comment">// or by field name:</span></div><div class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t.getAs[<span class="type">String</span>](<span class="string">"name"</span>)).collect().foreach(println)</div><div class="line"></div><div class="line"><span class="comment">// row.getValuesMap[T] retrieves multiple columns at once into a Map[String, T]</span></div><div class="line">teenagers.map(_.getValuesMap[<span class="type">Any</span>](<span class="type">List</span>(<span class="string">"name"</span>, <span class="string">"age"</span>))).collect().foreach(println)</div></pre></td></tr></table></figure></p>
<p>测试数据:<br>spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Michael, 29</div><div class="line">Andy, 30</div><div class="line">Justin, 19</div></pre></td></tr></table></figure></p>
<p>测试结果如图：<br><img src="/images/201701/SparkSql_1.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/22/SparkStreaming初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/22/SparkStreaming初体验/" itemprop="url">
                  SparkStreaming初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-22T15:53:39+08:00">
                2017-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkStreaming简单介绍"><a href="#SparkStreaming简单介绍" class="headerlink" title="SparkStreaming简单介绍"></a>SparkStreaming简单介绍</h2><p>Spark Streaming是建立在Spark上的实时计算框架<br>输入和输出概览：<br><img src="/images/201701/SparkStreaming_1.png"><br>Spark Streaming把实时输入数据流以时间片(如1秒)为单位切分成块。SparkStreaming会把每块数据作为一个RDD，并使用RDD操作处理每一小块数据<br><img src="/images/201701/SparkStreaming_2.png"></p>
<h2 id="例子-从kafka输入源-读取数据后-直接输出"><a href="#例子-从kafka输入源-读取数据后-直接输出" class="headerlink" title="例子:从kafka输入源 读取数据后 直接输出"></a>例子:从kafka输入源 读取数据后 直接输出</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</div><div class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">process_58_data</span> </span>&#123;</div><div class="line">  <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">ERROR</span>)</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> masterUrl = <span class="string">"local[2]"</span> <span class="comment">//不能local，需要两个核以上</span></div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(masterUrl).setAppName(<span class="string">"58_data"</span>)</div><div class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</div><div class="line">    <span class="keyword">val</span> topics = <span class="type">Set</span>(<span class="string">"58_data"</span>) <span class="comment">//kafka的topic</span></div><div class="line">    <span class="keyword">val</span> brokers = <span class="string">"master:9092,worker1:9092,worker2:9092"</span> <span class="comment">//kafka端口</span></div><div class="line">    <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">"metadata.broker.list"</span> -&gt; brokers)</div><div class="line">    <span class="keyword">val</span> kafkaStream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](ssc, kafkaParams, topics) <span class="comment">//调用Kafka工具包创建DSteam</span></div><div class="line">    kafkaStream.foreachRDD(rdd =&gt;&#123;</div><div class="line">      rdd.foreachPartition(iter =&gt; &#123;</div><div class="line">        iter.foreach( x =&gt;</div><div class="line">          println(x._2)</div><div class="line">        )</div><div class="line">      &#125;)</div><div class="line">    &#125;)</div><div class="line">    ssc.start() <span class="comment">//启动流计算环境StreamingContext</span></div><div class="line">    ssc.awaitTermination() <span class="comment">//等待作业完成</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之前写过简单的爬虫用来抓取网页信息，将数据放入kafka中，配合SparkStreaming，最后输出结果如下:<br><img src="/images/201701/SparkStreaming_3.png"></p>
<h2 id="SparkStreaming中DSteam转化操作"><a href="#SparkStreaming中DSteam转化操作" class="headerlink" title="SparkStreaming中DSteam转化操作"></a>SparkStreaming中DSteam转化操作</h2><h3 id="无状态："><a href="#无状态：" class="headerlink" title="无状态："></a>无状态：</h3><p>SparkStreaming是建立在Spark，所以很多RDD转化操作都适用于Dsteam.<br>例如: map, flatMap, filter, repartition, join, reduceByKey<br>(注: 针对键值对的Dsteam转化操作需要import StreamingContext._)</p>
<h3 id="有状态-SparkStreaming特有的操作-："><a href="#有状态-SparkStreaming特有的操作-：" class="headerlink" title="有状态(SparkStreaming特有的操作)："></a>有状态(SparkStreaming特有的操作)：</h3><p>滑动窗口和updateStateByKey<br>滑动窗口使用详情可以参考：<a href="http://blog.csdn.net/legotime/article/details/51836040" target="_blank" rel="external">http://blog.csdn.net/legotime/article/details/51836040</a></p>
<p>参考文档：<br><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a><br>《Spark快速大数据分析》</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/21/spark机器学习初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/21/spark机器学习初体验/" itemprop="url">
                  spark机器学习初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-21T18:19:48+08:00">
                2017-01-21
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="垃圾邮件分类例子"><a href="#垃圾邮件分类例子" class="headerlink" title="垃圾邮件分类例子"></a>垃圾邮件分类例子</h2><h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><p>垃圾邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">spam.txt</div><div class="line">Dear sir, I am a Prince in a far kingdom you have not heard of.  I want to send you money via wire transfer so please ...</div><div class="line">Get Viagra real cheap!  Send money right away to ...</div><div class="line">Oh my gosh you can be really strong too with these drugs found in the rainforest. Get them cheap right now ...</div><div class="line">YOUR COMPUTER HAS BEEN INFECTED!  YOU MUST RESET YOUR PASSWORD.  Reply to this email with your password and SSN ...</div><div class="line">THIS IS NOT A SCAM!  Send money and get access to awesome stuff really cheap and never have to ...</div></pre></td></tr></table></figure></p>
<p>正常邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ham.txt</div><div class="line">Dear Spark Learner, Thanks so much for attending the Spark Summit 2014!  Check out videos of talks from the summit at ...</div><div class="line">Hi Mom, Apologies for being late about emailing and forgetting to send you the package.  I hope you and bro have been ...</div><div class="line">Wow, hey Fred, just heard about the Spark petabyte sort.  I think we need to take time to try it out immediately ...</div><div class="line">Hi Spark user list, This is my first question to this list, so thanks in advance for your help!  I tried running ...</div><div class="line">Thanks Tom for your email.  I need to refer you to Alice for this one.  I haven&apos;t yet figured out that part either ...</div><div class="line">Good job yesterday!  I was attending your talk, and really enjoyed it.  I want to try out GraphX ...</div><div class="line">Summit demo got whoops from audience!  Had to let you know. --Joe</div></pre></td></tr></table></figure></p>
<h3 id="Scala代码"><a href="#Scala代码" class="headerlink" title="Scala代码"></a>Scala代码</h3><p>这个程序使用了MLlib两个函数：HashingTF(从文本数据构建 词频特征向量)和LogisticRegressionWithSGD(随机体度下降法实现逻辑回归)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.<span class="type">LogisticRegressionWithSGD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.feature.<span class="type">HashingTF</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">MLlib</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">s"Book example: Scala"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line"></div><div class="line">    <span class="comment">// Load 2 types of emails from text files: spam and ham (non-spam).</span></div><div class="line">    <span class="comment">// Each line has text from one email.</span></div><div class="line">    <span class="keyword">val</span> spam = sc.textFile(<span class="string">"files/spam.txt"</span>)</div><div class="line">    <span class="keyword">val</span> ham = sc.textFile(<span class="string">"files/ham.txt"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Create a HashingTF instance to map email text to vectors of 100 features.</span></div><div class="line">    <span class="keyword">val</span> tf = <span class="keyword">new</span> <span class="type">HashingTF</span>(numFeatures = <span class="number">100</span>)</div><div class="line">    <span class="comment">// Each email is split into words, and each word is mapped to one feature.</span></div><div class="line">    <span class="comment">// 1、特征提取</span></div><div class="line">    <span class="keyword">val</span> spamFeatures = spam.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line">    <span class="keyword">val</span> hamFeatures = ham.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line"></div><div class="line">    <span class="comment">// Create LabeledPoint datasets for positive (spam) and negative (ham) examples.</span></div><div class="line">    <span class="comment">// 2、将文本数据转换为数值特征，返回LabeledPoint类型RDD(包含一个特质向量和一个标签)</span></div><div class="line">    <span class="keyword">val</span> positiveExamples = spamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">1</span>, features))</div><div class="line">    <span class="keyword">val</span> negativeExamples = hamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">0</span>, features))</div><div class="line">    <span class="keyword">val</span> trainingData = positiveExamples ++ negativeExamples</div><div class="line">    trainingData.cache() <span class="comment">// Cache data since Logistic Regression is an iterative algorithm.</span></div><div class="line"></div><div class="line">    <span class="comment">// Create a Logistic Regression learner which uses the LBFGS optimizer.</span></div><div class="line">    <span class="comment">// 3、调用分类算法，返回模型对象</span></div><div class="line">    <span class="keyword">val</span> lrLearner = <span class="keyword">new</span> <span class="type">LogisticRegressionWithSGD</span>()</div><div class="line">    <span class="comment">// Run the actual learning algorithm on the training data.</span></div><div class="line">    <span class="keyword">val</span> model = lrLearner.run(trainingData)</div><div class="line"></div><div class="line">    <span class="comment">// Test on a positive example (spam) and a negative one (ham).</span></div><div class="line">    <span class="comment">// First apply the same HashingTF feature transformation used on the training data.</span></div><div class="line">    <span class="keyword">val</span> posTestExample = tf.transform(<span class="string">"O M G GET cheap stuff by sending money to ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="keyword">val</span> negTestExample = tf.transform(<span class="string">"Hi Dad, I started studying Spark the other ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="comment">// Now use the learned model to predict spam/ham for new emails.</span></div><div class="line">    println(<span class="string">s"Prediction for positive test example: <span class="subst">$&#123;model.predict(posTestExample)&#125;</span>"</span>)</div><div class="line">    println(<span class="string">s"Prediction for negative test example: <span class="subst">$&#123;model.predict(negTestExample)&#125;</span>"</span>)</div><div class="line"></div><div class="line">    sc.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>运行结果如果所示：<br><img src="/images/201701/SparkML_1.png"></p>
<h2 id="机器学习流水线中典型步骤"><a href="#机器学习流水线中典型步骤" class="headerlink" title="机器学习流水线中典型步骤"></a>机器学习流水线中典型步骤</h2><p>源数据ETL-&gt;数据预处理-&gt;特征提取(返回MLlib的数据类型，比如上例的LabeledPoint类型)-&gt;训练(返回模型)-&gt;模型评估</p>
<h2 id="简单理解"><a href="#简单理解" class="headerlink" title="简单理解"></a>简单理解</h2><p>确定模型—-训练模型—-使用模型<br>模型简单说可以理解为函数。<br>确定模型是说自己认为这些数据的特征符合哪个函数(应该使用什么模型)<br>训练模型就是用已有的数据，通过一些方法（最优化或者其他方法）确定函数的参数，参数确定后的函数就是训练的结果<br>使用模型就是把新的数据代入函数求值</p>
<p>参考文档：<br>《Spark快速大数据分析》<br><a href="https://www.zhihu.com/question/29271217?sort=created" target="_blank" rel="external">https://www.zhihu.com/question/29271217?sort=created</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/20/spark源码浅析-提交Task到Executor/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/20/spark源码浅析-提交Task到Executor/" itemprop="url">
                  spark源码浅析：提交Task到Executor
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-20T16:15:23+08:00">
                2017-01-20
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="从DAGScheduler-submitMissingTasks-开始追源码"><a href="#从DAGScheduler-submitMissingTasks-开始追源码" class="headerlink" title="从DAGScheduler.submitMissingTasks 开始追源码"></a>从DAGScheduler.submitMissingTasks 开始追源码</h2><p>DAGScheduler.submitMissingTasks主要功能<br>1、找到RDD中需要计算的partition<br>2、获取Task的最佳计算位置<br>3、序列化Task的Binary，并进行广播<br>4、根据stage的不同类型创建，为stage的每个分区创建创建task,并封装成TaskSet<br>5、调用TaskScheduler的submitTasks，提交TaskSet<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** Called when stage's parents are available and we can now do its task. */</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>) &#123;</div><div class="line">  logDebug(<span class="string">"submitMissingTasks("</span> + stage + <span class="string">")"</span>)</div><div class="line">  <span class="comment">// Get our pending tasks and remember them in our pendingTasks entry</span></div><div class="line">  stage.pendingPartitions.clear()</div><div class="line"></div><div class="line">  <span class="comment">// First figure out the indexes of partition ids to compute.</span></div><div class="line">  <span class="comment">// 1、找到RDD中需要计算的partition</span></div><div class="line">  <span class="comment">// 对于Shuffle类型的Stage，需要判断stage中是否缓存了该结果</span></div><div class="line">  <span class="comment">// 对于Result类型的Stage，则判断计算Job中该partition是否已经计算完成</span></div><div class="line">  <span class="keyword">val</span> partitionsToCompute: <span class="type">Seq</span>[<span class="type">Int</span>] = stage.findMissingPartitions()</div><div class="line"></div><div class="line">  <span class="comment">// Create internal accumulators if the stage has no accumulators initialized.</span></div><div class="line">  <span class="comment">// Reset internal accumulators only if this stage is not partially submitted</span></div><div class="line">  <span class="comment">// Otherwise, we may override existing accumulator values from some tasks</span></div><div class="line">  <span class="keyword">if</span> (stage.internalAccumulators.isEmpty || stage.numPartitions == partitionsToCompute.size) &#123;</div><div class="line">    stage.resetInternalAccumulators()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Use the scheduling pool, job group, description, etc. from an ActiveJob associated</span></div><div class="line">  <span class="comment">// with this Stage</span></div><div class="line">  <span class="keyword">val</span> properties = jobIdToActiveJob(jobId).properties</div><div class="line"></div><div class="line">  runningStages += stage</div><div class="line">  <span class="comment">// SparkListenerStageSubmitted should be posted before testing whether tasks are</span></div><div class="line">  <span class="comment">// serializable. If tasks are not serializable, a SparkListenerStageCompleted event</span></div><div class="line">  <span class="comment">// will be posted, which should always come after a corresponding SparkListenerStageSubmitted</span></div><div class="line">  <span class="comment">// event.</span></div><div class="line">  stage <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - <span class="number">1</span>)</div><div class="line">    <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</div><div class="line">      outputCommitCoordinator.stageStart(</div><div class="line">        stage = s.id, maxPartitionId = s.rdd.partitions.length - <span class="number">1</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 2、获取Task的最佳计算位置</span></div><div class="line">  <span class="comment">// 根据RDD的数据信息得到task的最佳计算位置，从而获取较好的数据本地性</span></div><div class="line">  <span class="keyword">val</span> taskIdToLocations: <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">TaskLocation</span>]] = <span class="keyword">try</span> &#123;</div><div class="line">    stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap</div><div class="line">      <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="keyword">val</span> job = s.activeJob.get</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> p = s.partitions(id)</div><div class="line">          (id, getPreferredLocs(stage.rdd, p))</div><div class="line">        &#125;.toMap</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      stage.makeNewStageAttempt(partitionsToCompute.size)</div><div class="line">      listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</div><div class="line">      abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)</div><div class="line">  listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</div><div class="line"></div><div class="line">  <span class="comment">// <span class="doctag">TODO:</span> Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.</span></div><div class="line">  <span class="comment">// Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast</span></div><div class="line">  <span class="comment">// the serialized copy of the RDD and for each task we will deserialize it, which means each</span></div><div class="line">  <span class="comment">// task gets a different copy of the RDD. This provides stronger isolation between tasks that</span></div><div class="line">  <span class="comment">// might modify state of objects referenced in their closures. This is necessary in Hadoop</span></div><div class="line">  <span class="comment">// where the JobConf/Configuration object is not thread-safe.</span></div><div class="line">  <span class="comment">// 3、序列化Task的Binary，并进行广播</span></div><div class="line">  <span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).</span></div><div class="line">    <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).</span></div><div class="line">    <span class="keyword">val</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>).array()</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">        closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>).array()</div><div class="line">    &#125;</div><div class="line">    taskBinary = sc.broadcast(taskBinaryBytes)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="comment">// In the case of a failure during serialization, abort the stage.</span></div><div class="line">    <span class="keyword">case</span> e: <span class="type">NotSerializableException</span> =&gt;</div><div class="line">      abortStage(stage, <span class="string">"Task not serializable: "</span> + e.toString, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line"></div><div class="line">      <span class="comment">// Abort execution</span></div><div class="line">      <span class="keyword">return</span></div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      abortStage(stage, <span class="string">s"Task serialization failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 4、根据stage的不同类型创建，为stage的每个分区创建创建task,并封装成TaskSet</span></div><div class="line">  <span class="comment">// Stage分两种类型ShuffleMapStage生成ShuffleMapTask，ResultStage生成ResultTask</span></div><div class="line">  <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</div><div class="line">    stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">          <span class="keyword">val</span> part = stage.rdd.partitions(id)</div><div class="line">          <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">            taskBinary, part, locs, stage.internalAccumulators)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="keyword">val</span> job = stage.activeJob.get</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</div><div class="line">          <span class="keyword">val</span> part = stage.rdd.partitions(p)</div><div class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">          <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">            taskBinary, part, locs, id, stage.internalAccumulators)</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</div><div class="line">    logInfo(<span class="string">"Submitting "</span> + tasks.size + <span class="string">" missing tasks from "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">")"</span>)</div><div class="line">    stage.pendingPartitions ++= tasks.map(_.partitionId)</div><div class="line">    logDebug(<span class="string">"New pending partitions: "</span> + stage.pendingPartitions)</div><div class="line">    <span class="comment">// 5、调用TaskScheduler的submitTasks，提交TaskSet</span></div><div class="line">    taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</div><div class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))</div><div class="line">    stage.latestInfo.submissionTime = <span class="type">Some</span>(clock.getTimeMillis())</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// Because we posted SparkListenerStageSubmitted earlier, we should mark</span></div><div class="line">    <span class="comment">// the stage as completed here in case there are no tasks to run</span></div><div class="line">    markStageAsFinished(stage, <span class="type">None</span>)</div><div class="line">    <span class="keyword">val</span> debugString = stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        <span class="string">s"Stage <span class="subst">$&#123;stage&#125;</span> is actually done; "</span> +</div><div class="line">          <span class="string">s"(available: <span class="subst">$&#123;stage.isAvailable&#125;</span>,"</span> +</div><div class="line">          <span class="string">s"available outputs: <span class="subst">$&#123;stage.numAvailableOutputs&#125;</span>,"</span> +</div><div class="line">          <span class="string">s"partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)"</span></div><div class="line">      <span class="keyword">case</span> stage : <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="string">s"Stage <span class="subst">$&#123;stage&#125;</span> is actually done; (partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)"</span></div><div class="line">    &#125;</div><div class="line">    logDebug(debugString)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSchedulerImpl-submitTasks"><a href="#TaskSchedulerImpl-submitTasks" class="headerlink" title="TaskSchedulerImpl.submitTasks"></a>TaskSchedulerImpl.submitTasks</h2><p>TaskSchedulerImpl.submitTasks主要功能<br>1、创建TaskSetManager<br>2、将TaskSetManager加入rootPool调度池中，由schedulableBuilder决定调度顺序<br>3、调用SchedulerBackend的reviveOffers方法对Task进行调度，决定task具体运行在哪个Executor中<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.submitTasks</div><div class="line">  <span class="comment">/*</span></div><div class="line">  * 主要将任务加入调度池，最后调用了backend.reviveOffers()</div><div class="line">  * 这里的backend是CoarseGrainedSchedulerBackend一个Executor任务调度对象</div><div class="line">  */</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">submitTasks</span></span>(taskSet: <span class="type">TaskSet</span>) &#123;</div><div class="line">    <span class="keyword">val</span> tasks = taskSet.tasks</div><div class="line">    logInfo(<span class="string">"Adding task set "</span> + taskSet.id + <span class="string">" with "</span> + tasks.length + <span class="string">" tasks"</span>)</div><div class="line">    <span class="keyword">this</span>.synchronized &#123;</div><div class="line">      <span class="comment">// 1、创建TaskSetManager</span></div><div class="line">      <span class="comment">// TaskSetManager会负责task的失败重试；跟踪每个task的执行状态；处理locality-aware的调用。</span></div><div class="line">      <span class="keyword">val</span> manager = createTaskSetManager(taskSet, maxTaskFailures)</div><div class="line">      <span class="keyword">val</span> stage = taskSet.stageId</div><div class="line">      <span class="keyword">val</span> stageTaskSets =</div><div class="line">        taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">TaskSetManager</span>])</div><div class="line">      stageTaskSets(taskSet.stageAttemptId) = manager</div><div class="line">      <span class="keyword">val</span> conflictingTaskSet = stageTaskSets.exists &#123; <span class="keyword">case</span> (_, ts) =&gt;</div><div class="line">        ts.taskSet != taskSet &amp;&amp; !ts.isZombie</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (conflictingTaskSet) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"more than one active taskSet for stage <span class="subst">$stage</span>:"</span> +</div><div class="line">          <span class="string">s" <span class="subst">$&#123;stageTaskSets.toSeq.map&#123;_._2.taskSet.id&#125;</span>.mkString("</span>,<span class="string">")&#125;"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// 2、将TaskSetManager加入rootPool调度池中，由schedulableBuilder决定调度顺序</span></div><div class="line">      <span class="comment">// SchedulerBuilder有两个实现FIFOSchedulerBuilder和FairSchedulerBuilder，默认采用的是FIFO方式</span></div><div class="line">      schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!isLocal &amp;&amp; !hasReceivedTask) &#123;</div><div class="line">        starvationTimer.scheduleAtFixedRate(<span class="keyword">new</span> <span class="type">TimerTask</span>() &#123;</div><div class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">            <span class="keyword">if</span> (!hasLaunchedTask) &#123;</div><div class="line">              logWarning(<span class="string">"Initial job has not accepted any resources; "</span> +</div><div class="line">                <span class="string">"check your cluster UI to ensure that workers are registered "</span> +</div><div class="line">                <span class="string">"and have sufficient resources"</span>)</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">              <span class="keyword">this</span>.cancel()</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;, <span class="type">STARVATION_TIMEOUT_MS</span>, <span class="type">STARVATION_TIMEOUT_MS</span>)</div><div class="line">      &#125;</div><div class="line">      hasReceivedTask = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 3、调用SchedulerBackend的reviveOffers方法对Task进行调度，决定task具体运行在哪个Executor中</span></div><div class="line">    backend.reviveOffers()</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>调用CoarseGrainedSchedulerBackend的reviveOffers方法，该方法给driverEndpoint发送ReviveOffer消息</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="type">CoarseGrainedSchedulerBackend</span>.reviveOffers</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>() &#123;</div><div class="line">    driverEndpoint.send(<span class="type">ReviveOffers</span>)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>driverEndpoint收到ReviveOffer消息后调用makeOffers方法</p>
<h2 id="CoarseGrainedSchedulerBackend-makeOffers"><a href="#CoarseGrainedSchedulerBackend-makeOffers" class="headerlink" title="CoarseGrainedSchedulerBackend.makeOffers"></a>CoarseGrainedSchedulerBackend.makeOffers</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="type">CoarseGrainedSchedulerBackend</span>.makeOffers</div><div class="line">    <span class="comment">// Make fake resource offers on all executor</span></div><div class="line">    <span class="comment">// makeOffers方法中，将Executor的信息集合与调度池中的Tasks封装成WokerOffers列表传给了 launchTasks</span></div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeOffers</span></span>() &#123;</div><div class="line">      <span class="comment">// Filter out executors under killing</span></div><div class="line">      <span class="comment">// 过滤出活跃状态的Executor</span></div><div class="line">      <span class="keyword">val</span> activeExecutors = executorDataMap.filterKeys(executorIsAlive)</div><div class="line">      <span class="comment">// 将Executor封装成WorkerOffer对象</span></div><div class="line">      <span class="keyword">val</span> workOffers = activeExecutors.map &#123; <span class="keyword">case</span> (id, executorData) =&gt;</div><div class="line">        <span class="keyword">new</span> <span class="type">WorkerOffer</span>(id, executorData.executorHost, executorData.freeCores)</div><div class="line">      &#125;.toSeq</div><div class="line">      launchTasks(scheduler.resourceOffers(workOffers))</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>注意：上面代码中的executorDataMap，在客户端向Master注册Application的时候，Master已经为Application分配并启动好Executor，然后注册给CoarseGrainedSchedulerBackend，注册信息就是存储在executorDataMap数据结构中。</p>
<h2 id="TaskSchedulerImpl-resourceOffers"><a href="#TaskSchedulerImpl-resourceOffers" class="headerlink" title="TaskSchedulerImpl.resourceOffers"></a>TaskSchedulerImpl.resourceOffers</h2><p>准备好计算资源后，接下来TaskSchedulerImpl基于这些计算资源为task分配Executor<br>看一下TaskSchedulerImpl的resourceOffers方法：<br>传递的参数offers表示worker提供的资源，该方法根据资源情况，结合待执行任务的优先级，将任务平衡的分配给executors<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.resourceOffers</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Called by cluster manager to offer resources on slaves. We respond by asking our active task</div><div class="line">   * sets for tasks in order of priority. We fill each node with tasks in a round-robin manner so</div><div class="line">   * that tasks are balanced across the cluster.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">resourceOffers</span></span>(offers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>]): <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]] = synchronized &#123;</div><div class="line">    <span class="comment">// Mark each slave as alive and remember its hostname</span></div><div class="line">    <span class="comment">// Also track if new executor is added</span></div><div class="line">    <span class="comment">// 激活所有slave节点，记录其hostname，并检查是否有新的executor加入</span></div><div class="line">    <span class="keyword">var</span> newExecAvail = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (o &lt;- offers) &#123;</div><div class="line">      executorIdToHost(o.executorId) = o.host</div><div class="line">      executorIdToTaskCount.getOrElseUpdate(o.executorId, <span class="number">0</span>)</div><div class="line">      <span class="keyword">if</span> (!executorsByHost.contains(o.host)) &#123;</div><div class="line">        executorsByHost(o.host) = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()</div><div class="line">        executorAdded(o.executorId, o.host)</div><div class="line">        newExecAvail = <span class="literal">true</span></div><div class="line">      &#125;</div><div class="line">      <span class="keyword">for</span> (rack &lt;- getRackForHost(o.host)) &#123;</div><div class="line">        hostsByRack.getOrElseUpdate(rack, <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()) += o.host</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Randomly shuffle offers to avoid always placing tasks on the same set of workers.</span></div><div class="line">    <span class="comment">// 随机打乱offers,避免总是前几个worker被分配到任务</span></div><div class="line">    <span class="keyword">val</span> shuffledOffers = <span class="type">Random</span>.shuffle(offers)</div><div class="line">    <span class="comment">// Build a list of tasks to assign to each worker.</span></div><div class="line">    <span class="comment">// 构建一个二维数组，保存每个Executor上将要分配的那些task</span></div><div class="line">    <span class="keyword">val</span> tasks = shuffledOffers.map(o =&gt; <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>](o.cores))</div><div class="line">    <span class="keyword">val</span> availableCpus = shuffledOffers.map(o =&gt; o.cores).toArray</div><div class="line">    <span class="comment">// 根据SchedulerBuilder的调度算法，给TaskManager排好序</span></div><div class="line">    <span class="keyword">val</span> sortedTaskSets = rootPool.getSortedTaskSetQueue</div><div class="line">    <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets) &#123;</div><div class="line">      logDebug(<span class="string">"parentName: %s, name: %s, runningTasks: %s"</span>.format(</div><div class="line">        taskSet.parent.name, taskSet.name, taskSet.runningTasks))</div><div class="line">      <span class="keyword">if</span> (newExecAvail) &#123;</div><div class="line">        taskSet.executorAdded()</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Take each TaskSet in our scheduling order, and then offer it each node in increasing order</span></div><div class="line">    <span class="comment">// of locality levels so that it gets a chance to launch local tasks on all of them.</span></div><div class="line">    <span class="comment">// <span class="doctag">NOTE:</span> the preferredLocality order: PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></div><div class="line">    <span class="comment">// 按照调度优先级顺序遍历TaskSet，在所有系统资源(WorkerOffer)上从最高Locality到最低Locality依次尝试执行最适合的task</span></div><div class="line">    <span class="comment">// 数据本地性级别顺序: PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></div><div class="line">    <span class="keyword">var</span> launchedTask = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets; maxLocality &lt;- taskSet.myLocalityLevels) &#123;</div><div class="line">      do &#123;</div><div class="line">        launchedTask = resourceOfferSingleTaskSet(</div><div class="line">            taskSet, maxLocality, shuffledOffers, availableCpus, tasks)</div><div class="line">      &#125; <span class="keyword">while</span> (launchedTask)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</div><div class="line">      hasLaunchedTask = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> tasks</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSchedulerImpl-resourceOfferSingleTaskSet"><a href="#TaskSchedulerImpl-resourceOfferSingleTaskSet" class="headerlink" title="TaskSchedulerImpl.resourceOfferSingleTaskSet"></a>TaskSchedulerImpl.resourceOfferSingleTaskSet</h2><p>下面再看看resourceOfferSingleTaskSet代码<br>用当前的数据本地性，调用TaskSetManager的resourceOffer方法，在当前executor上分配task<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.resourceOfferSingleTaskSet</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">resourceOfferSingleTaskSet</span></span>(</div><div class="line">      taskSet: <span class="type">TaskSetManager</span>,</div><div class="line">      maxLocality: <span class="type">TaskLocality</span>,</div><div class="line">      shuffledOffers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>],</div><div class="line">      availableCpus: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">      tasks: <span class="type">Seq</span>[<span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>]]) : <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">var</span> launchedTask = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until shuffledOffers.size) &#123;</div><div class="line">      <span class="keyword">val</span> execId = shuffledOffers(i).executorId</div><div class="line">      <span class="keyword">val</span> host = shuffledOffers(i).host</div><div class="line">      <span class="comment">// 判断executor是否有足够的CPU核数来运行task</span></div><div class="line">      <span class="keyword">if</span> (availableCpus(i) &gt;= <span class="type">CPUS_PER_TASK</span>) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="comment">// 真正调用的是TaskSetManager.resourceOffer方法</span></div><div class="line">          <span class="keyword">for</span> (task &lt;- taskSet.resourceOffer(execId, host, maxLocality)) &#123;</div><div class="line">            tasks(i) += task</div><div class="line">            <span class="keyword">val</span> tid = task.taskId</div><div class="line">            taskIdToTaskSetManager(tid) = taskSet</div><div class="line">            taskIdToExecutorId(tid) = execId</div><div class="line">            executorIdToTaskCount(execId) += <span class="number">1</span></div><div class="line">            executorsByHost(host) += execId</div><div class="line">            availableCpus(i) -= <span class="type">CPUS_PER_TASK</span></div><div class="line">            assert(availableCpus(i) &gt;= <span class="number">0</span>)</div><div class="line">            launchedTask = <span class="literal">true</span></div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="keyword">case</span> e: <span class="type">TaskNotSerializableException</span> =&gt;</div><div class="line">            logError(<span class="string">s"Resource offer failed, task set <span class="subst">$&#123;taskSet.name&#125;</span> was not serializable"</span>)</div><div class="line">            <span class="comment">// Do not offer resources for this task, but don't throw an error to allow other</span></div><div class="line">            <span class="comment">// task sets to be submitted.</span></div><div class="line">            <span class="keyword">return</span> launchedTask</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> launchedTask</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSetManager-resourceOffer"><a href="#TaskSetManager-resourceOffer" class="headerlink" title="TaskSetManager.resourceOffer"></a>TaskSetManager.resourceOffer</h2><p>TaskSetManager.resourceOffer方法的作用是为executor资源提供一个最符合数据本地性的任务<br>TaskLocality是枚举类，表示数据本地化的级别，其优先级为 PROCESS_LOCAL(最高) &lt; NODE_LOCAL &lt; NO_PREF &lt; RACK_LOCAL &lt; ANY(最低)<br>其中PROCESS_LOCAL，NODE_LOCAL，RACK_LOCAL可分别设置对应的延迟时间，默认值是3s<br>TaskSetManager内部维护了以下几个HashMap<br>1、pendingTasksForExecutor<br>2、pendingTasksForHost<br>3、pendingTasksForRack<br>4、pendingTasksWithNoPrefs<br>TaskSetManager在初始化时，若Task的preferredLocations不为空，则将Task添加到前三个pending队列；若为空，则加入pendingTasksWithNoPrefs<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// TaskSetManager.resourceOffer</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">resourceOffer</span></span>(</div><div class="line">    execId: <span class="type">String</span>,</div><div class="line">    host: <span class="type">String</span>,</div><div class="line">    maxLocality: <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span>)</div><div class="line">  : <span class="type">Option</span>[<span class="type">TaskDescription</span>] =</div><div class="line">&#123;</div><div class="line">  <span class="keyword">if</span> (!isZombie) &#123;</div><div class="line">    <span class="keyword">val</span> curTime = clock.getTimeMillis()</div><div class="line"></div><div class="line">    <span class="keyword">var</span> allowedLocality = maxLocality</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</div><div class="line">      <span class="comment">// 结合各Locality设置的延迟时间及上次成功在当前Locality级别提交任务的时间，获得能够允许的最高本地化级别的Locality级别</span></div><div class="line">      allowedLocality = getAllowedLocalityLevel(curTime)</div><div class="line">      <span class="comment">// 大于表示本地化级别更低</span></div><div class="line">      <span class="keyword">if</span> (allowedLocality &gt; maxLocality) &#123;</div><div class="line">        <span class="comment">// </span></div><div class="line">        allowedLocality = maxLocality</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// dequeueTask返回的是允许的Locality范围内Locality级别最高的Task的TaskDescription</span></div><div class="line">    dequeueTask(execId, host, allowedLocality) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>((index, taskLocality, speculative)) =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> task = tasks(index)</div><div class="line">        <span class="keyword">val</span> taskId = sched.newTaskId()</div><div class="line">        <span class="comment">// Do various bookkeeping</span></div><div class="line">        copiesRunning(index) += <span class="number">1</span></div><div class="line">        <span class="keyword">val</span> attemptNum = taskAttempts(index).size</div><div class="line">        <span class="keyword">val</span> info = <span class="keyword">new</span> <span class="type">TaskInfo</span>(taskId, index, attemptNum, curTime,</div><div class="line">          execId, host, taskLocality, speculative)</div><div class="line">        taskInfos(taskId) = info</div><div class="line">        taskAttempts(index) = info :: taskAttempts(index)</div><div class="line">        <span class="comment">// 除非Task的Locality级别为NO_PREF，否则更新当前Locality级别为该task的Locality，并更新lastLaunchTime</span></div><div class="line">        <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</div><div class="line">          currentLocalityIndex = getLocalityIndex(taskLocality)</div><div class="line">          lastLaunchTime = curTime</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 序列化task</span></div><div class="line">        <span class="keyword">val</span> startTime = clock.getTimeMillis()</div><div class="line">        <span class="keyword">val</span> serializedTask: <span class="type">ByteBuffer</span> = <span class="keyword">try</span> &#123;</div><div class="line">          <span class="type">Task</span>.serializeWithDependencies(task, sched.sc.addedFiles, sched.sc.addedJars, ser)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="comment">// 序列化出错没有重试的必要</span></div><div class="line">          <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">            <span class="keyword">val</span> msg = <span class="string">s"Failed to serialize task <span class="subst">$taskId</span>, not attempting to retry it."</span></div><div class="line">            logError(msg, e)</div><div class="line">            abort(<span class="string">s"<span class="subst">$msg</span> Exception during serialization: <span class="subst">$e</span>"</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">TaskNotSerializableException</span>(e)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 若task过大，则存在优化的必要</span></div><div class="line">        <span class="keyword">if</span> (serializedTask.limit &gt; <span class="type">TaskSetManager</span>.<span class="type">TASK_SIZE_TO_WARN_KB</span> * <span class="number">1024</span> &amp;&amp;</div><div class="line">            !emittedTaskSizeWarning) &#123;</div><div class="line">          emittedTaskSizeWarning = <span class="literal">true</span></div><div class="line">          logWarning(<span class="string">s"Stage <span class="subst">$&#123;task.stageId&#125;</span> contains a task of very large size "</span> +</div><div class="line">            <span class="string">s"(<span class="subst">$&#123;serializedTask.limit / 1024&#125;</span> KB). The maximum recommended task size is "</span> +</div><div class="line">            <span class="string">s"<span class="subst">$&#123;TaskSetManager.TASK_SIZE_TO_WARN_KB&#125;</span> KB."</span>)</div><div class="line">        &#125;</div><div class="line">        addRunningTask(taskId)</div><div class="line"></div><div class="line">        <span class="comment">// We used to log the time it takes to serialize the task, but task size is already</span></div><div class="line">        <span class="comment">// a good proxy to task serialization time.</span></div><div class="line">        <span class="comment">// val timeTaken = clock.getTime() - startTime</span></div><div class="line">        <span class="keyword">val</span> taskName = <span class="string">s"task <span class="subst">$&#123;info.id&#125;</span> in stage <span class="subst">$&#123;taskSet.id&#125;</span>"</span></div><div class="line">        logInfo(<span class="string">"Starting %s (TID %d, %s, %s, %d bytes)"</span>.format(</div><div class="line">            taskName, taskId, host, taskLocality, serializedTask.limit))</div><div class="line"></div><div class="line">        <span class="comment">// 通知DAGScheduler任务开始执行</span></div><div class="line">        sched.dagScheduler.taskStarted(task, info)</div><div class="line">        <span class="keyword">return</span> <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">TaskDescription</span>(taskId = taskId, attemptNumber = attemptNum, execId,</div><div class="line">          taskName, index, serializedTask))</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> _ =&gt;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="type">None</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSetManager-getAllowedLocalityLevel"><a href="#TaskSetManager-getAllowedLocalityLevel" class="headerlink" title="TaskSetManager.getAllowedLocalityLevel"></a>TaskSetManager.getAllowedLocalityLevel</h2><p>TaskSetManager.getAllowedLocalityLevel结合各Locality设置的延迟时间及上次成功在当前Locality级别提交任务的时间，获得能够允许的最高本地化级别的Locality级别<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// TaskSetManager.getAllowedLocalityLevel</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getAllowedLocalityLevel</span></span>(curTime: <span class="type">Long</span>): <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span> = &#123;</div><div class="line">  <span class="comment">// 移除已被调度或完成的task，采用的是lazy方式</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tasksNeedToBeScheduledFrom</span></span>(pendingTaskIds: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">var</span> indexOffset = pendingTaskIds.size</div><div class="line">    <span class="keyword">while</span> (indexOffset &gt; <span class="number">0</span>) &#123;</div><div class="line">      indexOffset -= <span class="number">1</span></div><div class="line">      <span class="keyword">val</span> index = pendingTaskIds(indexOffset)</div><div class="line">      <span class="keyword">if</span> (copiesRunning(index) == <span class="number">0</span> &amp;&amp; !successful(index)) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="literal">true</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        pendingTaskIds.remove(indexOffset)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="literal">false</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 遍历pendingTasks，移除已被调度的task，若仍有task待调度，返回true</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">moreTasksToRunIn</span></span>(pendingTasks: <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]]): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">val</span> emptyKeys = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">String</span>]</div><div class="line">    <span class="keyword">val</span> hasTasks = pendingTasks.exists &#123;</div><div class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, tasks: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]) =&gt;</div><div class="line">        <span class="keyword">if</span> (tasksNeedToBeScheduledFrom(tasks)) &#123;</div><div class="line">          <span class="literal">true</span></div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          emptyKeys += id</div><div class="line">          <span class="literal">false</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// The key could be executorId, host or rackId</span></div><div class="line">    emptyKeys.foreach(id =&gt; pendingTasks.remove(id))</div><div class="line">    hasTasks</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// currentLocalityIndex记录了当前运行在哪个TaskLocality</span></div><div class="line">  <span class="keyword">while</span> (currentLocalityIndex &lt; myLocalityLevels.length - <span class="number">1</span>) &#123;</div><div class="line">    <span class="keyword">val</span> moreTasks = myLocalityLevels(currentLocalityIndex) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">PROCESS_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForExecutor)</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">NODE_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForHost)</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span> =&gt; pendingTasksWithNoPrefs.nonEmpty</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">RACK_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForRack)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (!moreTasks) &#123;</div><div class="line">      <span class="comment">// 若当前Locality没有需要执行的task，则进入更低一级Locality，并更新lastLaunchTime</span></div><div class="line">      lastLaunchTime = curTime</div><div class="line">      logDebug(<span class="string">s"No tasks for locality level <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex)&#125;</span>, "</span> +</div><div class="line">        <span class="string">s"so moving to locality level <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex + 1)&#125;</span>"</span>)</div><div class="line">      currentLocalityIndex += <span class="number">1</span></div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curTime - lastLaunchTime &gt;= localityWaits(currentLocalityIndex)) &#123;</div><div class="line">      <span class="comment">// 若距离上次成功在此Locality级别提交任务的时间间隔超过了该Locality级别设定的延迟时间，则进入更低一级Locality，并更新lastLaunchTime</span></div><div class="line">      lastLaunchTime += localityWaits(currentLocalityIndex)</div><div class="line">      currentLocalityIndex += <span class="number">1</span></div><div class="line">      logDebug(<span class="string">s"Moving to <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex)&#125;</span> after waiting for "</span> +</div><div class="line">        <span class="string">s"<span class="subst">$&#123;localityWaits(currentLocalityIndex)&#125;</span>ms"</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> myLocalityLevels(currentLocalityIndex)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  myLocalityLevels(currentLocalityIndex)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>取得最适合运行的Task后，调用ScheduledBackend.launchTasks方法 将task在Executor上启动运行</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="http://www.cnblogs.com/zhouyf/p/5743382.html" target="_blank" rel="external">http://www.cnblogs.com/zhouyf/p/5743382.html</a><br><a href="http://blog.csdn.net/anzhsoft/article/details/40238111#comments" target="_blank" rel="external">http://blog.csdn.net/anzhsoft/article/details/40238111#comments</a><br><a href="http://blog.csdn.net/bigdata_wang/article/details/48846129" target="_blank" rel="external">http://blog.csdn.net/bigdata_wang/article/details/48846129</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/19/hbase分布式搭建/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/19/hbase分布式搭建/" itemprop="url">
                  hbase分布式搭建
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-19T11:45:40+08:00">
                2017-01-19
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="已有的环境"><a href="#已有的环境" class="headerlink" title="已有的环境"></a>已有的环境</h2><p>三台机器hostname: master, worker1, worker2<br>并已安装好分布式Hadoop2.6.0</p>
<h3 id="定位JAVA-HOME"><a href="#定位JAVA-HOME" class="headerlink" title="定位JAVA_HOME"></a>定位JAVA_HOME</h3><p>mac: 使用命令/usr/libexec/java_home<br><img src="/images/201701/JAVA_HOME_2.png"><br>linux: 如下图所示<br><img src="/images/201701/JAVA_HOME_1.png"></p>
<h2 id="下载HBase"><a href="#下载HBase" class="headerlink" title="下载HBase"></a>下载HBase</h2><p>官网下载地址：<a href="http://www.apache.org/dyn/closer.cgi/hbase/" target="_blank" rel="external">http://www.apache.org/dyn/closer.cgi/hbase/</a><br>我下载的是Stable版本：<a href="http://mirrors.cnnic.cn/apache/hbase/stable/hbase-1.2.4-bin.tar.gz" target="_blank" rel="external">http://mirrors.cnnic.cn/apache/hbase/stable/hbase-1.2.4-bin.tar.gz</a></p>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>将下载后的压缩包解压后 放到/Users/xiwu/hbase-1.2.4目录下</p>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-env-sh"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-env-sh" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-env.sh"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-env.sh</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=通过之前方法定位</div><div class="line"><span class="built_in">export</span> HBASE_LOG_DIR=/Users/xiwu/hbase-1.2.4/logs</div><div class="line"><span class="comment">#如果使用HBase自带的Zookeeper值设成true 如果使用自己安装的Zookeeper需要将该值设为false</span></div><div class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">true</span></div></pre></td></tr></table></figure>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-site-xml"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-site-xml" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-site.xml"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.rootdir&lt;/name&gt;</div><div class="line">        &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</div><div class="line">        &lt;value&gt;true&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</div><div class="line">        &lt;value&gt;master,worker1,worker2&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.master.maxclockskew&lt;/name&gt;</div><div class="line">        &lt;value&gt;180000&lt;/value&gt;</div><div class="line">        &lt;description&gt;Time difference of regionserver from master&lt;/description&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>hbase.rootdir 指定Hbase数据存储目录<br>hbase.cluster.distributed 指定是否是完全分布式模式，单机模式和伪分布式模式需要将该值设为false<br>hbase.zookeeper.quorum 指定zooke的集群，多台机器以逗号分隔</p>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-regionservers"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-regionservers" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim regionservers"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim regionservers</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">master</div><div class="line">worker1</div><div class="line">worker2</div></pre></td></tr></table></figure>
<p>PS.以上操作在三台机器都相同。可以在一台机器上弄好后，scp复制过去</p>
<h2 id="启动HBase"><a href="#启动HBase" class="headerlink" title="启动HBase"></a>启动HBase</h2><p>//先启动hdfs<br>cd ${HADOOP_HOME} &amp;&amp; ./sbin/start-dfs.sh<br>//再启动hbase<br>cd ${HBASE_HOME} &amp;&amp; ./bin/start-hbase.sh<br>正确启动后结果如图所示:<br><img src="/images/201701/hbase_1.png"><br>master: HMaster,HQuorumPeer,HRegionServer<br>worker1,worker2: HQuorumPeer,HRegionServer<br>也可以登录：<a href="http://master:16010/" target="_blank" rel="external">http://master:16010/</a> 查看HBase状态<br>如果所示:<br><img src="/images/201701/hbase_2.png"></p>
<h2 id="测试HBase"><a href="#测试HBase" class="headerlink" title="测试HBase"></a>测试HBase</h2><p>cd ${HBASE_HOME} &amp;&amp; ./bin/hbase shell<br><img src="/images/201701/hbase_3.png"><br><img src="/images/201701/hbase_4.png"><br><img src="/images/201701/hbase_5.png"><br>更多操作参考<a href="http://www.yiibai.com/hbase/hbase_shell.html" target="_blank" rel="external">http://www.yiibai.com/hbase/hbase_shell.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="xiwu1212@163.com" />
          <p class="site-author-name" itemprop="name">xiwu1212@163.com</p>
          <p class="site-description motion-element" itemprop="description">学无止境</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiwu1212@163.com</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  




  
  

  

  

  

  


</body>
</html>
