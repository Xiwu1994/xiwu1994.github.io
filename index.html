<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="Refrain">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Refrain">
<meta property="og:description" content="学无止境">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Refrain">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title> Refrain </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Refrain</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/26/a/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/26/a/" itemprop="url">
                  a
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-26T12:00:43+08:00">
                2017-01-26
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/25/supervisor使用/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/25/supervisor使用/" itemprop="url">
                  Supervisor使用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-25T15:52:23+08:00">
                2017-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="下载安装Supervisor"><a href="#下载安装Supervisor" class="headerlink" title="下载安装Supervisor"></a>下载安装Supervisor</h3><p>pip install supervisor<br>如果在命令行中输入echo_supervisord_conf没有找到命令，那么需要在环境变量PATH添加Python的bin目录路径</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>echo_supervisord_conf &gt; /etc/supervisord.conf<br>vim /etc/supervisord.conf<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">[unix_http_server]</div><div class="line">file=/tmp/supervisor.sock   ; UNIX socket 文件，supervisorctl 会使用</div><div class="line">;chmod=0700                 ; socket 文件的 mode，默认是 0700</div><div class="line">;chown=nobody:nogroup       ; socket 文件的 owner，格式： uid:gid</div><div class="line"> </div><div class="line">;[inet_http_server]         ; HTTP 服务器，提供 web 管理界面</div><div class="line">;port=127.0.0.1:9001        ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性</div><div class="line">;username=user              ; 登录管理后台的用户名</div><div class="line">;password=123               ; 登录管理后台的密码</div><div class="line"> </div><div class="line">[supervisord]</div><div class="line">logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log</div><div class="line">logfile_maxbytes=50MB        ; 日志文件大小，超出会 rotate，默认 50MB</div><div class="line">logfile_backups=10           ; 日志文件保留备份数量默认 10</div><div class="line">loglevel=info                ; 日志级别，默认 info，其它: debug,warn,trace</div><div class="line">pidfile=/tmp/supervisord.pid ; pid 文件</div><div class="line">nodaemon=false               ; 是否在前台启动，默认是 false，即以 daemon 的方式启动</div><div class="line">minfds=1024                  ; 可以打开的文件描述符的最小值，默认 1024</div><div class="line">minprocs=200                 ; 可以打开的进程数的最小值，默认 200</div><div class="line"> </div><div class="line">; the below section must remain in the config file for RPC</div><div class="line">; (supervisorctl/web interface) to work, additional interfaces may be</div><div class="line">; added by defining them in separate rpcinterface: sections</div><div class="line">[rpcinterface:supervisor]</div><div class="line">supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface</div><div class="line"> </div><div class="line">[supervisorctl]</div><div class="line">serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致</div><div class="line">;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord</div><div class="line"> </div><div class="line">; 包含其他的配置文件</div><div class="line">[include]</div><div class="line">files = relative/directory/*.ini    ; 可以是 *.conf 或 *.ini</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/24/Spark性能调优简单总结/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/24/Spark性能调优简单总结/" itemprop="url">
                  Spark性能调优简单总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-24T14:00:44+08:00">
                2017-01-24
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="spark性能调优：初级-开发调优、资源调优-高级-数据倾斜调优、shuffle调优"><a href="#spark性能调优：初级-开发调优、资源调优-高级-数据倾斜调优、shuffle调优" class="headerlink" title="spark性能调优：初级(开发调优、资源调优) 高级(数据倾斜调优、shuffle调优)"></a>spark性能调优：初级(开发调优、资源调优) 高级(数据倾斜调优、shuffle调优)</h2><h3 id="开发调优"><a href="#开发调优" class="headerlink" title="开发调优"></a>开发调优</h3><p>RDD lineage设计、算子的合理使用、特殊操作的优化<br>原则一：避免创建重复的RDD<br>原则二：尽可能复用同一个RDD<br>原则三：对多次使用的RDD进行持久化<br>原则四：尽量避免使用shuffle类算子<br>原则五：使用map-side预聚合的shuffle操作 (reduceByKey优于groupByKey)<br>原则六：使用高性能的算子<br>    使用reduceByKey/aggregateByKey替代groupByKey<br>    使用mapPartitions替代普通map(mapPartitions单次函数调用就要处理掉一个partition所有的数据,很可能出现OOM异常)<br>    使用foreachPartitions替代foreach<br>    使用filter之后进行coalesce操作(重新分区，但是不用排序)<br>    使用repartitionAndSortWithinPartitions替代repartition与sort类操作<br>原则七：广播大变量(大变量存储转变 task-&gt;executor)<br>原则八：使用Kryo优化序列化性能<br>原则九：优化数据结构(内存使用  集合类型&gt;数组 对象&gt;字符串&gt;原始类型)</p>
<h3 id="资源调优"><a href="#资源调优" class="headerlink" title="资源调优"></a>资源调优</h3><p>num-executors = 总共要用多少个Executor进程来执行<br>executor-memory = 每个Executor进程的内存<br>executor-cores = 每个Executor进程的CPU core数量<br>driver-memory = Driver进程的内存<br>spark.default.parallelism = 每个stage的task数量(默认根据底层HDFS的block数量来设置task的数量,Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适)<br>spark.storage.memoryFraction = RDD持久化数据在Executor内存占比，默认是0.6<br>spark.shuffle.memoryFraction = shuffle过程在Executor内存占比，默认是0.2<br><img src="/images/201701/Spark_Performance_1.png"></p>
<h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><p>数据倾斜-&gt;shuffle key量大</p>
<h4 id="数据倾斜的原因"><a href="#数据倾斜的原因" class="headerlink" title="数据倾斜的原因"></a>数据倾斜的原因</h4><p>进行shuffle(操作有distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition)的时候，<br>必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，可能出现某一个key的量特别的大</p>
<h4 id="数据倾斜的定位"><a href="#数据倾斜的定位" class="headerlink" title="数据倾斜的定位"></a>数据倾斜的定位</h4><p>1、WebUI或者log日志可以告诉我们哪些个stage(task)运行的数据量大小<br>2、分析代码，重点看有shuffle操作关键代码，定位到具体造成倾斜的操作</p>
<h4 id="数据倾斜的解决方案"><a href="#数据倾斜的解决方案" class="headerlink" title="数据倾斜的解决方案"></a>数据倾斜的解决方案</h4><p>一：提高shuffle操作的并行度(最简单，但是解决不了某个key的量特别大，因为同一个key必须放到一个task下)<br>提高shuffle算子执行时shuffle read task的数量<br>1、对RDD执行shuffle算子时，给shuffle算子传入一个参数，设置reduceByKey(1000)<br>2、对于Spark SQL中的shuffle类语句，group by、join等，设置spark.sql.shuffle.partitions<br>二：使用Hive ETL预处理数据<br>对数据倾斜的数据进行清洗后，供spark程序使用<br>三：过滤少数导致倾斜的key<br>先通过sample算子对数据进行采样，计算每个key对应的数量，再用filter过滤掉这些key<br>四、两阶段聚合，局部聚合+全局聚合<br>适用场景：只对聚合类操作reduceByKey有效，对join操作无效<br>先局部聚合，先给每个key都打上一个随机数(比如10以内的随机数，目的是打散巨大的key)，再执行reduceByKey<br>再全局聚合，将各个key的前缀给去掉，再次进行全局聚合操作<br>五、将reduce join转为map join<br>适用场景：对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小<br>解决办法：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作<br>六：采样倾斜key并分拆join操作<br>适用场景：因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀<br>将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。<br>七：使用随机前缀和扩容RDD进行join<br>使用场景：如果在进行join操作时，RDD中有大量的key导致数据倾斜<br>和方案六差不多，只不过不拆分RDD了，对整体RDD进行扩容(对内存消耗很大)<br><img src="/images/201701/Spark_Performance_2.png"></p>
<h3 id="shuffle调优"><a href="#shuffle调优" class="headerlink" title="shuffle调优"></a>shuffle调优</h3><p>影响一个Spark作业性能的因素，主要还是代码开发、资源参数以 及数据倾斜 shuffle调优只能在整个Spark的性能调优中占到一小部分而已</p>
<p>以下是Shffule过程中的一些主要参数，这里详细讲解了各个参数的功能、默认值以及基于实践经验给出的调优建议。</p>
<p>spark.shuffle.file.buffer</p>
<ul>
<li>默认值：32k</li>
<li>参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>spark.reducer.maxSizeInFlight</p>
<ul>
<li>默认值：48m</li>
<li>参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。</li>
<li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li>
</ul>
<p>spark.shuffle.io.maxRetries</p>
<ul>
<li>默认值：3</li>
<li>参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取 还是没有成功，就可能会导致作业执行失败。</li>
<li>调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定 性。</li>
</ul>
<p>spark.shuffle.io.retryWait</p>
<ul>
<li>默认值：5s</li>
<li>参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。</li>
<li>调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</li>
</ul>
<p>spark.shuffle.memoryFraction</p>
<ul>
<li>默认值：0.2</li>
<li>参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。</li>
<li>调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升10%左右。</li>
</ul>
<p>spark.shuffle.manager</p>
<ul>
<li>默认值：sort</li>
<li>参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。tungsten-sort与sort类似，但是使用了tungsten计划中的 堆外内存管理机制，内存使用效率更高。</li>
<li>调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的 SortShuffleManager就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的 HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，tungsten-sort要慎用，因为之前发现了 一些相应的bug。</li>
</ul>
<p>spark.shuffle.sort.bypassMergeThreshold</p>
<ul>
<li>默认值：200</li>
<li>参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临 时磁盘文件都合并成一个文件，并会创建单独的索引文件。</li>
<li>调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁 盘文件，因此shuffle write性能有待提高。</li>
</ul>
<p>spark.shuffle.consolidateFiles</p>
<ul>
<li>默认值：false</li>
<li>参数说明：如果使用HashShuffleManager，该参数有效。如果设置为true，那么就会开启consolidate机制，会大幅度 合并shuffle write的输出文件，对于shuffle read task数量特别多的情况下，这种方法可以极大地减少磁盘IO开销，提升性能。</li>
<li>调优建议：如果的确不需要SortShuffleManager的排序机制，那么除了使用bypass机制，还可以尝试将 spark.shffle.manager参数手动指定为hash，使用HashShuffleManager，同时开启consolidate机制。在 实践中尝试过，发现其性能比开启了bypass机制的SortShuffleManager要高出10%~30%。</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/23/SparkSQL初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/23/SparkSQL初体验/" itemprop="url">
                  SparkSQL初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-23T13:57:04+08:00">
                2017-01-23
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkSQL输入源"><a href="#SparkSQL输入源" class="headerlink" title="SparkSQL输入源"></a>SparkSQL输入源</h2><p>Hive、Parquet、JSON、基于RDD(需要隐式转换)<br>因为还没有搭好Hive且没有使用过Parquet，下面主要将JSON和基于RDD的输入源<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> org.apache.spark.sql.<span class="type">SQLContext</span>(sc)</div><div class="line"><span class="comment">// Create the DataFrame (From JSON)</span></div><div class="line"><span class="keyword">val</span> df1 = sqlContext.read.json(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.json"</span>)</div><div class="line"></div><div class="line"><span class="comment">// Create the DataFrame (From RDD) 方法一</span></div><div class="line"><span class="comment">// 利用反射机制，推导包含某种类型的RDD，通过反射将其转换为指定类型的DataFrame，</span></div><div class="line"><span class="comment">// 适用于提前知道RDD的schema</span></div><div class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>) <span class="title">//放在main函数外面</span></span></div><div class="line"><span class="keyword">import</span> sqlContext.implicits._</div><div class="line"><span class="keyword">val</span> df2 = sc.textFile(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line">    .map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Person</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim.toInt)).toDF()</div><div class="line"></div><div class="line"><span class="comment">// Create the DataFrame (From RDD) 方法二</span></div><div class="line"><span class="comment">// 当case class不能提前定义好时，通过编程接口与RDD进行交互获取schema，</span></div><div class="line"><span class="comment">// 并动态创建DataFrame，在运行时决定列及其类型。</span></div><div class="line"><span class="keyword">val</span> people = sc.textFile(<span class="string">"spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line"><span class="keyword">val</span> schemaString = <span class="string">"name age"</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span>;</div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>,<span class="type">StructField</span>,<span class="type">StringType</span>&#125;;</div><div class="line"><span class="keyword">val</span> schema =</div><div class="line">  <span class="type">StructType</span>(schemaString.split(<span class="string">" "</span>).map(fieldName =&gt; <span class="type">StructField</span>(fieldName,</div><div class="line">  <span class="type">StringType</span>, <span class="literal">true</span>))) <span class="comment">//基于structType类型创建schema</span></div><div class="line"><span class="keyword">val</span> rowRDD = people.map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Row</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim)) <span class="comment">//与创建的RDD相匹配</span></div><div class="line"><span class="comment">// 通过SQLContext的createDataFrame方法对rowRDD应用schema</span></div><div class="line"><span class="keyword">val</span> df3 = sqlContext.createDataFrame(rowRDD, schema)</div></pre></td></tr></table></figure></p>
<p>上面代码df1、df2、df3都是DataFrame类型</p>
<p>DataFrame类型的一些常见的api操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Show the content of the DataFrame</span></div><div class="line">df.show()</div><div class="line"></div><div class="line"><span class="comment">// Print the schema in a tree format</span></div><div class="line">df.printSchema()</div><div class="line"></div><div class="line"><span class="comment">// Select only the "name" column</span></div><div class="line">df.select(<span class="string">"name"</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Select everybody, but increment the age by 1</span></div><div class="line">df.select(df(<span class="string">"name"</span>), df(<span class="string">"age"</span>) + <span class="number">1</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Select people older than 21</span></div><div class="line">df.filter(df(<span class="string">"age"</span>) &gt; <span class="number">21</span>).show()</div><div class="line"></div><div class="line"><span class="comment">// Count people by age</span></div><div class="line">df.groupBy(<span class="string">"age"</span>).count().show()</div></pre></td></tr></table></figure></p>
<p>下面是简单的sql操作<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 注册输入的DataFrame</span></div><div class="line">df2.registerTempTable(<span class="string">"people"</span>)</div><div class="line"></div><div class="line"><span class="comment">// SQL statements can be run by using the sql methods provided by sqlContext.</span></div><div class="line"><span class="keyword">val</span> teenagers = sqlContext.sql(<span class="string">"SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19"</span>)</div><div class="line"></div><div class="line"><span class="comment">// The results of SQL queries are DataFrames and support all the normal RDD operations.</span></div><div class="line"><span class="comment">// The columns of a row in the result can be accessed by field index:</span></div><div class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t(<span class="number">0</span>)).collect().foreach(println)</div><div class="line"></div><div class="line"><span class="comment">// or by field name:</span></div><div class="line">teenagers.map(t =&gt; <span class="string">"Name: "</span> + t.getAs[<span class="type">String</span>](<span class="string">"name"</span>)).collect().foreach(println)</div><div class="line"></div><div class="line"><span class="comment">// row.getValuesMap[T] retrieves multiple columns at once into a Map[String, T]</span></div><div class="line">teenagers.map(_.getValuesMap[<span class="type">Any</span>](<span class="type">List</span>(<span class="string">"name"</span>, <span class="string">"age"</span>))).collect().foreach(println)</div></pre></td></tr></table></figure></p>
<p>测试数据:<br>spark-1.6.2-bin-hadoop2.6/examples/src/main/resources/people.txt<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Michael, 29</div><div class="line">Andy, 30</div><div class="line">Justin, 19</div></pre></td></tr></table></figure></p>
<p>测试结果如图：<br><img src="/images/201701/SparkSql_1.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/22/SparkStreaming初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/22/SparkStreaming初体验/" itemprop="url">
                  SparkStreaming初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-22T15:53:39+08:00">
                2017-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SparkStreaming简单介绍"><a href="#SparkStreaming简单介绍" class="headerlink" title="SparkStreaming简单介绍"></a>SparkStreaming简单介绍</h2><p>Spark Streaming是建立在Spark上的实时计算框架<br>输入和输出概览：<br><img src="/images/201701/SparkStreaming_1.png"><br>Spark Streaming把实时输入数据流以时间片(如1秒)为单位切分成块。SparkStreaming会把每块数据作为一个RDD，并使用RDD操作处理每一小块数据<br><img src="/images/201701/SparkStreaming_2.png"></p>
<h2 id="例子-从kafka输入源-读取数据后-直接输出"><a href="#例子-从kafka输入源-读取数据后-直接输出" class="headerlink" title="例子:从kafka输入源 读取数据后 直接输出"></a>例子:从kafka输入源 读取数据后 直接输出</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaUtils</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</div><div class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">process_58_data</span> </span>&#123;</div><div class="line">  <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">ERROR</span>)</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> masterUrl = <span class="string">"local[2]"</span> <span class="comment">//不能local，需要两个核以上</span></div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(masterUrl).setAppName(<span class="string">"58_data"</span>)</div><div class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</div><div class="line">    <span class="keyword">val</span> topics = <span class="type">Set</span>(<span class="string">"58_data"</span>) <span class="comment">//kafka的topic</span></div><div class="line">    <span class="keyword">val</span> brokers = <span class="string">"master:9092,worker1:9092,worker2:9092"</span> <span class="comment">//kafka端口</span></div><div class="line">    <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">"metadata.broker.list"</span> -&gt; brokers)</div><div class="line">    <span class="keyword">val</span> kafkaStream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](ssc, kafkaParams, topics) <span class="comment">//调用Kafka工具包创建DSteam</span></div><div class="line">    kafkaStream.foreachRDD(rdd =&gt;&#123;</div><div class="line">      rdd.foreachPartition(iter =&gt; &#123;</div><div class="line">        iter.foreach( x =&gt;</div><div class="line">          println(x._2)</div><div class="line">        )</div><div class="line">      &#125;)</div><div class="line">    &#125;)</div><div class="line">    ssc.start() <span class="comment">//启动流计算环境StreamingContext</span></div><div class="line">    ssc.awaitTermination() <span class="comment">//等待作业完成</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之前写过简单的爬虫用来抓取网页信息，将数据放入kafka中，配合SparkStreaming，最后输出结果如下:<br><img src="/images/201701/SparkStreaming_3.png"></p>
<h2 id="SparkStreaming中DSteam转化操作"><a href="#SparkStreaming中DSteam转化操作" class="headerlink" title="SparkStreaming中DSteam转化操作"></a>SparkStreaming中DSteam转化操作</h2><h3 id="无状态："><a href="#无状态：" class="headerlink" title="无状态："></a>无状态：</h3><p>SparkStreaming是建立在Spark，所以很多RDD转化操作都适用于Dsteam.<br>例如: map, flatMap, filter, repartition, join, reduceByKey<br>(注: 针对键值对的Dsteam转化操作需要import StreamingContext._)</p>
<h3 id="有状态-SparkStreaming特有的操作-："><a href="#有状态-SparkStreaming特有的操作-：" class="headerlink" title="有状态(SparkStreaming特有的操作)："></a>有状态(SparkStreaming特有的操作)：</h3><p>滑动窗口和updateStateByKey<br>滑动窗口使用详情可以参考：<a href="http://blog.csdn.net/legotime/article/details/51836040" target="_blank" rel="external">http://blog.csdn.net/legotime/article/details/51836040</a></p>
<p>参考文档：<br><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a><br>《Spark快速大数据分析》</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/21/spark机器学习初体验/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/21/spark机器学习初体验/" itemprop="url">
                  spark机器学习初体验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-21T18:19:48+08:00">
                2017-01-21
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="垃圾邮件分类例子"><a href="#垃圾邮件分类例子" class="headerlink" title="垃圾邮件分类例子"></a>垃圾邮件分类例子</h2><h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><p>垃圾邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">spam.txt</div><div class="line">Dear sir, I am a Prince in a far kingdom you have not heard of.  I want to send you money via wire transfer so please ...</div><div class="line">Get Viagra real cheap!  Send money right away to ...</div><div class="line">Oh my gosh you can be really strong too with these drugs found in the rainforest. Get them cheap right now ...</div><div class="line">YOUR COMPUTER HAS BEEN INFECTED!  YOU MUST RESET YOUR PASSWORD.  Reply to this email with your password and SSN ...</div><div class="line">THIS IS NOT A SCAM!  Send money and get access to awesome stuff really cheap and never have to ...</div></pre></td></tr></table></figure></p>
<p>正常邮件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ham.txt</div><div class="line">Dear Spark Learner, Thanks so much for attending the Spark Summit 2014!  Check out videos of talks from the summit at ...</div><div class="line">Hi Mom, Apologies for being late about emailing and forgetting to send you the package.  I hope you and bro have been ...</div><div class="line">Wow, hey Fred, just heard about the Spark petabyte sort.  I think we need to take time to try it out immediately ...</div><div class="line">Hi Spark user list, This is my first question to this list, so thanks in advance for your help!  I tried running ...</div><div class="line">Thanks Tom for your email.  I need to refer you to Alice for this one.  I haven&apos;t yet figured out that part either ...</div><div class="line">Good job yesterday!  I was attending your talk, and really enjoyed it.  I want to try out GraphX ...</div><div class="line">Summit demo got whoops from audience!  Had to let you know. --Joe</div></pre></td></tr></table></figure></p>
<h3 id="Scala代码"><a href="#Scala代码" class="headerlink" title="Scala代码"></a>Scala代码</h3><p>这个程序使用了MLlib两个函数：HashingTF(从文本数据构建 词频特征向量)和LogisticRegressionWithSGD(随机体度下降法实现逻辑回归)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.<span class="type">LogisticRegressionWithSGD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.feature.<span class="type">HashingTF</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">MLlib</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">s"Book example: Scala"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line"></div><div class="line">    <span class="comment">// Load 2 types of emails from text files: spam and ham (non-spam).</span></div><div class="line">    <span class="comment">// Each line has text from one email.</span></div><div class="line">    <span class="keyword">val</span> spam = sc.textFile(<span class="string">"files/spam.txt"</span>)</div><div class="line">    <span class="keyword">val</span> ham = sc.textFile(<span class="string">"files/ham.txt"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// Create a HashingTF instance to map email text to vectors of 100 features.</span></div><div class="line">    <span class="keyword">val</span> tf = <span class="keyword">new</span> <span class="type">HashingTF</span>(numFeatures = <span class="number">100</span>)</div><div class="line">    <span class="comment">// Each email is split into words, and each word is mapped to one feature.</span></div><div class="line">    <span class="comment">// 1、特征提取</span></div><div class="line">    <span class="keyword">val</span> spamFeatures = spam.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line">    <span class="keyword">val</span> hamFeatures = ham.map(email =&gt; tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line"></div><div class="line">    <span class="comment">// Create LabeledPoint datasets for positive (spam) and negative (ham) examples.</span></div><div class="line">    <span class="comment">// 2、将文本数据转换为数值特征，返回LabeledPoint类型RDD(包含一个特质向量和一个标签)</span></div><div class="line">    <span class="keyword">val</span> positiveExamples = spamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">1</span>, features))</div><div class="line">    <span class="keyword">val</span> negativeExamples = hamFeatures.map(features =&gt; <span class="type">LabeledPoint</span>(<span class="number">0</span>, features))</div><div class="line">    <span class="keyword">val</span> trainingData = positiveExamples ++ negativeExamples</div><div class="line">    trainingData.cache() <span class="comment">// Cache data since Logistic Regression is an iterative algorithm.</span></div><div class="line"></div><div class="line">    <span class="comment">// Create a Logistic Regression learner which uses the LBFGS optimizer.</span></div><div class="line">    <span class="comment">// 3、调用分类算法，返回模型对象</span></div><div class="line">    <span class="keyword">val</span> lrLearner = <span class="keyword">new</span> <span class="type">LogisticRegressionWithSGD</span>()</div><div class="line">    <span class="comment">// Run the actual learning algorithm on the training data.</span></div><div class="line">    <span class="keyword">val</span> model = lrLearner.run(trainingData)</div><div class="line"></div><div class="line">    <span class="comment">// Test on a positive example (spam) and a negative one (ham).</span></div><div class="line">    <span class="comment">// First apply the same HashingTF feature transformation used on the training data.</span></div><div class="line">    <span class="keyword">val</span> posTestExample = tf.transform(<span class="string">"O M G GET cheap stuff by sending money to ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="keyword">val</span> negTestExample = tf.transform(<span class="string">"Hi Dad, I started studying Spark the other ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    <span class="comment">// Now use the learned model to predict spam/ham for new emails.</span></div><div class="line">    println(<span class="string">s"Prediction for positive test example: <span class="subst">$&#123;model.predict(posTestExample)&#125;</span>"</span>)</div><div class="line">    println(<span class="string">s"Prediction for negative test example: <span class="subst">$&#123;model.predict(negTestExample)&#125;</span>"</span>)</div><div class="line"></div><div class="line">    sc.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>运行结果如果所示：<br><img src="/images/201701/SparkML_1.png"></p>
<h2 id="机器学习流水线中典型步骤"><a href="#机器学习流水线中典型步骤" class="headerlink" title="机器学习流水线中典型步骤"></a>机器学习流水线中典型步骤</h2><p>源数据ETL-&gt;数据预处理-&gt;特征提取(返回MLlib的数据类型，比如上例的LabeledPoint类型)-&gt;训练(返回模型)-&gt;模型评估</p>
<h2 id="简单理解"><a href="#简单理解" class="headerlink" title="简单理解"></a>简单理解</h2><p>确定模型—-训练模型—-使用模型<br>模型简单说可以理解为函数。<br>确定模型是说自己认为这些数据的特征符合哪个函数(应该使用什么模型)<br>训练模型就是用已有的数据，通过一些方法（最优化或者其他方法）确定函数的参数，参数确定后的函数就是训练的结果<br>使用模型就是把新的数据代入函数求值</p>
<p>参考文档：<br>《Spark快速大数据分析》<br><a href="https://www.zhihu.com/question/29271217?sort=created" target="_blank" rel="external">https://www.zhihu.com/question/29271217?sort=created</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/20/spark源码浅析-提交Task到Executor/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/20/spark源码浅析-提交Task到Executor/" itemprop="url">
                  spark源码浅析：提交Task到Executor
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-20T16:15:23+08:00">
                2017-01-20
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="从DAGScheduler-submitMissingTasks-开始追源码"><a href="#从DAGScheduler-submitMissingTasks-开始追源码" class="headerlink" title="从DAGScheduler.submitMissingTasks 开始追源码"></a>从DAGScheduler.submitMissingTasks 开始追源码</h2><p>DAGScheduler.submitMissingTasks主要功能<br>1、找到RDD中需要计算的partition<br>2、获取Task的最佳计算位置<br>3、序列化Task的Binary，并进行广播<br>4、根据stage的不同类型创建，为stage的每个分区创建创建task,并封装成TaskSet<br>5、调用TaskScheduler的submitTasks，提交TaskSet<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** Called when stage's parents are available and we can now do its task. */</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>) &#123;</div><div class="line">  logDebug(<span class="string">"submitMissingTasks("</span> + stage + <span class="string">")"</span>)</div><div class="line">  <span class="comment">// Get our pending tasks and remember them in our pendingTasks entry</span></div><div class="line">  stage.pendingPartitions.clear()</div><div class="line"></div><div class="line">  <span class="comment">// First figure out the indexes of partition ids to compute.</span></div><div class="line">  <span class="comment">// 1、找到RDD中需要计算的partition</span></div><div class="line">  <span class="comment">// 对于Shuffle类型的Stage，需要判断stage中是否缓存了该结果</span></div><div class="line">  <span class="comment">// 对于Result类型的Stage，则判断计算Job中该partition是否已经计算完成</span></div><div class="line">  <span class="keyword">val</span> partitionsToCompute: <span class="type">Seq</span>[<span class="type">Int</span>] = stage.findMissingPartitions()</div><div class="line"></div><div class="line">  <span class="comment">// Create internal accumulators if the stage has no accumulators initialized.</span></div><div class="line">  <span class="comment">// Reset internal accumulators only if this stage is not partially submitted</span></div><div class="line">  <span class="comment">// Otherwise, we may override existing accumulator values from some tasks</span></div><div class="line">  <span class="keyword">if</span> (stage.internalAccumulators.isEmpty || stage.numPartitions == partitionsToCompute.size) &#123;</div><div class="line">    stage.resetInternalAccumulators()</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Use the scheduling pool, job group, description, etc. from an ActiveJob associated</span></div><div class="line">  <span class="comment">// with this Stage</span></div><div class="line">  <span class="keyword">val</span> properties = jobIdToActiveJob(jobId).properties</div><div class="line"></div><div class="line">  runningStages += stage</div><div class="line">  <span class="comment">// SparkListenerStageSubmitted should be posted before testing whether tasks are</span></div><div class="line">  <span class="comment">// serializable. If tasks are not serializable, a SparkListenerStageCompleted event</span></div><div class="line">  <span class="comment">// will be posted, which should always come after a corresponding SparkListenerStageSubmitted</span></div><div class="line">  <span class="comment">// event.</span></div><div class="line">  stage <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - <span class="number">1</span>)</div><div class="line">    <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</div><div class="line">      outputCommitCoordinator.stageStart(</div><div class="line">        stage = s.id, maxPartitionId = s.rdd.partitions.length - <span class="number">1</span>)</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 2、获取Task的最佳计算位置</span></div><div class="line">  <span class="comment">// 根据RDD的数据信息得到task的最佳计算位置，从而获取较好的数据本地性</span></div><div class="line">  <span class="keyword">val</span> taskIdToLocations: <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">TaskLocation</span>]] = <span class="keyword">try</span> &#123;</div><div class="line">    stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap</div><div class="line">      <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="keyword">val</span> job = s.activeJob.get</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> p = s.partitions(id)</div><div class="line">          (id, getPreferredLocs(stage.rdd, p))</div><div class="line">        &#125;.toMap</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      stage.makeNewStageAttempt(partitionsToCompute.size)</div><div class="line">      listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</div><div class="line">      abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)</div><div class="line">  listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</div><div class="line"></div><div class="line">  <span class="comment">// <span class="doctag">TODO:</span> Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.</span></div><div class="line">  <span class="comment">// Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast</span></div><div class="line">  <span class="comment">// the serialized copy of the RDD and for each task we will deserialize it, which means each</span></div><div class="line">  <span class="comment">// task gets a different copy of the RDD. This provides stronger isolation between tasks that</span></div><div class="line">  <span class="comment">// might modify state of objects referenced in their closures. This is necessary in Hadoop</span></div><div class="line">  <span class="comment">// where the JobConf/Configuration object is not thread-safe.</span></div><div class="line">  <span class="comment">// 3、序列化Task的Binary，并进行广播</span></div><div class="line">  <span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></div><div class="line">  <span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).</span></div><div class="line">    <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).</span></div><div class="line">    <span class="keyword">val</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>).array()</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">        closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>).array()</div><div class="line">    &#125;</div><div class="line">    taskBinary = sc.broadcast(taskBinaryBytes)</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="comment">// In the case of a failure during serialization, abort the stage.</span></div><div class="line">    <span class="keyword">case</span> e: <span class="type">NotSerializableException</span> =&gt;</div><div class="line">      abortStage(stage, <span class="string">"Task not serializable: "</span> + e.toString, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line"></div><div class="line">      <span class="comment">// Abort execution</span></div><div class="line">      <span class="keyword">return</span></div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      abortStage(stage, <span class="string">s"Task serialization failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 4、根据stage的不同类型创建，为stage的每个分区创建创建task,并封装成TaskSet</span></div><div class="line">  <span class="comment">// Stage分两种类型ShuffleMapStage生成ShuffleMapTask，ResultStage生成ResultTask</span></div><div class="line">  <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</div><div class="line">    stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">          <span class="keyword">val</span> part = stage.rdd.partitions(id)</div><div class="line">          <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">            taskBinary, part, locs, stage.internalAccumulators)</div><div class="line">        &#125;</div><div class="line"></div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="keyword">val</span> job = stage.activeJob.get</div><div class="line">        partitionsToCompute.map &#123; id =&gt;</div><div class="line">          <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</div><div class="line">          <span class="keyword">val</span> part = stage.rdd.partitions(p)</div><div class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">          <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">            taskBinary, part, locs, id, stage.internalAccumulators)</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">catch</span> &#123;</div><div class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">      abortStage(stage, <span class="string">s"Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;e.getStackTraceString&#125;</span>"</span>, <span class="type">Some</span>(e))</div><div class="line">      runningStages -= stage</div><div class="line">      <span class="keyword">return</span></div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</div><div class="line">    logInfo(<span class="string">"Submitting "</span> + tasks.size + <span class="string">" missing tasks from "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">")"</span>)</div><div class="line">    stage.pendingPartitions ++= tasks.map(_.partitionId)</div><div class="line">    logDebug(<span class="string">"New pending partitions: "</span> + stage.pendingPartitions)</div><div class="line">    <span class="comment">// 5、调用TaskScheduler的submitTasks，提交TaskSet</span></div><div class="line">    taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</div><div class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))</div><div class="line">    stage.latestInfo.submissionTime = <span class="type">Some</span>(clock.getTimeMillis())</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// Because we posted SparkListenerStageSubmitted earlier, we should mark</span></div><div class="line">    <span class="comment">// the stage as completed here in case there are no tasks to run</span></div><div class="line">    markStageAsFinished(stage, <span class="type">None</span>)</div><div class="line">    <span class="keyword">val</span> debugString = stage <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">        <span class="string">s"Stage <span class="subst">$&#123;stage&#125;</span> is actually done; "</span> +</div><div class="line">          <span class="string">s"(available: <span class="subst">$&#123;stage.isAvailable&#125;</span>,"</span> +</div><div class="line">          <span class="string">s"available outputs: <span class="subst">$&#123;stage.numAvailableOutputs&#125;</span>,"</span> +</div><div class="line">          <span class="string">s"partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)"</span></div><div class="line">      <span class="keyword">case</span> stage : <span class="type">ResultStage</span> =&gt;</div><div class="line">        <span class="string">s"Stage <span class="subst">$&#123;stage&#125;</span> is actually done; (partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)"</span></div><div class="line">    &#125;</div><div class="line">    logDebug(debugString)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSchedulerImpl-submitTasks"><a href="#TaskSchedulerImpl-submitTasks" class="headerlink" title="TaskSchedulerImpl.submitTasks"></a>TaskSchedulerImpl.submitTasks</h2><p>TaskSchedulerImpl.submitTasks主要功能<br>1、创建TaskSetManager<br>2、将TaskSetManager加入rootPool调度池中，由schedulableBuilder决定调度顺序<br>3、调用SchedulerBackend的reviveOffers方法对Task进行调度，决定task具体运行在哪个Executor中<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.submitTasks</div><div class="line">  <span class="comment">/*</span></div><div class="line">  * 主要将任务加入调度池，最后调用了backend.reviveOffers()</div><div class="line">  * 这里的backend是CoarseGrainedSchedulerBackend一个Executor任务调度对象</div><div class="line">  */</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">submitTasks</span></span>(taskSet: <span class="type">TaskSet</span>) &#123;</div><div class="line">    <span class="keyword">val</span> tasks = taskSet.tasks</div><div class="line">    logInfo(<span class="string">"Adding task set "</span> + taskSet.id + <span class="string">" with "</span> + tasks.length + <span class="string">" tasks"</span>)</div><div class="line">    <span class="keyword">this</span>.synchronized &#123;</div><div class="line">      <span class="comment">// 1、创建TaskSetManager</span></div><div class="line">      <span class="comment">// TaskSetManager会负责task的失败重试；跟踪每个task的执行状态；处理locality-aware的调用。</span></div><div class="line">      <span class="keyword">val</span> manager = createTaskSetManager(taskSet, maxTaskFailures)</div><div class="line">      <span class="keyword">val</span> stage = taskSet.stageId</div><div class="line">      <span class="keyword">val</span> stageTaskSets =</div><div class="line">        taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">TaskSetManager</span>])</div><div class="line">      stageTaskSets(taskSet.stageAttemptId) = manager</div><div class="line">      <span class="keyword">val</span> conflictingTaskSet = stageTaskSets.exists &#123; <span class="keyword">case</span> (_, ts) =&gt;</div><div class="line">        ts.taskSet != taskSet &amp;&amp; !ts.isZombie</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (conflictingTaskSet) &#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">s"more than one active taskSet for stage <span class="subst">$stage</span>:"</span> +</div><div class="line">          <span class="string">s" <span class="subst">$&#123;stageTaskSets.toSeq.map&#123;_._2.taskSet.id&#125;</span>.mkString("</span>,<span class="string">")&#125;"</span>)</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// 2、将TaskSetManager加入rootPool调度池中，由schedulableBuilder决定调度顺序</span></div><div class="line">      <span class="comment">// SchedulerBuilder有两个实现FIFOSchedulerBuilder和FairSchedulerBuilder，默认采用的是FIFO方式</span></div><div class="line">      schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!isLocal &amp;&amp; !hasReceivedTask) &#123;</div><div class="line">        starvationTimer.scheduleAtFixedRate(<span class="keyword">new</span> <span class="type">TimerTask</span>() &#123;</div><div class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</div><div class="line">            <span class="keyword">if</span> (!hasLaunchedTask) &#123;</div><div class="line">              logWarning(<span class="string">"Initial job has not accepted any resources; "</span> +</div><div class="line">                <span class="string">"check your cluster UI to ensure that workers are registered "</span> +</div><div class="line">                <span class="string">"and have sufficient resources"</span>)</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">              <span class="keyword">this</span>.cancel()</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;, <span class="type">STARVATION_TIMEOUT_MS</span>, <span class="type">STARVATION_TIMEOUT_MS</span>)</div><div class="line">      &#125;</div><div class="line">      hasReceivedTask = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 3、调用SchedulerBackend的reviveOffers方法对Task进行调度，决定task具体运行在哪个Executor中</span></div><div class="line">    backend.reviveOffers()</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>调用CoarseGrainedSchedulerBackend的reviveOffers方法，该方法给driverEndpoint发送ReviveOffer消息</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="type">CoarseGrainedSchedulerBackend</span>.reviveOffers</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>() &#123;</div><div class="line">    driverEndpoint.send(<span class="type">ReviveOffers</span>)</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>driverEndpoint收到ReviveOffer消息后调用makeOffers方法</p>
<h2 id="CoarseGrainedSchedulerBackend-makeOffers"><a href="#CoarseGrainedSchedulerBackend-makeOffers" class="headerlink" title="CoarseGrainedSchedulerBackend.makeOffers"></a>CoarseGrainedSchedulerBackend.makeOffers</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="type">CoarseGrainedSchedulerBackend</span>.makeOffers</div><div class="line">    <span class="comment">// Make fake resource offers on all executor</span></div><div class="line">    <span class="comment">// makeOffers方法中，将Executor的信息集合与调度池中的Tasks封装成WokerOffers列表传给了 launchTasks</span></div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeOffers</span></span>() &#123;</div><div class="line">      <span class="comment">// Filter out executors under killing</span></div><div class="line">      <span class="comment">// 过滤出活跃状态的Executor</span></div><div class="line">      <span class="keyword">val</span> activeExecutors = executorDataMap.filterKeys(executorIsAlive)</div><div class="line">      <span class="comment">// 将Executor封装成WorkerOffer对象</span></div><div class="line">      <span class="keyword">val</span> workOffers = activeExecutors.map &#123; <span class="keyword">case</span> (id, executorData) =&gt;</div><div class="line">        <span class="keyword">new</span> <span class="type">WorkerOffer</span>(id, executorData.executorHost, executorData.freeCores)</div><div class="line">      &#125;.toSeq</div><div class="line">      launchTasks(scheduler.resourceOffers(workOffers))</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>注意：上面代码中的executorDataMap，在客户端向Master注册Application的时候，Master已经为Application分配并启动好Executor，然后注册给CoarseGrainedSchedulerBackend，注册信息就是存储在executorDataMap数据结构中。</p>
<h2 id="TaskSchedulerImpl-resourceOffers"><a href="#TaskSchedulerImpl-resourceOffers" class="headerlink" title="TaskSchedulerImpl.resourceOffers"></a>TaskSchedulerImpl.resourceOffers</h2><p>准备好计算资源后，接下来TaskSchedulerImpl基于这些计算资源为task分配Executor<br>看一下TaskSchedulerImpl的resourceOffers方法：<br>传递的参数offers表示worker提供的资源，该方法根据资源情况，结合待执行任务的优先级，将任务平衡的分配给executors<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.resourceOffers</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Called by cluster manager to offer resources on slaves. We respond by asking our active task</div><div class="line">   * sets for tasks in order of priority. We fill each node with tasks in a round-robin manner so</div><div class="line">   * that tasks are balanced across the cluster.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">resourceOffers</span></span>(offers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>]): <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]] = synchronized &#123;</div><div class="line">    <span class="comment">// Mark each slave as alive and remember its hostname</span></div><div class="line">    <span class="comment">// Also track if new executor is added</span></div><div class="line">    <span class="comment">// 激活所有slave节点，记录其hostname，并检查是否有新的executor加入</span></div><div class="line">    <span class="keyword">var</span> newExecAvail = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (o &lt;- offers) &#123;</div><div class="line">      executorIdToHost(o.executorId) = o.host</div><div class="line">      executorIdToTaskCount.getOrElseUpdate(o.executorId, <span class="number">0</span>)</div><div class="line">      <span class="keyword">if</span> (!executorsByHost.contains(o.host)) &#123;</div><div class="line">        executorsByHost(o.host) = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()</div><div class="line">        executorAdded(o.executorId, o.host)</div><div class="line">        newExecAvail = <span class="literal">true</span></div><div class="line">      &#125;</div><div class="line">      <span class="keyword">for</span> (rack &lt;- getRackForHost(o.host)) &#123;</div><div class="line">        hostsByRack.getOrElseUpdate(rack, <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()) += o.host</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Randomly shuffle offers to avoid always placing tasks on the same set of workers.</span></div><div class="line">    <span class="comment">// 随机打乱offers,避免总是前几个worker被分配到任务</span></div><div class="line">    <span class="keyword">val</span> shuffledOffers = <span class="type">Random</span>.shuffle(offers)</div><div class="line">    <span class="comment">// Build a list of tasks to assign to each worker.</span></div><div class="line">    <span class="comment">// 构建一个二维数组，保存每个Executor上将要分配的那些task</span></div><div class="line">    <span class="keyword">val</span> tasks = shuffledOffers.map(o =&gt; <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>](o.cores))</div><div class="line">    <span class="keyword">val</span> availableCpus = shuffledOffers.map(o =&gt; o.cores).toArray</div><div class="line">    <span class="comment">// 根据SchedulerBuilder的调度算法，给TaskManager排好序</span></div><div class="line">    <span class="keyword">val</span> sortedTaskSets = rootPool.getSortedTaskSetQueue</div><div class="line">    <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets) &#123;</div><div class="line">      logDebug(<span class="string">"parentName: %s, name: %s, runningTasks: %s"</span>.format(</div><div class="line">        taskSet.parent.name, taskSet.name, taskSet.runningTasks))</div><div class="line">      <span class="keyword">if</span> (newExecAvail) &#123;</div><div class="line">        taskSet.executorAdded()</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// Take each TaskSet in our scheduling order, and then offer it each node in increasing order</span></div><div class="line">    <span class="comment">// of locality levels so that it gets a chance to launch local tasks on all of them.</span></div><div class="line">    <span class="comment">// <span class="doctag">NOTE:</span> the preferredLocality order: PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></div><div class="line">    <span class="comment">// 按照调度优先级顺序遍历TaskSet，在所有系统资源(WorkerOffer)上从最高Locality到最低Locality依次尝试执行最适合的task</span></div><div class="line">    <span class="comment">// 数据本地性级别顺序: PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></div><div class="line">    <span class="keyword">var</span> launchedTask = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets; maxLocality &lt;- taskSet.myLocalityLevels) &#123;</div><div class="line">      do &#123;</div><div class="line">        launchedTask = resourceOfferSingleTaskSet(</div><div class="line">            taskSet, maxLocality, shuffledOffers, availableCpus, tasks)</div><div class="line">      &#125; <span class="keyword">while</span> (launchedTask)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</div><div class="line">      hasLaunchedTask = <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> tasks</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSchedulerImpl-resourceOfferSingleTaskSet"><a href="#TaskSchedulerImpl-resourceOfferSingleTaskSet" class="headerlink" title="TaskSchedulerImpl.resourceOfferSingleTaskSet"></a>TaskSchedulerImpl.resourceOfferSingleTaskSet</h2><p>下面再看看resourceOfferSingleTaskSet代码<br>用当前的数据本地性，调用TaskSetManager的resourceOffer方法，在当前executor上分配task<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="type">TaskSchedulerImpl</span>.resourceOfferSingleTaskSet</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">resourceOfferSingleTaskSet</span></span>(</div><div class="line">      taskSet: <span class="type">TaskSetManager</span>,</div><div class="line">      maxLocality: <span class="type">TaskLocality</span>,</div><div class="line">      shuffledOffers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>],</div><div class="line">      availableCpus: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">      tasks: <span class="type">Seq</span>[<span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>]]) : <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">var</span> launchedTask = <span class="literal">false</span></div><div class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until shuffledOffers.size) &#123;</div><div class="line">      <span class="keyword">val</span> execId = shuffledOffers(i).executorId</div><div class="line">      <span class="keyword">val</span> host = shuffledOffers(i).host</div><div class="line">      <span class="comment">// 判断executor是否有足够的CPU核数来运行task</span></div><div class="line">      <span class="keyword">if</span> (availableCpus(i) &gt;= <span class="type">CPUS_PER_TASK</span>) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">          <span class="comment">// 真正调用的是TaskSetManager.resourceOffer方法</span></div><div class="line">          <span class="keyword">for</span> (task &lt;- taskSet.resourceOffer(execId, host, maxLocality)) &#123;</div><div class="line">            tasks(i) += task</div><div class="line">            <span class="keyword">val</span> tid = task.taskId</div><div class="line">            taskIdToTaskSetManager(tid) = taskSet</div><div class="line">            taskIdToExecutorId(tid) = execId</div><div class="line">            executorIdToTaskCount(execId) += <span class="number">1</span></div><div class="line">            executorsByHost(host) += execId</div><div class="line">            availableCpus(i) -= <span class="type">CPUS_PER_TASK</span></div><div class="line">            assert(availableCpus(i) &gt;= <span class="number">0</span>)</div><div class="line">            launchedTask = <span class="literal">true</span></div><div class="line">          &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="keyword">case</span> e: <span class="type">TaskNotSerializableException</span> =&gt;</div><div class="line">            logError(<span class="string">s"Resource offer failed, task set <span class="subst">$&#123;taskSet.name&#125;</span> was not serializable"</span>)</div><div class="line">            <span class="comment">// Do not offer resources for this task, but don't throw an error to allow other</span></div><div class="line">            <span class="comment">// task sets to be submitted.</span></div><div class="line">            <span class="keyword">return</span> launchedTask</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> launchedTask</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSetManager-resourceOffer"><a href="#TaskSetManager-resourceOffer" class="headerlink" title="TaskSetManager.resourceOffer"></a>TaskSetManager.resourceOffer</h2><p>TaskSetManager.resourceOffer方法的作用是为executor资源提供一个最符合数据本地性的任务<br>TaskLocality是枚举类，表示数据本地化的级别，其优先级为 PROCESS_LOCAL(最高) &lt; NODE_LOCAL &lt; NO_PREF &lt; RACK_LOCAL &lt; ANY(最低)<br>其中PROCESS_LOCAL，NODE_LOCAL，RACK_LOCAL可分别设置对应的延迟时间，默认值是3s<br>TaskSetManager内部维护了以下几个HashMap<br>1、pendingTasksForExecutor<br>2、pendingTasksForHost<br>3、pendingTasksForRack<br>4、pendingTasksWithNoPrefs<br>TaskSetManager在初始化时，若Task的preferredLocations不为空，则将Task添加到前三个pending队列；若为空，则加入pendingTasksWithNoPrefs<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// TaskSetManager.resourceOffer</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">resourceOffer</span></span>(</div><div class="line">    execId: <span class="type">String</span>,</div><div class="line">    host: <span class="type">String</span>,</div><div class="line">    maxLocality: <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span>)</div><div class="line">  : <span class="type">Option</span>[<span class="type">TaskDescription</span>] =</div><div class="line">&#123;</div><div class="line">  <span class="keyword">if</span> (!isZombie) &#123;</div><div class="line">    <span class="keyword">val</span> curTime = clock.getTimeMillis()</div><div class="line"></div><div class="line">    <span class="keyword">var</span> allowedLocality = maxLocality</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</div><div class="line">      <span class="comment">// 结合各Locality设置的延迟时间及上次成功在当前Locality级别提交任务的时间，获得能够允许的最高本地化级别的Locality级别</span></div><div class="line">      allowedLocality = getAllowedLocalityLevel(curTime)</div><div class="line">      <span class="comment">// 大于表示本地化级别更低</span></div><div class="line">      <span class="keyword">if</span> (allowedLocality &gt; maxLocality) &#123;</div><div class="line">        <span class="comment">// </span></div><div class="line">        allowedLocality = maxLocality</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// dequeueTask返回的是允许的Locality范围内Locality级别最高的Task的TaskDescription</span></div><div class="line">    dequeueTask(execId, host, allowedLocality) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>((index, taskLocality, speculative)) =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> task = tasks(index)</div><div class="line">        <span class="keyword">val</span> taskId = sched.newTaskId()</div><div class="line">        <span class="comment">// Do various bookkeeping</span></div><div class="line">        copiesRunning(index) += <span class="number">1</span></div><div class="line">        <span class="keyword">val</span> attemptNum = taskAttempts(index).size</div><div class="line">        <span class="keyword">val</span> info = <span class="keyword">new</span> <span class="type">TaskInfo</span>(taskId, index, attemptNum, curTime,</div><div class="line">          execId, host, taskLocality, speculative)</div><div class="line">        taskInfos(taskId) = info</div><div class="line">        taskAttempts(index) = info :: taskAttempts(index)</div><div class="line">        <span class="comment">// 除非Task的Locality级别为NO_PREF，否则更新当前Locality级别为该task的Locality，并更新lastLaunchTime</span></div><div class="line">        <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</div><div class="line">          currentLocalityIndex = getLocalityIndex(taskLocality)</div><div class="line">          lastLaunchTime = curTime</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 序列化task</span></div><div class="line">        <span class="keyword">val</span> startTime = clock.getTimeMillis()</div><div class="line">        <span class="keyword">val</span> serializedTask: <span class="type">ByteBuffer</span> = <span class="keyword">try</span> &#123;</div><div class="line">          <span class="type">Task</span>.serializeWithDependencies(task, sched.sc.addedFiles, sched.sc.addedJars, ser)</div><div class="line">        &#125; <span class="keyword">catch</span> &#123;</div><div class="line">          <span class="comment">// 序列化出错没有重试的必要</span></div><div class="line">          <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</div><div class="line">            <span class="keyword">val</span> msg = <span class="string">s"Failed to serialize task <span class="subst">$taskId</span>, not attempting to retry it."</span></div><div class="line">            logError(msg, e)</div><div class="line">            abort(<span class="string">s"<span class="subst">$msg</span> Exception during serialization: <span class="subst">$e</span>"</span>)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">TaskNotSerializableException</span>(e)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// 若task过大，则存在优化的必要</span></div><div class="line">        <span class="keyword">if</span> (serializedTask.limit &gt; <span class="type">TaskSetManager</span>.<span class="type">TASK_SIZE_TO_WARN_KB</span> * <span class="number">1024</span> &amp;&amp;</div><div class="line">            !emittedTaskSizeWarning) &#123;</div><div class="line">          emittedTaskSizeWarning = <span class="literal">true</span></div><div class="line">          logWarning(<span class="string">s"Stage <span class="subst">$&#123;task.stageId&#125;</span> contains a task of very large size "</span> +</div><div class="line">            <span class="string">s"(<span class="subst">$&#123;serializedTask.limit / 1024&#125;</span> KB). The maximum recommended task size is "</span> +</div><div class="line">            <span class="string">s"<span class="subst">$&#123;TaskSetManager.TASK_SIZE_TO_WARN_KB&#125;</span> KB."</span>)</div><div class="line">        &#125;</div><div class="line">        addRunningTask(taskId)</div><div class="line"></div><div class="line">        <span class="comment">// We used to log the time it takes to serialize the task, but task size is already</span></div><div class="line">        <span class="comment">// a good proxy to task serialization time.</span></div><div class="line">        <span class="comment">// val timeTaken = clock.getTime() - startTime</span></div><div class="line">        <span class="keyword">val</span> taskName = <span class="string">s"task <span class="subst">$&#123;info.id&#125;</span> in stage <span class="subst">$&#123;taskSet.id&#125;</span>"</span></div><div class="line">        logInfo(<span class="string">"Starting %s (TID %d, %s, %s, %d bytes)"</span>.format(</div><div class="line">            taskName, taskId, host, taskLocality, serializedTask.limit))</div><div class="line"></div><div class="line">        <span class="comment">// 通知DAGScheduler任务开始执行</span></div><div class="line">        sched.dagScheduler.taskStarted(task, info)</div><div class="line">        <span class="keyword">return</span> <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">TaskDescription</span>(taskId = taskId, attemptNumber = attemptNum, execId,</div><div class="line">          taskName, index, serializedTask))</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> _ =&gt;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="type">None</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="TaskSetManager-getAllowedLocalityLevel"><a href="#TaskSetManager-getAllowedLocalityLevel" class="headerlink" title="TaskSetManager.getAllowedLocalityLevel"></a>TaskSetManager.getAllowedLocalityLevel</h2><p>TaskSetManager.getAllowedLocalityLevel结合各Locality设置的延迟时间及上次成功在当前Locality级别提交任务的时间，获得能够允许的最高本地化级别的Locality级别<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// TaskSetManager.getAllowedLocalityLevel</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getAllowedLocalityLevel</span></span>(curTime: <span class="type">Long</span>): <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span> = &#123;</div><div class="line">  <span class="comment">// 移除已被调度或完成的task，采用的是lazy方式</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">tasksNeedToBeScheduledFrom</span></span>(pendingTaskIds: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">var</span> indexOffset = pendingTaskIds.size</div><div class="line">    <span class="keyword">while</span> (indexOffset &gt; <span class="number">0</span>) &#123;</div><div class="line">      indexOffset -= <span class="number">1</span></div><div class="line">      <span class="keyword">val</span> index = pendingTaskIds(indexOffset)</div><div class="line">      <span class="keyword">if</span> (copiesRunning(index) == <span class="number">0</span> &amp;&amp; !successful(index)) &#123;</div><div class="line">        <span class="keyword">return</span> <span class="literal">true</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        pendingTaskIds.remove(indexOffset)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="literal">false</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// 遍历pendingTasks，移除已被调度的task，若仍有task待调度，返回true</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">moreTasksToRunIn</span></span>(pendingTasks: <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]]): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">val</span> emptyKeys = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">String</span>]</div><div class="line">    <span class="keyword">val</span> hasTasks = pendingTasks.exists &#123;</div><div class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, tasks: <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]) =&gt;</div><div class="line">        <span class="keyword">if</span> (tasksNeedToBeScheduledFrom(tasks)) &#123;</div><div class="line">          <span class="literal">true</span></div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">          emptyKeys += id</div><div class="line">          <span class="literal">false</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// The key could be executorId, host or rackId</span></div><div class="line">    emptyKeys.foreach(id =&gt; pendingTasks.remove(id))</div><div class="line">    hasTasks</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// currentLocalityIndex记录了当前运行在哪个TaskLocality</span></div><div class="line">  <span class="keyword">while</span> (currentLocalityIndex &lt; myLocalityLevels.length - <span class="number">1</span>) &#123;</div><div class="line">    <span class="keyword">val</span> moreTasks = myLocalityLevels(currentLocalityIndex) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">PROCESS_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForExecutor)</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">NODE_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForHost)</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span> =&gt; pendingTasksWithNoPrefs.nonEmpty</div><div class="line">      <span class="keyword">case</span> <span class="type">TaskLocality</span>.<span class="type">RACK_LOCAL</span> =&gt; moreTasksToRunIn(pendingTasksForRack)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (!moreTasks) &#123;</div><div class="line">      <span class="comment">// 若当前Locality没有需要执行的task，则进入更低一级Locality，并更新lastLaunchTime</span></div><div class="line">      lastLaunchTime = curTime</div><div class="line">      logDebug(<span class="string">s"No tasks for locality level <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex)&#125;</span>, "</span> +</div><div class="line">        <span class="string">s"so moving to locality level <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex + 1)&#125;</span>"</span>)</div><div class="line">      currentLocalityIndex += <span class="number">1</span></div><div class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curTime - lastLaunchTime &gt;= localityWaits(currentLocalityIndex)) &#123;</div><div class="line">      <span class="comment">// 若距离上次成功在此Locality级别提交任务的时间间隔超过了该Locality级别设定的延迟时间，则进入更低一级Locality，并更新lastLaunchTime</span></div><div class="line">      lastLaunchTime += localityWaits(currentLocalityIndex)</div><div class="line">      currentLocalityIndex += <span class="number">1</span></div><div class="line">      logDebug(<span class="string">s"Moving to <span class="subst">$&#123;myLocalityLevels(currentLocalityIndex)&#125;</span> after waiting for "</span> +</div><div class="line">        <span class="string">s"<span class="subst">$&#123;localityWaits(currentLocalityIndex)&#125;</span>ms"</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="keyword">return</span> myLocalityLevels(currentLocalityIndex)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  myLocalityLevels(currentLocalityIndex)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>取得最适合运行的Task后，调用ScheduledBackend.launchTasks方法 将task在Executor上启动运行</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="http://www.cnblogs.com/zhouyf/p/5743382.html" target="_blank" rel="external">http://www.cnblogs.com/zhouyf/p/5743382.html</a><br><a href="http://blog.csdn.net/anzhsoft/article/details/40238111#comments" target="_blank" rel="external">http://blog.csdn.net/anzhsoft/article/details/40238111#comments</a><br><a href="http://blog.csdn.net/bigdata_wang/article/details/48846129" target="_blank" rel="external">http://blog.csdn.net/bigdata_wang/article/details/48846129</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/19/hbase分布式搭建/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/19/hbase分布式搭建/" itemprop="url">
                  hbase分布式搭建
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-19T11:45:40+08:00">
                2017-01-19
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="已有的环境"><a href="#已有的环境" class="headerlink" title="已有的环境"></a>已有的环境</h2><p>三台机器hostname: master, worker1, worker2<br>并已安装好分布式Hadoop2.6.0</p>
<h3 id="定位JAVA-HOME"><a href="#定位JAVA-HOME" class="headerlink" title="定位JAVA_HOME"></a>定位JAVA_HOME</h3><p>mac: 使用命令/usr/libexec/java_home<br><img src="/images/201701/JAVA_HOME_2.png"><br>linux: 如下图所示<br><img src="/images/201701/JAVA_HOME_1.png"></p>
<h2 id="下载HBase"><a href="#下载HBase" class="headerlink" title="下载HBase"></a>下载HBase</h2><p>官网下载地址：<a href="http://www.apache.org/dyn/closer.cgi/hbase/" target="_blank" rel="external">http://www.apache.org/dyn/closer.cgi/hbase/</a><br>我下载的是Stable版本：<a href="http://mirrors.cnnic.cn/apache/hbase/stable/hbase-1.2.4-bin.tar.gz" target="_blank" rel="external">http://mirrors.cnnic.cn/apache/hbase/stable/hbase-1.2.4-bin.tar.gz</a></p>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>将下载后的压缩包解压后 放到/Users/xiwu/hbase-1.2.4目录下</p>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-env-sh"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-env-sh" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-env.sh"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-env.sh</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=通过之前方法定位</div><div class="line"><span class="built_in">export</span> HBASE_LOG_DIR=/Users/xiwu/hbase-1.2.4/logs</div><div class="line"><span class="comment">#如果使用HBase自带的Zookeeper值设成true 如果使用自己安装的Zookeeper需要将该值设为false</span></div><div class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">true</span></div></pre></td></tr></table></figure>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-site-xml"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-hbase-site-xml" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-site.xml"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim hbase-site.xml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.rootdir&lt;/name&gt;</div><div class="line">        &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</div><div class="line">        &lt;value&gt;true&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</div><div class="line">        &lt;value&gt;master,worker1,worker2&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hbase.master.maxclockskew&lt;/name&gt;</div><div class="line">        &lt;value&gt;180000&lt;/value&gt;</div><div class="line">        &lt;description&gt;Time difference of regionserver from master&lt;/description&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>hbase.rootdir 指定Hbase数据存储目录<br>hbase.cluster.distributed 指定是否是完全分布式模式，单机模式和伪分布式模式需要将该值设为false<br>hbase.zookeeper.quorum 指定zooke的集群，多台机器以逗号分隔</p>
<h3 id="cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-regionservers"><a href="#cd-Users-xiwu-hbase-1-2-4-conf-amp-amp-vim-regionservers" class="headerlink" title="cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim regionservers"></a>cd /Users/xiwu/hbase-1.2.4/conf &amp;&amp; vim regionservers</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">master</div><div class="line">worker1</div><div class="line">worker2</div></pre></td></tr></table></figure>
<p>PS.以上操作在三台机器都相同。可以在一台机器上弄好后，scp复制过去</p>
<h2 id="启动HBase"><a href="#启动HBase" class="headerlink" title="启动HBase"></a>启动HBase</h2><p>//先启动hdfs<br>cd ${HADOOP_HOME} &amp;&amp; ./sbin/start-dfs.sh<br>//再启动hbase<br>cd ${HBASE_HOME} &amp;&amp; ./bin/start-hbase.sh<br>正确启动后结果如图所示:<br><img src="/images/201701/hbase_1.png"><br>master: HMaster,HQuorumPeer,HRegionServer<br>worker1,worker2: HQuorumPeer,HRegionServer<br>也可以登录：<a href="http://master:16010/" target="_blank" rel="external">http://master:16010/</a> 查看HBase状态<br>如果所示:<br><img src="/images/201701/hbase_2.png"></p>
<h2 id="测试HBase"><a href="#测试HBase" class="headerlink" title="测试HBase"></a>测试HBase</h2><p>cd ${HBASE_HOME} &amp;&amp; ./bin/hbase shell<br><img src="/images/201701/hbase_3.png"><br><img src="/images/201701/hbase_4.png"><br><img src="/images/201701/hbase_5.png"><br>更多操作参考<a href="http://www.yiibai.com/hbase/hbase_shell.html" target="_blank" rel="external">http://www.yiibai.com/hbase/hbase_shell.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/18/spark提交任务源码浅析/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/18/spark提交任务源码浅析/" itemprop="url">
                  Spark源码浅析：Stage划分及提交Task
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-18T11:37:59+08:00">
                2017-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="spark版本"><a href="#spark版本" class="headerlink" title="spark版本"></a>spark版本</h3><p>spark 1.6.1</p>
<h2 id="从Rdd的action开始追源码，最后都会到rdd-runJob"><a href="#从Rdd的action开始追源码，最后都会到rdd-runJob" class="headerlink" title="从Rdd的action开始追源码，最后都会到rdd.runJob"></a>从Rdd的action开始追源码，最后都会到rdd.runJob</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// RDD.scala</span></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Run a function on a given set of partitions in an RDD and pass the results to the given</div><div class="line">   * handler function. This is the main entry point for all actions in Spark.</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](</div><div class="line">      rdd: <span class="type">RDD</span>[<span class="type">T</span>],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</div><div class="line">      partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</div><div class="line">      resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">if</span> (stopped.get()) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">"SparkContext has been shutdown"</span>)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">val</span> callSite = getCallSite</div><div class="line">    <span class="keyword">val</span> cleanedFunc = clean(func)</div><div class="line">    logInfo(<span class="string">"Starting job: "</span> + callSite.shortForm)</div><div class="line">    <span class="keyword">if</span> (conf.getBoolean(<span class="string">"spark.logLineage"</span>, <span class="literal">false</span>)) &#123;</div><div class="line">      logInfo(<span class="string">"RDD's recursive dependencies:\n"</span> + rdd.toDebugString)</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</div><div class="line">    progressBar.foreach(_.finishAll())</div><div class="line">    rdd.doCheckpoint()</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>可以看到接下来调用了dagScheduler.runJob<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</div><div class="line">      rdd: <span class="type">RDD</span>[<span class="type">T</span>],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</div><div class="line">      partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</div><div class="line">      callSite: <span class="type">CallSite</span>,</div><div class="line">      resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</div><div class="line">      properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> start = <span class="type">System</span>.nanoTime</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</div><div class="line">    waiter.awaitResult() <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">JobSucceeded</span> =&gt;</div><div class="line">        logInfo(<span class="string">"Job %d finished: %s, took %f s"</span>.format</div><div class="line">          (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</div><div class="line">      <span class="keyword">case</span> <span class="type">JobFailed</span>(exception: <span class="type">Exception</span>) =&gt;</div><div class="line">        logInfo(<span class="string">"Job %d failed: %s, took %f s"</span>.format</div><div class="line">          (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</div><div class="line">        <span class="comment">// SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.</span></div><div class="line">        <span class="keyword">val</span> callerStackTrace = <span class="type">Thread</span>.currentThread().getStackTrace.tail</div><div class="line">        exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)</div><div class="line">        <span class="keyword">throw</span> exception</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</div><div class="line">      rdd: <span class="type">RDD</span>[<span class="type">T</span>],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</div><div class="line">      partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</div><div class="line">      callSite: <span class="type">CallSite</span>,</div><div class="line">      resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</div><div class="line">      properties: <span class="type">Properties</span>): <span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</div><div class="line">    <span class="comment">// Check to make sure we are not launching a task on a partition that does not exist.</span></div><div class="line">    <span class="keyword">val</span> maxPartitions = rdd.partitions.length</div><div class="line">    partitions.find(p =&gt; p &gt;= maxPartitions || p &lt; <span class="number">0</span>).foreach &#123; p =&gt;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(</div><div class="line">        <span class="string">"Attempting to access a non-existent partition: "</span> + p + <span class="string">". "</span> +</div><div class="line">          <span class="string">"Total number of partitions: "</span> + maxPartitions)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> jobId = nextJobId.getAndIncrement()</div><div class="line">    <span class="keyword">if</span> (partitions.size == <span class="number">0</span>) &#123;</div><div class="line">      <span class="comment">// Return immediately if the job is running 0 tasks</span></div><div class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, <span class="number">0</span>, resultHandler)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    assert(partitions.size &gt; <span class="number">0</span>)</div><div class="line">    <span class="keyword">val</span> func2 = func.asInstanceOf[(<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _]</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>(<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</div><div class="line">    eventProcessLoop.post(<span class="type">JobSubmitted</span>(</div><div class="line">      jobId, rdd, func2, partitions.toArray, callSite, waiter,</div><div class="line">      <span class="type">SerializationUtils</span>.clone(properties)))</div><div class="line">    waiter</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>eventProcessLoop是DAGSchedulerEventProcessLoop类的实例，DAGSchedulerEventProcessLoop类是EventLoop的子类。EventLoop里有一个阻塞队列，post函数往队列里放请求，还有开启了一个线程不断从队列里取请求。<br>以上代码总结，往队列里放了一个JobSubmitted的请求，然后需要处理JobSubmitted请求了<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line"><span class="keyword">private</span>[scheduler] <span class="class"><span class="keyword">class</span> <span class="title">DAGSchedulerEventProcessLoop</span>(<span class="params">dagScheduler: <span class="type">DAGScheduler</span></span>)</span></div><div class="line">  <span class="keyword">extends</span> <span class="type">EventLoop</span>[<span class="type">DAGSchedulerEvent</span>](<span class="string">"dag-scheduler-event-loop"</span>) <span class="keyword">with</span> <span class="type">Logging</span> &#123;</div><div class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> timer = dagScheduler.metricsSource.messageProcessingTimer</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * The main event loop of the DAG scheduler.</div><div class="line">   */</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> timerContext = timer.time()</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      doOnReceive(event)</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      timerContext.stop()</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doOnReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = event <span class="keyword">match</span> &#123;</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">case</span> <span class="type">JobSubmitted</span>(jobId, rdd, func, partitions, callSite, listener, properties) =&gt;</div><div class="line">      dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</div><div class="line">      ...</div><div class="line">      ...</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">  <span class="comment">/*</span></div><div class="line">  * 下面的代码中，调用了newResultStage进行任务的划分，该方法是划分任务的核心方法，划分任务的根据最后一个依赖关系作为开始，</div><div class="line">  * 通过递归，将每个宽依赖做为切分Stage的依据，切分Stage的过程是流程中的一环，当任务切分完毕后</div><div class="line">  * 代码继续执行来到submitStage(finalStage)这里开始进行任务提交</div><div class="line">  */</div><div class="line">  <span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</div><div class="line">      finalRDD: <span class="type">RDD</span>[_],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</div><div class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">      callSite: <span class="type">CallSite</span>,</div><div class="line">      listener: <span class="type">JobListener</span>,</div><div class="line">      properties: <span class="type">Properties</span>) &#123;</div><div class="line">    <span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      <span class="comment">// New stage creation may throw an exception if, for example, jobs are run on a</span></div><div class="line">      <span class="comment">// HadoopRDD whose underlying HDFS files have been deleted.</span></div><div class="line">      <span class="comment">//== Next Step 1==</span></div><div class="line">      finalStage = newResultStage(finalRDD, func, partitions, jobId, callSite)</div><div class="line">    &#125; <span class="keyword">catch</span> &#123;</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</div><div class="line">        logWarning(<span class="string">"Creating new stage failed due to exception - job: "</span> + jobId, e)</div><div class="line">        listener.jobFailed(e)</div><div class="line">        <span class="keyword">return</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)</div><div class="line">    clearCacheLocs()</div><div class="line">    logInfo(<span class="string">"Got job %s (%s) with %d output partitions"</span>.format(</div><div class="line">      job.jobId, callSite.shortForm, partitions.length))</div><div class="line">    logInfo(<span class="string">"Final stage: "</span> + finalStage + <span class="string">" ("</span> + finalStage.name + <span class="string">")"</span>)</div><div class="line">    logInfo(<span class="string">"Parents of final stage: "</span> + finalStage.parents)</div><div class="line">    logInfo(<span class="string">"Missing parents: "</span> + getMissingParentStages(finalStage))</div><div class="line"></div><div class="line">    <span class="keyword">val</span> jobSubmissionTime = clock.getTimeMillis()</div><div class="line">    jobIdToActiveJob(jobId) = job</div><div class="line">    activeJobs += job</div><div class="line">    finalStage.setActiveJob(job)</div><div class="line">    <span class="keyword">val</span> stageIds = jobIdToStageIds(jobId).toArray</div><div class="line">    <span class="keyword">val</span> stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))</div><div class="line">    listenerBus.post(</div><div class="line">      <span class="type">SparkListenerJobStart</span>(job.jobId, jobSubmissionTime, stageInfos, properties))</div><div class="line">    <span class="comment">//== Next Step 2==</span></div><div class="line">    submitStage(finalStage)</div><div class="line">    submitWaitingStages()</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>newResultStage函数 通过传入finalRDD最后返回finalStage (stage之间和rdd之间都会有依赖关系, newResultStage函数是 通过rdd之间的依赖关系 划分stage的)<br>继续看源码<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Create a ResultStage associated with the provided jobId.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">newResultStage</span></span>(</div><div class="line">      rdd: <span class="type">RDD</span>[_],</div><div class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</div><div class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</div><div class="line">      jobId: <span class="type">Int</span>,</div><div class="line">      callSite: <span class="type">CallSite</span>): <span class="type">ResultStage</span> = &#123;</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">val</span> (parentStages: <span class="type">List</span>[<span class="type">Stage</span>], id: <span class="type">Int</span>) = getParentStagesAndId(rdd, jobId)</div><div class="line">    <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ResultStage</span>(id, rdd, func, partitions, parentStages, jobId, callSite)</div><div class="line">    stageIdToStage(id) = stage</div><div class="line">    updateJobIdStageIdMaps(jobId, stage)</div><div class="line">    stage</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getParentStagesAndId</span></span>(rdd: <span class="type">RDD</span>[_], firstJobId: <span class="type">Int</span>): (<span class="type">List</span>[<span class="type">Stage</span>], <span class="type">Int</span>) = &#123;</div><div class="line">    <span class="comment">//== Next Step ==</span></div><div class="line">    <span class="keyword">val</span> parentStages = getParentStages(rdd, firstJobId)</div><div class="line">    <span class="keyword">val</span> id = nextStageId.getAndIncrement()</div><div class="line">    (parentStages, id)</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>以上代码是为了获取finalRDD对应finalStages的所有依赖父Stage</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Get or create the list of parent stages for a given RDD.  The new Stages will be created with</div><div class="line">   * the provided firstJobId.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getParentStages</span></span>(rdd: <span class="type">RDD</span>[_], firstJobId: <span class="type">Int</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> parents = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</div><div class="line">    <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></div><div class="line">    <span class="comment">// caused by recursively visiting</span></div><div class="line">    <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(r: <span class="type">RDD</span>[_]) &#123;</div><div class="line">      <span class="keyword">if</span> (!visited(r)) &#123;</div><div class="line">        visited += r</div><div class="line">        <span class="comment">// Kind of ugly: need to register RDDs with the cache here since</span></div><div class="line">        <span class="comment">// we can't do it in its constructor because # of partitions is unknown</span></div><div class="line">        <span class="keyword">for</span> (dep &lt;- r.dependencies) &#123;</div><div class="line">          dep <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</div><div class="line">              <span class="comment">//== Next Step == PS.如果是finalRdd的直接宽依赖，那么需要划分stage了</span></div><div class="line">              parents += getShuffleMapStage(shufDep, firstJobId)</div><div class="line">            <span class="keyword">case</span> _ =&gt;</div><div class="line">              waitingForVisit.push(dep.rdd)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    waitingForVisit.push(rdd)</div><div class="line">    <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</div><div class="line">      visit(waitingForVisit.pop())</div><div class="line">    &#125;</div><div class="line">    parents.toList</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">   * Get or create a shuffle map stage for the given shuffle dependency's map side.</div><div class="line">   */</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getShuffleMapStage</span></span>(</div><div class="line">      shuffleDep: <span class="type">ShuffleDependency</span>[_, _, _],</div><div class="line">      firstJobId: <span class="type">Int</span>): <span class="type">ShuffleMapStage</span> = &#123;</div><div class="line">    shuffleToMapStage.get(shuffleDep.shuffleId) <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> <span class="type">Some</span>(stage) =&gt; stage</div><div class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt;</div><div class="line">        <span class="comment">// We are going to register ancestor shuffle dependencies</span></div><div class="line">        <span class="comment">//== Next Step == PS.找到finalRdd的直接宽依赖rdd 对应的祖先宽依赖，进行注册</span></div><div class="line">        getAncestorShuffleDependencies(shuffleDep.rdd).foreach &#123; dep =&gt;</div><div class="line">          shuffleToMapStage(dep.shuffleId) = newOrUsedShuffleStage(dep, firstJobId)</div><div class="line">        &#125;</div><div class="line">        <span class="comment">// Then register current shuffleDep</span></div><div class="line">        <span class="keyword">val</span> stage = newOrUsedShuffleStage(shuffleDep, firstJobId)</div><div class="line">        shuffleToMapStage(shuffleDep.shuffleId) = stage</div><div class="line">        stage</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>以上代码是找到finalRdd的直接父Stage。并在找到直接宽依赖rdd的时候，对先找到这些rdd的所有祖先宽依赖，再对这些祖先宽依赖进行注册(这里也会划分stage)。<br>下面的代码是如果找到rdd的所有祖先宽依赖(直接或间接)<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// DAGScheduler.scala</span></div><div class="line">  <span class="comment">/** Find ancestor shuffle dependencies that are not registered in shuffleToMapStage yet */</span></div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getAncestorShuffleDependencies</span></span>(rdd: <span class="type">RDD</span>[_]): <span class="type">Stack</span>[<span class="type">ShuffleDependency</span>[_, _, _]] = &#123;</div><div class="line">    <span class="keyword">val</span> parents = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">ShuffleDependency</span>[_, _, _]]</div><div class="line">    <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></div><div class="line">    <span class="comment">// caused by recursively visiting</span></div><div class="line">    <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">RDD</span>[_]]</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(r: <span class="type">RDD</span>[_]) &#123;</div><div class="line">      <span class="keyword">if</span> (!visited(r)) &#123;</div><div class="line">        visited += r</div><div class="line">        <span class="keyword">for</span> (dep &lt;- r.dependencies) &#123;</div><div class="line">          dep <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</div><div class="line">              <span class="keyword">if</span> (!shuffleToMapStage.contains(shufDep.shuffleId)) &#123;</div><div class="line">                parents.push(shufDep)</div><div class="line">              &#125;</div><div class="line">            <span class="keyword">case</span> _ =&gt;</div><div class="line">          &#125;</div><div class="line">          waitingForVisit.push(dep.rdd)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    waitingForVisit.push(rdd)</div><div class="line">    <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</div><div class="line">      visit(waitingForVisit.pop())</div><div class="line">    &#125;</div><div class="line">    parents</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>下面举一个例子来说明划分stage的过程<br><img src="/images/201701/dagPicture_1.png"><br>图说明：12表示finalRdd,蓝色表示宽依赖,黑色表示窄依赖<br>1、newResultStage函数 入参12号finalRdd, 通过函数getParentStagesAndId得到finalRdd的直接宽依赖9,10,4,5号Rdd在的Stage。并且注册9,10,4,5号Rdd在的Stage对应的所有直接或间接Stage(通过getParentStagesAndId下的getShuffleMapStage函数)<br>2、getShuffleMapStage函数 入参(举例:10号Rdd在的Stage), 通过函数getAncestorShuffleDependencies得到10号Rdd的所有直接或间接宽依赖(宽依赖有2号和3号)，并通过函数newOrUsedShuffleStage进行注册2号和3号成为新的Stage<br>最后划分的Stage如下图所示：<br><img src="/images/201701/dagPicture_2.png"></p>
<p>回到DAGScheduler.handleJobSubmitted函数<br>以上部分完成了handleJobSubmitted函数的newResultStage步骤(划分Stage)，函数还有submitStage步骤<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/** Submits stage, but first recursively submits any missing parents. */</span></div><div class="line"><span class="comment">//递归的方式提交stage</span></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>) &#123;</div><div class="line">  <span class="keyword">val</span> jobId = activeJobForStage(stage)</div><div class="line">  <span class="keyword">if</span> (jobId.isDefined) &#123;</div><div class="line">    logDebug(<span class="string">"submitStage("</span> + stage + <span class="string">")"</span>)</div><div class="line">    <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</div><div class="line">      <span class="comment">//== Next Step 1 ==</span></div><div class="line">      <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id) <span class="comment">//获取未提交过的直接宽依赖</span></div><div class="line">      logDebug(<span class="string">"missing: "</span> + missing)</div><div class="line">      <span class="keyword">if</span> (missing.isEmpty) &#123;</div><div class="line">        logInfo(<span class="string">"Submitting "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">"), which has no missing parents"</span>)</div><div class="line">        <span class="comment">//== Next Step 2 ==</span></div><div class="line">        submitMissingTasks(stage, jobId.get) <span class="comment">//提交任务(parentStage都提交过了)</span></div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">for</span> (parent &lt;- missing) &#123;</div><div class="line">          <span class="comment">//提交 没有提交过的parentStage</span></div><div class="line">          submitStage(parent)</div><div class="line">        &#125;</div><div class="line">        waitingStages += stage <span class="comment">//记录待提交的Stages</span></div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    abortStage(stage, <span class="string">"No active job for stage "</span> + stage.id, <span class="type">None</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getMissingParentStages</span></span>(stage: <span class="type">Stage</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</div><div class="line">  <span class="keyword">val</span> missing = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</div><div class="line">  <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</div><div class="line">  <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></div><div class="line">  <span class="comment">// caused by recursively visiting</span></div><div class="line">  <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">RDD</span>[_]]</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(rdd: <span class="type">RDD</span>[_]) &#123;</div><div class="line">    <span class="keyword">if</span> (!visited(rdd)) &#123;</div><div class="line">      visited += rdd</div><div class="line">      <span class="keyword">val</span> rddHasUncachedPartitions = getCacheLocs(rdd).contains(<span class="type">Nil</span>)</div><div class="line">      <span class="keyword">if</span> (rddHasUncachedPartitions) &#123;</div><div class="line">        <span class="keyword">for</span> (dep &lt;- rdd.dependencies) &#123;</div><div class="line">          dep <span class="keyword">match</span> &#123;</div><div class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</div><div class="line">              <span class="keyword">val</span> mapStage = getShuffleMapStage(shufDep, stage.firstJobId)</div><div class="line">              <span class="keyword">if</span> (!mapStage.isAvailable) &#123;</div><div class="line">                missing += mapStage</div><div class="line">              &#125;</div><div class="line">            <span class="keyword">case</span> narrowDep: <span class="type">NarrowDependency</span>[_] =&gt;</div><div class="line">              waitingForVisit.push(narrowDep.rdd)</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  waitingForVisit.push(stage.rdd)</div><div class="line">  <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</div><div class="line">    visit(waitingForVisit.pop())</div><div class="line">  &#125;</div><div class="line">  missing.toList</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>继续以上面的图为例，submitStage(Stage8) =&gt; getMissingParentStages(Stage8) 得到 Stage4, Stage5, Stage6, Stage7<br>再递归提交submitStage(Stage4), submitStage(Stage5),submitStage(Stage6),submitStage(Stage7)…<br>最后能调用submitMissingTasks函数的有Stage1, Stage2, Stage3, Stage4, Stage5<br>waitingStages记录待提交有Stage6, Stage7, Stage8.最后通过DAGScheduler.handleJobSubmitted的submitWaitingStages处理这些待提交的Stage<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitWaitingStages</span></span>() &#123;</div><div class="line">  <span class="comment">// <span class="doctag">TODO:</span> We might want to run this less often, when we are sure that something has become</span></div><div class="line">  <span class="comment">// runnable that wasn't before.</span></div><div class="line">  logTrace(<span class="string">"Checking for newly runnable parent stages"</span>)</div><div class="line">  logTrace(<span class="string">"running: "</span> + runningStages)</div><div class="line">  logTrace(<span class="string">"waiting: "</span> + waitingStages)</div><div class="line">  logTrace(<span class="string">"failed: "</span> + failedStages)</div><div class="line">  <span class="keyword">val</span> waitingStagesCopy = waitingStages.toArray</div><div class="line">  waitingStages.clear()</div><div class="line">  <span class="keyword">for</span> (stage &lt;- waitingStagesCopy.sortBy(_.firstJobId)) &#123;</div><div class="line">    submitStage(stage)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>先告一段落..</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/01/17/elk简单搭建/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/01/17/elk简单搭建/" itemprop="url">
                  elk简单分布式搭建
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-01-17T17:16:52+08:00">
                2017-01-17
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="机器Hostname"><a href="#机器Hostname" class="headerlink" title="机器Hostname"></a>机器Hostname</h2><p>master, worker1, worker2</p>
<h1 id="安装logstash"><a href="#安装logstash" class="headerlink" title="安装logstash"></a>安装logstash</h1><h3 id="下载logstash"><a href="#下载logstash" class="headerlink" title="下载logstash"></a>下载logstash</h3><p>master,worker1,worker2 重复以下操作<br>官网下载地址：<a href="https://www.elastic.co/downloads/logstash" target="_blank" rel="external">https://www.elastic.co/downloads/logstash</a><br>我将下载后的压缩包解压在/opt/elasticsearch/logstash-5.1.1目录</p>
<h3 id="举一个简单的使用例子"><a href="#举一个简单的使用例子" class="headerlink" title="举一个简单的使用例子:"></a>举一个简单的使用例子:</h3><p>编辑测试数据<br>vim /opt/elasticsearch/logstash-5.1.1/test_data/2.log<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a</div><div class="line">b</div><div class="line">c</div><div class="line">efg</div></pre></td></tr></table></figure></p>
<h3 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><p>vim /opt/elasticsearch/logstash-5.1.1/config/test.conf<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">input &#123;</div><div class="line">    file &#123;</div><div class="line">        <span class="comment">#监听文件的路径</span></div><div class="line">        path =&gt; <span class="string">"/opt/elasticsearch/logstash-5.1.1/test_data/2.log"</span></div><div class="line">        <span class="comment">#监听文件的起始位置，默认是end</span></div><div class="line">        start_position =&gt; beginning</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line">filter &#123;</div><div class="line">&#125;</div><div class="line">output &#123;</div><div class="line">    <span class="comment">#输出到屏幕上</span></div><div class="line">    stdout &#123;&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="启动logstash"><a href="#启动logstash" class="headerlink" title="启动logstash"></a>启动logstash</h3><p>cd /opt/elasticsearch/logstash-5.1.1 &amp;&amp; ./bin/logstash -f ./config/test.conf<br>结果如图所示，PS.追加写文件，logstash也会跟着输出到屏幕上<br><img src="/images/201701/logstash_1.png"></p>
<h1 id="安装elasticsearch"><a href="#安装elasticsearch" class="headerlink" title="安装elasticsearch"></a>安装elasticsearch</h1><h3 id="下载elasticsearch"><a href="#下载elasticsearch" class="headerlink" title="下载elasticsearch"></a>下载elasticsearch</h3><p>官网下载地址：<a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="external">https://www.elastic.co/downloads/elasticsearch</a><br>将下载后的压缩包解压在/opt/elasticsearch/elasticsearch-5.1.1目录</p>
<h3 id="编辑配置文件-1"><a href="#编辑配置文件-1" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><p>cd /opt/elasticsearch/elasticsearch-5.1.1 &amp;&amp; vim ./config/elasticsearch.yml<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#master的config/elasticsearch.yml</span></div><div class="line">cluster.name: elasticsearch_cluster</div><div class="line">node.name: node-master</div><div class="line">path.data: /opt/elasticsearch/elasticsearch-5.1.1/data <span class="comment">#需要自己建目录</span></div><div class="line">path.logs: /opt/elasticsearch/elasticsearch-5.1.1/logs <span class="comment">#需要自己建目录</span></div><div class="line">network.host: master</div><div class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"master"</span>, <span class="string">"worker1"</span>, <span class="string">"worker2"</span>]</div><div class="line"></div><div class="line"><span class="comment">#worker1的config/elasticsearch.yml</span></div><div class="line">cluster.name: elasticsearch_cluster</div><div class="line">node.name: node-worker1</div><div class="line">path.data: /opt/elasticsearch/elasticsearch-5.1.1/data <span class="comment">#需要自己建目录</span></div><div class="line">path.logs: /opt/elasticsearch/elasticsearch-5.1.1/logs <span class="comment">#需要自己建目录</span></div><div class="line">network.host: worker1</div><div class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"master"</span>, <span class="string">"worker1"</span>, <span class="string">"worker2"</span>]</div><div class="line"></div><div class="line"><span class="comment">#worker2的config/elasticsearch.yml</span></div><div class="line">cluster.name: elasticsearch_cluster</div><div class="line">node.name: node-worker2</div><div class="line">path.data: /opt/elasticsearch/elasticsearch-5.1.1/data <span class="comment">#需要自己建目录</span></div><div class="line">path.logs: /opt/elasticsearch/elasticsearch-5.1.1/logs <span class="comment">#需要自己建目录</span></div><div class="line">network.host: worker2</div><div class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"master"</span>, <span class="string">"worker1"</span>, <span class="string">"worker2"</span>]</div></pre></td></tr></table></figure></p>
<h3 id="启动elasticsearch"><a href="#启动elasticsearch" class="headerlink" title="启动elasticsearch"></a>启动elasticsearch</h3><p>cd /opt/elasticsearch/elasticsearch-5.1.1 &amp;&amp; ./bin/elasticsearch<br>启动结果如果所示(先启动master，再worker1,worker2)<br><img src="/images/201701/elasticSearch_1.png"><br>可以在master的启动日志 看到加入节点worker1、worker2的消息<br>PS.不能用root用户启动，我是创建了elasticSearch用户</p>
<h1 id="安装kibana"><a href="#安装kibana" class="headerlink" title="安装kibana"></a>安装kibana</h1><h3 id="下载kibana"><a href="#下载kibana" class="headerlink" title="下载kibana"></a>下载kibana</h3><p>官网下载地址：<a href="https://www.elastic.co/downloads/kibana" target="_blank" rel="external">https://www.elastic.co/downloads/kibana</a><br>注.mac和linux版本不一样<br>将下载后的压缩包解压在/opt/elasticsearch/kibana-5.1.1-linux-x86_64目录</p>
<h3 id="编辑配置文件-2"><a href="#编辑配置文件-2" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><p>cd /opt/elasticsearch/kibana-5.1.1-linux-x86_64 &amp;&amp; vim ./config/kibana.yml<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#worker1的config/kibana.yml</span></div><div class="line">server.port: 5601</div><div class="line">server.host: <span class="string">"master"</span></div><div class="line">elasticsearch.url: <span class="string">"http://master:9200"</span> <span class="comment">#elasticsearch地址</span></div><div class="line"></div><div class="line"><span class="comment">#worker1的config/kibana.yml</span></div><div class="line">server.port: 5601</div><div class="line">server.host: <span class="string">"worker1"</span></div><div class="line">elasticsearch.url: <span class="string">"http://worker1:9200"</span> <span class="comment">#elasticsearch地址</span></div><div class="line"></div><div class="line"><span class="comment">#worker2的config/kibana.yml</span></div><div class="line">server.port: 5601</div><div class="line">server.host: <span class="string">"worker2"</span></div><div class="line">elasticsearch.url: <span class="string">"http://worker2:9200"</span> <span class="comment">#elasticsearch地址</span></div></pre></td></tr></table></figure></p>
<h3 id="启动kibana"><a href="#启动kibana" class="headerlink" title="启动kibana"></a>启动kibana</h3><p>cd /opt/elasticsearch/elasticsearch-5.1.1 &amp;&amp; ./bin/kibana</p>
<h3 id="登录kibana"><a href="#登录kibana" class="headerlink" title="登录kibana"></a>登录kibana</h3><p>访问master:5601<br>结果如图所示:<br><img src="/images/201701/kibana_1.png"></p>
<h1 id="elk配合使用-elasticsearch-logstash-kibana"><a href="#elk配合使用-elasticsearch-logstash-kibana" class="headerlink" title="elk配合使用(elasticsearch, logstash, kibana)"></a>elk配合使用(elasticsearch, logstash, kibana)</h1><h3 id="创建es的index"><a href="#创建es的index" class="headerlink" title="创建es的index"></a>创建es的index</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#es_test 是index</span></div><div class="line">curl -XPUT <span class="string">'http://master:9200/es_test/'</span> <span class="_">-d</span> <span class="string">'&#123;</span></div><div class="line">  "settings":&#123;</div><div class="line">      "index":&#123;</div><div class="line">          "number_of_shards":3,</div><div class="line">          "number_of_replicas":1</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">&#125;'</div></pre></td></tr></table></figure>
<p>之前我们已经启动了elasticsearch, logstash, kibana<br>接下来我们启动一个新的logstash，数据存入elasticsearch(三台机器一样操作)</p>
<h3 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#master </span></div><div class="line">cat /opt/elasticsearch/logstash-5.1.1/test_data/1.log</div><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line"><span class="comment">#worker1</span></div><div class="line">cat /opt/elasticsearch/logstash-5.1.1/test_data/1.log</div><div class="line">1</div><div class="line">5</div><div class="line">6</div><div class="line"><span class="comment">#worker2</span></div><div class="line">cat /opt/elasticsearch/logstash-5.1.1/test_data/1.log</div><div class="line">1</div><div class="line">7</div><div class="line">8</div></pre></td></tr></table></figure>
<h3 id="编辑配置文件-3"><a href="#编辑配置文件-3" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h3><p>vim /opt/elasticsearch/logstash-5.1.1/config/es_test.conf<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">input &#123;</div><div class="line">    file &#123;</div><div class="line">        path =&gt; <span class="string">"/opt/elasticsearch/logstash-5.1.1/test_data/1.log"</span></div><div class="line">        start_position =&gt; beginning</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line">output&#123;</div><div class="line">    <span class="comment">#将logstash的输出和elasticsearch对接</span></div><div class="line">    elasticsearch &#123;</div><div class="line">        hosts =&gt; <span class="string">"master:9200"</span></div><div class="line">        <span class="comment">#index类似mysql的database，之后我们会在kibana用到</span></div><div class="line">        index =&gt; <span class="string">"es_test"</span></div><div class="line">    &#125;</div><div class="line">    stdout&#123;codec=&gt;rubydebug&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>启动logstash<br>cd /opt/elasticsearch/logstash-5.1.1 &amp;&amp; ./bin/logstash -f ./config/es_test.conf</p>
<h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><p>再次登录master:5601<br>输入es_test，如图所示<br><img src="/images/201701/kibana_2.png"></p>
<p>搜索1，在3台机器上输出源都有，搜索结果如下<br><img src="/images/201701/kibana_3.png"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="xiwu1212@163.com" />
          <p class="site-author-name" itemprop="name">xiwu1212@163.com</p>
          <p class="site-description motion-element" itemprop="description">学无止境</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiwu1212@163.com</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  




  
  

  

  

  

  


</body>
</html>
