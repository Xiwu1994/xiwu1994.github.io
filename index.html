<!doctype html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="Refrain">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Refrain">
<meta property="og:description" content="学无止境">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Refrain">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Refrain</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  















  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Refrain</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/21/hive问题记录/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/21/hive问题记录/" itemprop="url">hive问题记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-21T10:59:53+08:00">
                2017-07-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1、HIVE-13632-gt-Hive-failing-on-insert-empty-array-into-parquet-table"><a href="#1、HIVE-13632-gt-Hive-failing-on-insert-empty-array-into-parquet-table" class="headerlink" title="1、HIVE-13632 -&gt; Hive failing on insert empty array into parquet table"></a>1、HIVE-13632 -&gt; Hive failing on insert empty array into parquet table</h3><p>报错如下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">by: parquet.io.ParquetEncodingException: empty fields are illegal, the field should be ommited completely instead</div><div class="line">at parquet.io.MessageColumnIO$MessageColumnIORecordConsumer.endField(MessageColumnIO.java:<span class="number">271</span>)</div><div class="line">at org.apache.hadoop.hive.ql.io.parquet.write.DataWritableWriter$ListDataWriter.write(DataWritableWriter.java:<span class="number">271</span>)</div><div class="line">at org.apache.hadoop.hive.ql.io.parquet.write.DataWritableWriter$GroupDataWriter.write(DataWritableWriter.java:<span class="number">199</span>)</div><div class="line">at org.apache.hadoop.hive.ql.io.parquet.write.DataWritableWriter$MessageDataWriter.write(DataWritableWriter.java:<span class="number">215</span>)</div><div class="line">at org.apache.hadoop.hive.ql.io.parquet.write.DataWritableWriter.write(DataWritableWriter.java:<span class="number">88</span>)</div><div class="line">at org.apache.hadoop.hive.ql.io.parquet.write.DataWritableWriteSupport.write(DataWritableWriteSupport.java:<span class="number">59</span>)</div><div class="line">at org.apache.hadoop.hive.ql.io.parquet.write.DataWritableWriteSupport.write(DataWritableWriteSupport.java:<span class="number">31</span>)</div><div class="line">at parquet.hadoop.InternalParquetRecordWriter.write(InternalParquetRecordWriter.java:<span class="number">116</span>)</div><div class="line">at parquet.hadoop.ParquetRecordWriter.write(ParquetRecordWriter.java:<span class="number">123</span>)</div><div class="line">at parquet.hadoop.ParquetRecordWriter.write(ParquetRecordWriter.java:<span class="number">42</span>)</div><div class="line">at org.apache.hadoop.hive.ql.io.parquet.write.ParquetRecordWriterWrapper.write(ParquetRecordWriterWrapper.java:<span class="number">111</span>)</div><div class="line">at org.apache.hadoop.hive.ql.io.parquet.write.ParquetRecordWriterWrapper.write(ParquetRecordWriterWrapper.java:<span class="number">124</span>)</div><div class="line">at org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:<span class="number">697</span>)</div></pre></td></tr></table></figure></p>
<p>解决办法:<br>insert overwrite table test_table select <strong>if(size(array_column)=0, null, array_column)</strong> from src limit 1</p>
<p>参考: <a href="https://issues.apache.org/jira/browse/HIVE-13632" target="_blank" rel="external">https://issues.apache.org/jira/browse/HIVE-13632</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/06/01/Hue安装配置/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/01/Hue安装配置/" itemprop="url">Hue安装配置</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-01T20:42:47+08:00">
                2017-06-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="下载Hue"><a href="#下载Hue" class="headerlink" title="下载Hue"></a>下载Hue</h3><p><a href="http://gethue.com/category/release/" target="_blank" rel="external">http://gethue.com/category/release/</a></p>
<h3 id="解压Hue安装包"><a href="#解压Hue安装包" class="headerlink" title="解压Hue安装包"></a>解压Hue安装包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">tar -xzvf hue-3.11.0.tgz</div><div class="line"><span class="built_in">cd</span> hue-3.11.0</div><div class="line"><span class="comment">#下载依赖</span></div><div class="line">sudo yum install apache-maven ant asciidoc cyrus-sasl-devel cyrus-sasl-gssapi gcc gcc-c++ krb5-devel libxml2-devel libxslt-devel make mysql mysql-devel openldap-devel python-devel sqlite-devel gmp-devel</div><div class="line">make apps</div></pre></td></tr></table></figure>
<h3 id="修改Hue配置"><a href="#修改Hue配置" class="headerlink" title="修改Hue配置"></a>修改Hue配置</h3><p>vim ./hue-3.11.0/desktop/conf/hue.ini<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 1</span></div><div class="line">  time_zone=Asia/Shanghai</div><div class="line"><span class="comment"># 2</span></div><div class="line">  [[database]]</div><div class="line">    engine=mysql</div><div class="line">    host=xxx.xxx.xxx.xxx</div><div class="line">    port=3306</div><div class="line">    user=xxx</div><div class="line">    password=xxx</div><div class="line">    <span class="comment"># Execute this script to produce the database password. This will be used when 'password' is not set.</span></div><div class="line">    <span class="comment">## password_script=/path/script</span></div><div class="line">    name=db_hue</div><div class="line">    <span class="comment">## options=&#123;&#125;</span></div><div class="line"><span class="comment"># 3</span></div><div class="line">  [[hdfs_clusters]]</div><div class="line">    <span class="comment"># HA support by using HttpFs</span></div><div class="line"></div><div class="line">    [[[default]]]</div><div class="line">      <span class="comment"># Enter the filesystem uri</span></div><div class="line">      fs_defaultfs=hdfs://xxx:8020</div><div class="line">      hadoop_conf_dir=xxx</div><div class="line"><span class="comment">#4</span></div><div class="line">[beeswax]</div><div class="line">  hive_server_host=xxx.xxx.xxx.xxx</div><div class="line">  hive_server_port=10000</div><div class="line"><span class="comment">#5</span></div><div class="line">[librdbms]</div><div class="line">  [[databases]]</div><div class="line">     [[[mysql_1]]]</div><div class="line">       nice_name=<span class="string">"xxx"</span></div><div class="line">       name=xxx</div><div class="line">       host=xxx.xxx.xxx.xxx</div><div class="line">       port=3306</div><div class="line">       user=root</div><div class="line">       password=xxx</div><div class="line">       options=&#123;<span class="string">"charset"</span>:<span class="string">"utf8"</span>&#125;</div></pre></td></tr></table></figure></p>
<h3 id="mysql执行建数据库命令"><a href="#mysql执行建数据库命令" class="headerlink" title="mysql执行建数据库命令"></a>mysql执行建数据库命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mysql -hhost -uroot -pxxx</div><div class="line">&gt; create database db_hue;</div><div class="line">&gt; <span class="built_in">exit</span>;</div><div class="line">./build/env/bin/hue syncdb</div><div class="line">./build/env/bin/hue migrate</div></pre></td></tr></table></figure>
<h3 id="启动Hue"><a href="#启动Hue" class="headerlink" title="启动Hue"></a>启动Hue</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./build/env/bin/supervisor</div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/13/分组TopN问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/13/分组TopN问题/" itemprop="url">分组TopN问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-13T15:02:21+08:00">
                2017-03-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><p>列说明:<br>菜名 省份名 市场名 价格<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">v2 p2 m7 2.2</div><div class="line">v2 p2 m8 2.4</div><div class="line">v1 p1 m8 1</div><div class="line">v1 p1 m9 1.2</div><div class="line">v1 p2 m10 1.3</div><div class="line">v1 p2 m11 1.4</div><div class="line">v2 p1 m9 2</div><div class="line">v2 p1 m10 3</div><div class="line">v2 p1 m11 5</div><div class="line">v2 p2 m12 2.2</div><div class="line">v2 p2 m13 2.4</div></pre></td></tr></table></figure></p>
<h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>一、对于每种菜，求出比全国平均价更高的省份<br>(解释：每种菜都有全国平均价格，每种菜在不同省也有不同的平均价格，找到比全国平均价高的省份)<br>二、对于上面的省份，求出比全国平均价高的每种菜的Top3的市场</p>
<h3 id="Spark任务"><a href="#Spark任务" class="headerlink" title="Spark任务"></a>Spark任务</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">test_data_spark</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"test"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">    <span class="keyword">val</span> rdd = sc.textFile(<span class="string">"./src/test/test_data"</span>).cache()</div><div class="line">    <span class="keyword">val</span> v_p_avg_price = rdd.map(x =&gt; &#123;</div><div class="line">      <span class="keyword">val</span> line = x.split(<span class="string">" "</span>)</div><div class="line">      (line(<span class="number">0</span>)+<span class="string">"#"</span>+line(<span class="number">1</span>), (line(<span class="number">3</span>).toFloat, <span class="number">1</span>))</div><div class="line">    &#125;).reduceByKey((x, y) =&gt; (x._1+y._1, x._2+y._2)).mapValues(x =&gt; x._1/x._2).cache()</div><div class="line">    <span class="comment">/*</span></div><div class="line">    v_p_avg_price 是求出每种菜的每个省份的 平均价格</div><div class="line">    (v2#p2,2.3000002)</div><div class="line">    (v1#p1,1.5666666)</div><div class="line">    (v1#p2,1.3499999)</div><div class="line">    (v2#p1,3.3333333)</div><div class="line">    */</div><div class="line">    <span class="keyword">val</span> v_avg_price = v_p_avg_price.map(x =&gt;</div><div class="line">      (x._1.split(<span class="string">"#"</span>)(<span class="number">0</span>), (x._2, <span class="number">1</span>))).reduceByKey((x, y) =&gt; (x._1+y._1, x._2+y._2)).mapValues(x =&gt; x._1/x._2)</div><div class="line">    <span class="comment">/*</span></div><div class="line">    v_avg_price 是每种菜的全国平均价格</div><div class="line">    (v1,1.4583333)</div><div class="line">    (v2,2.8166666)</div><div class="line">    * */</div><div class="line">    <span class="keyword">val</span> nn_v_p_avg_price = v_p_avg_price.map(x =&gt; (x._1.split(<span class="string">"#"</span>)(<span class="number">0</span>), (x._1.split(<span class="string">"#"</span>)(<span class="number">1</span>), x._2)))</div><div class="line">    <span class="keyword">val</span> higer_p = nn_v_p_avg_price.join(v_avg_price).map(x =&gt; &#123;</div><div class="line">      <span class="keyword">if</span>(x._2._1._2 &gt; x._2._2)&#123;</div><div class="line">        (x._1, x._2._1._1)</div><div class="line">      &#125;<span class="keyword">else</span>&#123;</div><div class="line">        (<span class="string">"NULL"</span>, <span class="string">"NULL"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;).filter(x =&gt; ! x._1.contains(<span class="string">"NULL"</span>)).map(x =&gt; (x._1 + <span class="string">"#"</span> + x._2, <span class="number">0</span>))</div><div class="line">    <span class="comment">/*</span></div><div class="line">    higer_p 是对于每种菜，求出比全国平均价更高的省份</div><div class="line">    (v1#p1,0)</div><div class="line">    (v2#p1,0)</div><div class="line">    * */</div><div class="line">    <span class="keyword">val</span> wait_filter_data = rdd.map(x =&gt; &#123;</div><div class="line">      <span class="keyword">val</span> line = x.split(<span class="string">" "</span>)</div><div class="line">      (line(<span class="number">0</span>)+<span class="string">"#"</span>+line(<span class="number">1</span>), line(<span class="number">2</span>)+<span class="string">"#"</span>+line(<span class="number">3</span>))</div><div class="line">    &#125;)</div><div class="line">    higer_p.join(wait_filter_data).groupByKey().mapValues(x =&gt; &#123;</div><div class="line">      x.toList.map(x =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> line = x._2.split(<span class="string">"#"</span>)</div><div class="line">        (line(<span class="number">0</span>), line(<span class="number">1</span>))</div><div class="line">      &#125;).sortBy(x =&gt; -x._2.toDouble).take(<span class="number">3</span>) <span class="comment">// ===分组求TopN操作 先groupByKey-&gt;sortBy-&gt;take===</span></div><div class="line">    &#125;).foreach(println _)</div><div class="line">    <span class="comment">/*</span></div><div class="line">    最后结果</div><div class="line">    (v1#p1,List((m5,3), (m4,2), (m2,1.2)))   m5是最高的，接下来m4, m2</div><div class="line">    (v2#p1,List((m5,5), (m6,5), (m11,5)))</div><div class="line">    * */</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<img src="/images/201703/groupby_topN_1.png">
<h3 id="SparkSQL任务-（Hive窗口函数）"><a href="#SparkSQL任务-（Hive窗口函数）" class="headerlink" title="SparkSQL任务 （Hive窗口函数）"></a>SparkSQL任务 （Hive窗口函数）</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">test_data_SparkSql</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="type">Logger</span>.getLogger(<span class="string">"org"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"test"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">    <span class="keyword">val</span> <span class="type">Hivectx</span> = <span class="keyword">new</span> <span class="type">HiveContext</span>(sc)</div><div class="line">    <span class="type">Hivectx</span>.sql(<span class="string">"DROP TABLE IF EXISTS LOG"</span>)</div><div class="line">    <span class="type">Hivectx</span>.sql(<span class="string">"CREATE TABLE IF NOT EXISTS LOG (v STRING,p STRING,m STRING, price FLOAT) row format delimited fields terminated by ' '"</span>)</div><div class="line">    <span class="type">Hivectx</span>.sql(<span class="string">"LOAD DATA LOCAL INPATH './src/test/test_data' INTO TABLE LOG"</span>)</div><div class="line">    <span class="type">Hivectx</span>.sql(<span class="string">"DROP TABLE IF EXISTS higher_p"</span>)</div><div class="line">    <span class="comment">//以上是将输入源导入Hive表中</span></div><div class="line"></div><div class="line">    <span class="type">Hivectx</span>.sql(<span class="string">"create table IF NOT EXISTS higher_p as select b.v, b.p from( select v, avg(price) price from log "</span> +</div><div class="line">      <span class="string">"group by v)a join (select v, p, avg(price) price from log group by v, p)b on a.v = b.v where b.price &gt; a.price"</span>)</div><div class="line">    <span class="comment">//上一部是找到  对于每种菜，求出比全国平均价更高的省份</span></div><div class="line"></div><div class="line">    <span class="keyword">val</span> result = <span class="type">Hivectx</span>.sql(<span class="string">"select * from(select b.v as v, b.p as p, b.m as m, b.price as price, row_number() OVER(PARTITION by b.v, b.p order by b.price desc) as rank from higher_p a join log b on a.v = b.v and a.p = b.p )c where c.rank &lt;= 3"</span>)</div><div class="line">    <span class="comment">//上一部是找到  对于上面的省份，求出比全国平均价高的每种菜的Top3的市场</span></div><div class="line">    <span class="comment">// 用到row_number 窗口函数（PS. 因为用到窗口函数，需要把表放到Hive中，不能建立临时表操作）</span></div><div class="line">    result.foreach(println _)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<img src="/images/201703/groupby_topN_2.png">
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/10/SparkStreaming和Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/10/SparkStreaming和Kafka/" itemprop="url">SparkStreaming+Kafka Receiver到DirectApi</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-10T14:10:42+08:00">
                2017-03-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <img src="/images/201703/SparkStreaming_Kafka_1.png">
<h3 id="Receiver到DirectApi-优点"><a href="#Receiver到DirectApi-优点" class="headerlink" title="Receiver到DirectApi 优点"></a>Receiver到DirectApi 优点</h3><ul>
<li>没有WAL，减少了存储和增快了性能(从kafka直接获取数据，比从hdfs快)</li>
<li>自己维护Offset，实现了exactly-one</li>
</ul>
<h3 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h3><ul>
<li>offset不通过zk维护，不能在监控工具上查看offset</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/03/kylin/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/03/kylin/" itemprop="url">kylin</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-03T23:37:32+08:00">
                2017-03-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/01/SparkStreaming的window操作/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/01/SparkStreaming的window操作/" itemprop="url">SparkStreaming的window操作</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-01T21:38:12+08:00">
                2017-03-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="简单介绍window操作"><a href="#简单介绍window操作" class="headerlink" title="简单介绍window操作"></a>简单介绍window操作</h3><img src="/images/201703/SparkStreaming_window_1.png">
<p><strong>原始的Dstream</strong>：一个参数，表示多长时间划分一个RDD<br><strong>窗口操作</strong>：两个参数，表示</p>
<ul>
<li>window length（窗口长度）：窗口的持续时间（上图为3个时间单位）</li>
<li>sliding interval （滑动间隔）- 窗口操作的时间间隔（上图为2个时间单位）</li>
</ul>
<p><strong>对上图简单理解：每隔2个时间单位，对之前的3个时间单位操作</strong></p>
<h3 id="API说明"><a href="#API说明" class="headerlink" title="API说明"></a>API说明</h3><p>举例：<br>SparkStreaming的输入：每秒从[aa,bb,cc,dd,ee,ff,gg,hh]中随机选一个作为输入<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc,<span class="type">Seconds</span>(<span class="number">1</span>))</div><div class="line"><span class="keyword">val</span> socketStreaming = ssc.socketTextStream(<span class="string">"master"</span>,<span class="number">9999</span>)</div></pre></td></tr></table></figure></p>
<h4 id="window"><a href="#window" class="headerlink" title="window"></a>window</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> data = socketStreaming.window(<span class="type">Seconds</span>(<span class="number">3</span>), <span class="type">Seconds</span>(<span class="number">2</span>))</div><div class="line">data.print()</div></pre></td></tr></table></figure>
<p>结果如图：<br><img src="/images/201703/SparkStreaming_window_2.png"></p>
<h4 id="countByValueAndWindow"><a href="#countByValueAndWindow" class="headerlink" title="countByValueAndWindow"></a>countByValueAndWindow</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> data = socketStreaming.countByValueAndWindow(<span class="type">Seconds</span>(<span class="number">3</span>),<span class="type">Seconds</span>(<span class="number">2</span>))</div><div class="line">data.print()</div></pre></td></tr></table></figure>
<img src="/images/201703/SparkStreaming_window_3.png">
<h4 id="reduceByKeyAndWindow"><a href="#reduceByKeyAndWindow" class="headerlink" title="reduceByKeyAndWindow"></a>reduceByKeyAndWindow</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> data = socketStreaming.map(x=&gt;(x,<span class="number">1</span>)).</div><div class="line">    reduceByKeyAndWindow(</div><div class="line">    _+_, <span class="comment">// 加上新进入窗口的新批次中的元素 </span></div><div class="line">    _-_, <span class="comment">// 减去离开窗口的的老批次的元素</span></div><div class="line">    <span class="type">Seconds</span>(<span class="number">3</span>),<span class="type">Seconds</span>(<span class="number">2</span>))</div><div class="line">data.print()</div></pre></td></tr></table></figure>
<img src="/images/201703/SparkStreaming_window_4.png">
<ul>
<li>reduceByKeyAndWindow(func,windowLength, slideInterval, [numTasks])</li>
<li>reduceByKeyAndWindow(func, invFunc,windowLength, slideInterval, [numTasks])</li>
<li>使用逆函数invFunc可以提高效率</li>
<li><img src="/images/201703/SparkStreaming_reduceByKeyAndWindow_1.png"></li>
<li><img src="/images/201703/SparkStreaming_reduceByKeyAndWindow_2.png">
</li>
</ul>
<h4 id="reduceByWindow和countByWindow"><a href="#reduceByWindow和countByWindow" class="headerlink" title="reduceByWindow和countByWindow"></a>reduceByWindow和countByWindow</h4><p>暂时没看明白,mark</p>
<p>PS.在今天面试之前，面试官竟然看了我的博客，还是很开心的～</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/28/MapReduce调优简单总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/28/MapReduce调优简单总结/" itemprop="url">MapReduce调优简单总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-28T13:57:14+08:00">
                2017-02-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <img src="/images/201702/mr_optimize_1.png">
<table>
<thead>
<tr>
<th>选项</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>mapreduce.map.memory.mb</td>
<td>int</td>
<td>1024</td>
<td>map使用的内存</td>
</tr>
<tr>
<td>mapred.min.split.size</td>
<td>int</td>
<td>1</td>
<td>Input Split的最小值</td>
</tr>
<tr>
<td>mapred.map.tasks</td>
<td>int</td>
<td>1</td>
<td>Map Task的数量</td>
</tr>
<tr>
<td>io.sort.mb</td>
<td>int</td>
<td>100</td>
<td>map缓冲区大小</td>
</tr>
<tr>
<td>io.sort.factor</td>
<td>int</td>
<td>10</td>
<td>并行处理spill的个数</td>
</tr>
<tr>
<td>min.num.spill.for.combine</td>
<td>int</td>
<td>3</td>
<td>最少有3个Spill文件需要Merge时，执行combine操作</td>
</tr>
<tr>
<td>mapred.compress.map.output</td>
<td>boolean</td>
<td>false</td>
<td>map中间数据是否采用压缩</td>
</tr>
<tr>
<td>mapred.map.output.compression.codec</td>
<td>String</td>
<td>.</td>
<td>压缩算法</td>
</tr>
</tbody>
</table>
<img src="/images/201702/mr_optimize_2.png">
<table>
<thead>
<tr>
<th>选项</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>mapreduce.reduce.memory.mb</td>
<td>int</td>
<td>1024</td>
<td>reduce使用的内存</td>
</tr>
<tr>
<td>mapred.reduce.parallel.copies</td>
<td>int</td>
<td>5</td>
<td>每个reduce去map中拿数据的并行数</td>
</tr>
<tr>
<td>mapred.reduce.copy.backoff</td>
<td>int</td>
<td>300</td>
<td>获取map数据最大超时时间</td>
</tr>
<tr>
<td>mapred.job.shuffle.input.buffer.percent</td>
<td>float</td>
<td>0.7</td>
<td>buffer大小占reduce可用内存的比例</td>
</tr>
<tr>
<td>mapred.child.java.opts</td>
<td>String</td>
<td>.</td>
<td>-Xmx1024m设置reduce可用内存为1g</td>
</tr>
<tr>
<td>mapred.job.shuffle.merge.percent</td>
<td>float</td>
<td>0.66</td>
<td>buffer中的数据达到多少比例开始写入磁盘</td>
</tr>
<tr>
<td>mapred.job.reduce.input.buffer.percent</td>
<td>float</td>
<td>0.0</td>
<td>指定多少比例的内存用来存放buffer中的数据</td>
</tr>
</tbody>
</table>
<p>一个通用的原则是给shuffle过程分配尽可能大的内存。<br>运行map和reduce任务的JVM，内存通过mapred.child.java.opts属性来设置，尽可能设大内存。<br>容器的内存大小通过mapreduce.map.memory.mb和mapreduce.reduce.memory.mb来设置，默认都是1024M。<br>Hadoop默认使用4KB作为缓冲，这个算是很小的，可以通过io.file.buffer.size来调高缓冲池大小。</p>
<p>Map Task和Reduce Task调优的一个原则就是<br>减少数据的传输量 =&gt; 预聚合combine<br>尽量使用内存 =&gt; 提高内存使用(1、map环形缓冲区 2、reduce的Merge阶段)<br>减少磁盘IO的次数 =&gt; 增加Spill大小<br>增大任务并行数 =&gt; Reduce数量，Map数量</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/27/hive优化简单总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/27/hive优化简单总结/" itemprop="url">hive优化简单总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-27T22:31:08+08:00">
                2017-02-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="合理控制Map和Reduce数"><a href="#合理控制Map和Reduce数" class="headerlink" title="合理控制Map和Reduce数"></a>合理控制Map和Reduce数</h3><h4 id="map数"><a href="#map数" class="headerlink" title="map数"></a>map数</h4><ul>
<li>Map数过大<br>1、Map阶段输出文件太小，产生大量小文件，reduce阶段在拉取数据的时候产生很大开销。<br>2、初始化和创建map的开销很大。</li>
<li>Map数过小<br>1、文件处理或查询并发度小，Job执行空间过长。<br>2、大量作业时，容易堵塞集群。</li>
</ul>
<p><strong>Map数过大过小解决办法</strong><br>一、过大，<strong>通过合并小文件</strong><br>有三个阶段可以合并文件<br>Map输入，Reduce输出，Map-only任务结束时<br>1、Map输入</p>
<ul>
<li>set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</li>
<li>set mapred.max.split.size=100000000 表示合并后文件大小大于100M，可以合并下一个</li>
<li>set mapred.min.split.size.per.node=100000000 表示文件小于100M，需要被合并</li>
</ul>
<p>2、 Reduce输出:<br>set hive.merge.mapredfiles = true(默认false)<br>3、 Map-only任务结束时:<br>set hive.merge.mapfiles=true(默认true)</p>
<p>二、 过小，<strong>通过设置mapred.map.tasks</strong><br><a href="https://xiwu1994.github.io/2017/02/14/Hadoop%E8%AE%A1%E7%AE%97Map%E6%95%B0/" target="_blank" rel="external">Map数量是如何计算的参考文档</a></p>
<h4 id="Reduce数"><a href="#Reduce数" class="headerlink" title="Reduce数"></a>Reduce数</h4><ul>
<li>Reduce数过大<br>1、最终生成了很多个小文件，如果作为下一个Job输入，会出现上面说的Map数过多的问题。<br>2、启动和初始化reduce也会消耗大量的时间和资源</li>
<li>Reduce数过小<br>1、每个文件很大，执行耗时。<br>2、可能出现数据领斜。</li>
</ul>
<p><strong>默认计算方法</strong><br>Hive分配reduce数基于以下参数：<br>参数1：hive.exec.reducers.bytes.per.reducer(默认是1G)<br>参数2：hive.exec.reducers.max(最大reduce数，默认为999)<br>计算Reduce数的公式：<br>N=min(参数2，总输入数据量/参数1)<br>PS. 注意总输入数据量是Map的输入量，而不是Map的输出量。所以这点不是很好，因此要预估Map的输出量来手动设置mapred.reduce.tasks<br><strong>即默认一个reduce处理1G数据量</strong></p>
<p><strong>解决办法:通过设置Reduce数</strong><br>参数mapred.reduce.tasks 默认是1<br>set mapred.reduce.tasks=XX</p>
<h3 id="数据倾斜-Join-Or-GroupBy"><a href="#数据倾斜-Join-Or-GroupBy" class="headerlink" title="数据倾斜(Join Or GroupBy)"></a>数据倾斜(Join Or GroupBy)</h3><h4 id="参数调节"><a href="#参数调节" class="headerlink" title="参数调节"></a>参数调节</h4><ul>
<li><strong>增加Shuffle并行度(Reduce个数)</strong><br>set hive.exec.reducers.max=200;<br>set mapred.reduce.tasks= 200; –增大Reduce个数</li>
<li><strong>Group By</strong><br>set hive.groupby.mapaggr.checkinterval=100000; –这个是group的键对应的记录条数超过这个值则会进行分拆,值根据具体数据量设置<br>set hive.groupby.skewindata=true; –如果是 <strong>Group By</strong> 过程出现倾斜 应该设置为true</li>
<li><strong>Join</strong><br>set hive.skewjoin.key=100000; –这个是join的键对应的记录条数超过这个值则会进行分拆,值根据具体数据量设置<br>set hive.optimize.skewjoin=true; –如果是 <strong>Join</strong> 过程出现倾斜 应该设置为true</li>
</ul>
<h4 id="SQL语句调节"><a href="#SQL语句调节" class="headerlink" title="SQL语句调节"></a>SQL语句调节</h4><ul>
<li>Join操作<br>1、<strong>若其中有一个表很小使用map join /*+ MAPJOIN(table) */</strong>，否则使用普通的reduce join<br>2、<strong>使用普通reduce join时 将条目少的表/子查询放在 Join 操作符的 左边</strong>（位于 Join 操作符左边的表的内容会被加载进内存）</li>
</ul>
<p>PS. 熟练运用 <strong>union all和 创建临时表insert overwrite table</strong> 优化SQL语句</p>
<h4 id="常见数据倾斜场景"><a href="#常见数据倾斜场景" class="headerlink" title="常见数据倾斜场景"></a>常见数据倾斜场景</h4><ul>
<li><p>空值产生的数据倾斜<br>解决办法：赋予空值一个随机值</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> * <span class="keyword">from</span> A a</div><div class="line"><span class="keyword">left</span> <span class="keyword">join</span> B b</div><div class="line"><span class="keyword">on</span> <span class="keyword">case</span> <span class="keyword">when</span> a.id <span class="keyword">is</span> <span class="literal">null</span> <span class="keyword">then</span> <span class="keyword">concat</span>(<span class="string">'hive'</span>, <span class="keyword">rand</span>()) <span class="keyword">else</span> a.id <span class="keyword">end</span> = b.id</div></pre></td></tr></table></figure>
</li>
<li><p>不同数据类型关联产生数据倾斜<br>解决方法：把数字类型转换成字符串类型</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> * <span class="keyword">from</span> A a</div><div class="line"><span class="keyword">left</span> <span class="keyword">join</span> B b</div><div class="line"><span class="keyword">on</span> a.id = <span class="keyword">cast</span>(b.id <span class="keyword">as</span> <span class="keyword">string</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>小表不小不大，用map join不好解决<br>抽出业务中的小数据源，作为map join中的小表。 进行多次的map join<br>例如业务：A表有大表，但是id的去重后的量少。 B表是小表，但是也比较大</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> <span class="comment">/*+mapjoin(c)*/</span> c.*</div><div class="line"><span class="keyword">from</span></div><div class="line">(</div><div class="line">  <span class="keyword">select</span> <span class="comment">/*+mapjoin(a)*/</span> b.* </div><div class="line">  <span class="keyword">from</span> (<span class="keyword">select</span> <span class="keyword">distinct</span> <span class="keyword">id</span> <span class="keyword">from</span> A) a</div><div class="line">  <span class="keyword">join</span> B b</div><div class="line">  <span class="keyword">on</span> a.id = b.id</div><div class="line">)c</div><div class="line"><span class="keyword">join</span> A d</div><div class="line"><span class="keyword">on</span> c.id = d.id</div></pre></td></tr></table></figure>
</li>
</ul>
<p>参考文档：<br><a href="http://www.cnblogs.com/smartloli/p/4356660.html" target="_blank" rel="external">http://www.cnblogs.com/smartloli/p/4356660.html</a><br><a href="http://www.cnblogs.com/xd502djj/p/3799432.html" target="_blank" rel="external">http://www.cnblogs.com/xd502djj/p/3799432.html</a><br><a href="http://blog.csdn.net/scgaliguodong123_/article/details/45477323" target="_blank" rel="external">http://blog.csdn.net/scgaliguodong123_/article/details/45477323</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/21/Hadoop2的Hdfs框架/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/21/Hadoop2的Hdfs框架/" itemprop="url">Hadoop2.x的Hdfs框架</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-21T17:09:38+08:00">
                2017-02-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="早期Hdfs改进的原因"><a href="#早期Hdfs改进的原因" class="headerlink" title="早期Hdfs改进的原因"></a>早期Hdfs改进的原因</h3><p>早期的hadoop版本，NameNode是HDFS集群的单点故障点，每一个集群只有一个NameNode,如果这个机器或进程不可用，整个集群就无法使用。</p>
<h3 id="SPOF方案回顾-single-point-of-failure单点故障"><a href="#SPOF方案回顾-single-point-of-failure单点故障" class="headerlink" title="SPOF方案回顾(single point of failure单点故障)"></a>SPOF方案回顾(single point of failure单点故障)</h3><ol>
<li>Secondary NameNode：<strong>它不是HA</strong>，它只是阶段性的合并edits和fsimage，以缩短集群启动的时间。当NN失效的时候，Secondary NN并无法立刻提供服务，Secondary NN甚至无法保证数据完整性：如果NN数据丢失的话，在上一次合并后的文件系统的改动会丢失</li>
<li>Backup NameNode：它在内存中复制了NN的当前状态，算是Warm Standby，可也就仅限于此，并没有 <strong>failover(故障自动处理)</strong> 等。它同样是阶段性的做checkpoint，也无法保证数据完整性</li>
<li>手动把<strong>name.dir指向NFS</strong>（Network File System），这是安全的Cold Standby，可以保证元数据不丢失，但集群的恢复则完全靠手动</li>
<li>Facebook AvatarNode：Facebook有强大的运维做后盾，所以Avatarnode只是Hot Standby，并没有自动切换，当主NN失效的时候，需要管理员确认，然后手动把对外提供服务的虚拟IP映射到Standby NN，这样做的好处是确保不会发生脑裂的场景。</li>
</ol>
<ul>
<li>Facebook AvatarNode 原理示例图</li>
<li><img src="/images/201702/hdfs2_1.png"></li>
<li>PrimaryNN与StandbyNN之间通过NFS来共享FsEdits、FsImage文件，这样主备NN之间就拥有了一致的目录树和block信息；而block的位置信息，可以根据DN向两个NN上报的信息过程中构建起来。这样再辅以虚IP，可以较好达到主备NN快速热切的目的。但是显然，这里的<em>NFS又引入了新的SPOF</em></li>
</ul>
<h3 id="HDFS-NameNode-高可用整体架构"><a href="#HDFS-NameNode-高可用整体架构" class="headerlink" title="HDFS NameNode 高可用整体架构"></a>HDFS NameNode 高可用整体架构</h3><img src="/images/201702/hdfs2_2.png">
<p>NameNode 的高可用架构主要分为下面几个部分：</p>
<ul>
<li>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。</li>
<li>主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。</li>
<li>Zookeeper 集群：为主备切换控制器提供主备选举支持。</li>
<li>共享存储系统：<strong>共享存储系统是实现NameNode的高可用最为关键的部分</strong>，共享存储系统保存了NameNode在运行过程中所产生的 HDFS 的元数据。主NameNode和备NameNode通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。</li>
<li>DataNode 节点：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。DataNode 会<strong>同时</strong>向主 NameNode 和备 NameNode 上报数据块的位置信息。</li>
</ul>
<h4 id="共享存储系统简单分析原理"><a href="#共享存储系统简单分析原理" class="headerlink" title="共享存储系统简单分析原理"></a>共享存储系统简单分析原理</h4><p>QJM/Qurom Journal Manager，这是一个基于Paxos算法实现的HDFS HA方案<br><img src="/images/201702/hdfs2_3.png"></p>
<ul>
<li>基本原理就是用2N+1台 JournalNode 存储EditLog，每次写数据操作有大多数（&gt;=N+1）返回成功时即认为该次写成功，数据不会丢失了。当然这个算法所能容忍的是最多有N台机器挂掉，如果多于N台挂掉，这个算法就失效了。</li>
<li>在HA架构里面SecondaryNameNode这个冷备角色已经不存在了，为了保持standby NN时时的与主Active NN的元数据保持一致，他们之间交互通过一系列守护的轻量级进程JournalNode</li>
<li>任何修改操作在 Active NN上执行时，JN进程同时也会记录修改log到至少半数以上的JN中，这时 Standby NN 监测到JN 里面的同步log发生变化了会读取 JN 里面的修改log，然后同步到自己的的目录镜像树里面，如下图：</li>
<li><img src="/images/201702/hdfs2_4.png"></li>
<li>当发生故障时，Active的 NN 挂掉后，Standby NN 会在它成为Active NN 前，读取所有的JN里面的修改日志，这样就能高可靠的保证与挂掉的NN的目录镜像树一致，然后无缝的接替它的职责，维护来自客户端请求，从而达到一个高可用的目的</li>
<li>QJM方式来实现HA的主要优势：</li>
</ul>
<ol>
<li>不需要配置额外的高共享存储，降低了复杂度和维护成本</li>
<li>消除spof</li>
<li>系统健壮性的程度是可配置</li>
<li>JN不会因为其中一台的延迟而影响整体的延迟，而且也不会因为JN的数量增多而影响性能（因为NN向JN发送日志是并行的）</li>
</ol>
<h4 id="NameNode的主备切换实现"><a href="#NameNode的主备切换实现" class="headerlink" title="NameNode的主备切换实现"></a>NameNode的主备切换实现</h4><p>NameNode 主备切换主要由 ZKFailoverController、HealthMonitor 和 ActiveStandbyElector 这 3 个组件来协同实现</p>
<ul>
<li>ZKFailoverController 启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。</li>
<li>HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调 ZKFailoverController 的相应方法进行自动的主备选举。</li>
<li>ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</li>
</ul>
<p>NameNode 实现主备切换的流程如下图所示:<br><img src="/images/201702/hdfs2_5.png"></p>
<ol>
<li>HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。</li>
<li>HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会回调 ZKFailoverController 注册的相应方法进行处理。</li>
<li>如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。</li>
<li>ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。</li>
<li>ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。</li>
<li>ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。</li>
</ol>
<p>参考文档:<br><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/" target="_blank" rel="external">https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/</a><br><a href="http://www.cnblogs.com/tgzhu/p/5790565.html" target="_blank" rel="external">http://www.cnblogs.com/tgzhu/p/5790565.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/20/Hadoop1的Hdfs框架/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xiwu1212@163.com">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Refrain">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/02/20/Hadoop1的Hdfs框架/" itemprop="url">Hadoop1.x的Hdfs框架</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-20T22:10:18+08:00">
                2017-02-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>hdfs是一个分布式文件系统。它以文件分块的形式实现对大文件安全的、可靠的以及可快速（高吞吐量）访问的分布式存储。</p>
<h2 id="HDFS架构图"><a href="#HDFS架构图" class="headerlink" title="HDFS架构图"></a>HDFS架构图</h2><img src="/images/201702/hdfs1_1.png">
<h2 id="HDFS一些概念"><a href="#HDFS一些概念" class="headerlink" title="HDFS一些概念"></a>HDFS一些概念</h2><ul>
<li>Block数据块</li>
<li>NameNode</li>
<li>DataNode</li>
<li>Secondary NameNode</li>
</ul>
<h3 id="Block数据块"><a href="#Block数据块" class="headerlink" title="Block数据块"></a>Block数据块</h3><p>HDFS中的所有文件都是<strong>分割成块</strong>存储在Datanode上的，每个块默认64M。每个块都有多个副本存储在不同的机器上：默认有3个副本，3个副本不可能存放在同一个机器上。<br>HDFS副本存放策略:<br><img src="/images/201702/hdfs1_2.png"></p>
<h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><p>NameNode是Hdfs中的master节点<br>主要功能:</p>
<ul>
<li>管理整个文件系统的<strong>命名空间</strong>和控制着客户端对文件的访问。(它不保存文件的内容，而是保存着文件的元数据: <strong>文件名称，所在目录，文件权限，文件拥有者，文件有多少块，每个块有多少副本，块都存在哪些节点上</strong>)</li>
<li>NameNode也负责维护所有这些<strong>文件或目录的打开、关闭、移动、重命名</strong>等操作。(对于实际文件数据的保存与操作，都是由DataNode负责。当一个客户端请求数据时，它仅仅是从NameNode中获取文件的元信息，而具体的数据传输不需要经过NameNode，是由客户端直接与相应的DataNode进行交互)</li>
</ul>
<p>PS. NameNode元信息<em>并不包含每个块的位置信息</em>，这些信息会在NameNode启动时从各个DataNode获取并保存在内存中</p>
<h4 id="fsimage"><a href="#fsimage" class="headerlink" title="fsimage"></a>fsimage</h4><p>fsimage是元数据镜像文件: NameNode启动后，fsimage被加载到内存中</p>
<h4 id="editslog"><a href="#editslog" class="headerlink" title="editslog"></a>editslog</h4><p>editslog是元数据操作日志文件: 客户端要对文件进行读写操作，在这些操作产生的日志就存在了editslog文件中</p>
<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><p>DataNode是Hdfs中的worker节点<br>主要功能:</p>
<ul>
<li>存储数据块</li>
<li>为客户端提供数据块的读写服务</li>
<li>根据NameNode的指示来进行创建、删除、和复制等操作</li>
<li>通过心跳定期向NameNode发送所存储文件块列表信息</li>
</ul>
<h3 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h3><p>NameNode作为Hdfs中的master，不能负载太高，所以需要一个助手来分担压力<br>主要功能:</p>
<ul>
<li>镜像备份（当NameNode出现故障后，通过备份的镜像能挽回一些损失）</li>
<li>日志editslog与镜像fsimage的定期合并(分担NameNode工作)</li>
</ul>
<h4 id="日志editslog与镜像fsimage的定期合并过程"><a href="#日志editslog与镜像fsimage的定期合并过程" class="headerlink" title="日志editslog与镜像fsimage的定期合并过程"></a>日志editslog与镜像fsimage的定期合并过程</h4><p>1、合并之前告知NameNode把所有的操作写到新的edites文件并将其命名为edits.new。<br>2、SecondaryNameNode从NameNode请求fsimage和edits文件<br>3、SecondaryNameNode把fsimage和edits文件合并成新的fsimage文件<br>4、NameNode从SecondaryNameNode获取合并好的新的fsimage并将旧的替换掉，并把edits用第一步创建的edits.new文件替换掉<br>5、更新fstime文件中的检查点</p>
<p>再总结一下整个过程中涉及到NameNode中的相关文件</p>
<ul>
<li>fsimage ：保存的是上个检查点的HDFS的元信息</li>
<li>edits ：保存的是从上个检查点开始发生的HDFS元信息状态改变信息</li>
<li>fstime：保存了最后一个检查点的时间戳</li>
</ul>
<h2 id="HDFS读写操作"><a href="#HDFS读写操作" class="headerlink" title="HDFS读写操作"></a>HDFS读写操作</h2><h3 id="读"><a href="#读" class="headerlink" title="读"></a>读</h3><ol>
<li>客户端发起读请求</li>
<li>客户端与NameNode得到文件的块及位置信息列表</li>
<li>客户端直接和DataNode交互读取数据</li>
<li>读取完成关闭连接</li>
</ol>
<img src="/images/201702/hdfs1_3.png">
<p>在上图中3步骤中，客户端通过网络拓扑，选择最优的DataNode去读取数据<br>网络拓扑简单理解(按照优先级排序):</p>
<ol>
<li>同一节点中的进程</li>
<li>同一机架上的不同节点</li>
<li>同一数据中心不同机架</li>
<li>不同数据中心的节点</li>
</ol>
<h3 id="写"><a href="#写" class="headerlink" title="写"></a>写</h3><ol>
<li>客户端在向NameNode请求之前先写入文件数据到本地文件系统的一个 <strong>临时文件</strong> </li>
<li>待临时文件 <strong>达到块大小</strong> 时开始向NameNode请求DataNode信息</li>
<li>NameNode在文件系统中创建文件并返回给客户端一个数据块及其对应DataNode的地址列表（列表中包含副本存放的地址）</li>
<li>客户端通过上一步得到的信息把创建临时文件块flush到列表中的第一个DataNode</li>
<li>当文件关闭，NameNode会提交这次文件创建，此时，文件在文件系统中可见</li>
</ol>
<p>上面第四步描述的flush过程实际处理过程比较负杂，现在单独描述一下:</p>
<ol>
<li>首先，第一个DataNode是以数据包(数据包一般4KB)的形式从客户端接收数据的，DataNode在把数据包写入到本地磁盘的 <strong>同时</strong> 会向第二个DataNode（作为副本节点）传送数据。</li>
<li>在第二个DataNode把接收到的数据包写入本地磁盘时会向第三个DataNode发送数据包</li>
<li>第三个DataNode开始向本地磁盘写入数据包。此时，数据包以流水线的形式被写入和备份到所有DataNode节点</li>
<li>传送管道中的每个DataNode节点在收到数据后都会向前面那个DataNode发送一个ACK,最终，第一个DataNode会向客户端发回一个ACK</li>
<li>当客户端收到数据块的确认之后，数据块被认为已经持久化到所有节点。然后，客户端会向NameNode发送一个确认</li>
<li>如果管道中的任何一个DataNode失败，管道会被关闭。数据将会继续写到剩余的DataNode中。同时NameNode会被告知待备份状态，NameNode会继续备份数据到新的可用的节点</li>
<li>数据块都会通过计算校验和来检测数据的完整性，校验和以隐藏文件的形式被单独存放在hdfs中，供读取时进行完整性校验</li>
</ol>
<img src="/images/201702/hdfs1_4.png">
<h2 id="HDFS的优缺点"><a href="#HDFS的优缺点" class="headerlink" title="HDFS的优缺点"></a>HDFS的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>高容错性<br>数据自动保存多个副本<br>副本丢失后，自动恢复</li>
<li>适合批处理<br>移动计算而非数据<br>数据位置暴露给计算框架</li>
<li>适合大数据处理<br>GB、TB、甚至PB级数据<br>百万规模以上的文件数量<br>10K+节点规模</li>
<li>流式文件访问<br>一次性写入，多次读取<br>保证数据一致性</li>
<li>可构建在廉价机器上<br>通过多副本提高可靠性<br>提供了容错和恢复机制<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3></li>
<li>低延迟与高吞吐率的数据访问</li>
<li>小文件存取<br>占用NameNode大量内存<br>寻道时间超过读取时间</li>
<li>并发写入、文件随机修改<br>一个文件同一个时间只能有一个写者 </li>
</ul>
<img src="/images/201702/hdfs1_5.png">
<p>参考文档:<br><a href="http://blog.csdn.net/suifeng3051/article/details/48548341" target="_blank" rel="external">http://blog.csdn.net/suifeng3051/article/details/48548341</a><br><a href="http://www.cnblogs.com/meet/p/5439805.html" target="_blank" rel="external">http://www.cnblogs.com/meet/p/5439805.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="xiwu1212@163.com" />
          <p class="site-author-name" itemprop="name">xiwu1212@163.com</p>
           
              <p class="site-description motion-element" itemprop="description">学无止境</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">tags</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiwu1212@163.com</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  

  

  

  

  

</body>
</html>
