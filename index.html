<!doctype html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="学无止境">
<meta property="og:type" content="website">
<meta property="og:title" content="Refrain">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Refrain">
<meta property="og:description" content="学无止境">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Refrain">
<meta name="twitter:description" content="学无止境">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title> Refrain </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Refrain</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/21/Hadoop2的Hdfs框架/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/21/Hadoop2的Hdfs框架/" itemprop="url">
                  Hadoop2.x的Hdfs框架
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-21T17:09:38+08:00">
                2017-02-21
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="早期Hdfs改进的原因"><a href="#早期Hdfs改进的原因" class="headerlink" title="早期Hdfs改进的原因"></a>早期Hdfs改进的原因</h3><p>早期的hadoop版本，NameNode是HDFS集群的单点故障点，每一个集群只有一个NameNode,如果这个机器或进程不可用，整个集群就无法使用。</p>
<h3 id="SPOF方案回顾-single-point-of-failure单点故障"><a href="#SPOF方案回顾-single-point-of-failure单点故障" class="headerlink" title="SPOF方案回顾(single point of failure单点故障)"></a>SPOF方案回顾(single point of failure单点故障)</h3><ol>
<li>Secondary NameNode：<strong>它不是HA</strong>，它只是阶段性的合并edits和fsimage，以缩短集群启动的时间。当NN失效的时候，Secondary NN并无法立刻提供服务，Secondary NN甚至无法保证数据完整性：如果NN数据丢失的话，在上一次合并后的文件系统的改动会丢失</li>
<li>Backup NameNode：它在内存中复制了NN的当前状态，算是Warm Standby，可也就仅限于此，并没有 <strong>failover(故障自动处理)</strong> 等。它同样是阶段性的做checkpoint，也无法保证数据完整性</li>
<li>手动把<strong>name.dir指向NFS</strong>（Network File System），这是安全的Cold Standby，可以保证元数据不丢失，但集群的恢复则完全靠手动</li>
<li>Facebook AvatarNode：Facebook有强大的运维做后盾，所以Avatarnode只是Hot Standby，并没有自动切换，当主NN失效的时候，需要管理员确认，然后手动把对外提供服务的虚拟IP映射到Standby NN，这样做的好处是确保不会发生脑裂的场景。</li>
</ol>
<ul>
<li>Facebook AvatarNode 原理示例图</li>
<li><img src="/images/201702/hdfs2_1.png"></li>
<li>PrimaryNN与StandbyNN之间通过NFS来共享FsEdits、FsImage文件，这样主备NN之间就拥有了一致的目录树和block信息；而block的位置信息，可以根据DN向两个NN上报的信息过程中构建起来。这样再辅以虚IP，可以较好达到主备NN快速热切的目的。但是显然，这里的<em>NFS又引入了新的SPOF</em></li>
</ul>
<h3 id="HDFS-NameNode-高可用整体架构"><a href="#HDFS-NameNode-高可用整体架构" class="headerlink" title="HDFS NameNode 高可用整体架构"></a>HDFS NameNode 高可用整体架构</h3><img src="/images/201702/hdfs2_2.png">
<p>NameNode 的高可用架构主要分为下面几个部分：</p>
<ul>
<li>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。</li>
<li>主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。</li>
<li>Zookeeper 集群：为主备切换控制器提供主备选举支持。</li>
<li>共享存储系统：<strong>共享存储系统是实现NameNode的高可用最为关键的部分</strong>，共享存储系统保存了NameNode在运行过程中所产生的 HDFS 的元数据。主NameNode和备NameNode通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。</li>
<li>DataNode 节点：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。DataNode 会<strong>同时</strong>向主 NameNode 和备 NameNode 上报数据块的位置信息。</li>
</ul>
<h4 id="共享存储系统简单分析原理"><a href="#共享存储系统简单分析原理" class="headerlink" title="共享存储系统简单分析原理"></a>共享存储系统简单分析原理</h4><p>QJM/Qurom Journal Manager，这是一个基于Paxos算法实现的HDFS HA方案<br><img src="/images/201702/hdfs2_3.png"></p>
<ul>
<li>基本原理就是用2N+1台 JournalNode 存储EditLog，每次写数据操作有大多数（&gt;=N+1）返回成功时即认为该次写成功，数据不会丢失了。当然这个算法所能容忍的是最多有N台机器挂掉，如果多于N台挂掉，这个算法就失效了。</li>
<li>在HA架构里面SecondaryNameNode这个冷备角色已经不存在了，为了保持standby NN时时的与主Active NN的元数据保持一致，他们之间交互通过一系列守护的轻量级进程JournalNode</li>
<li>任何修改操作在 Active NN上执行时，JN进程同时也会记录修改log到至少半数以上的JN中，这时 Standby NN 监测到JN 里面的同步log发生变化了会读取 JN 里面的修改log，然后同步到自己的的目录镜像树里面，如下图：</li>
<li><img src="/images/201702/hdfs2_4.png"></li>
<li>当发生故障时，Active的 NN 挂掉后，Standby NN 会在它成为Active NN 前，读取所有的JN里面的修改日志，这样就能高可靠的保证与挂掉的NN的目录镜像树一致，然后无缝的接替它的职责，维护来自客户端请求，从而达到一个高可用的目的</li>
<li>QJM方式来实现HA的主要优势：</li>
</ul>
<ol>
<li>不需要配置额外的高共享存储，降低了复杂度和维护成本</li>
<li>消除spof</li>
<li>系统健壮性的程度是可配置</li>
<li>JN不会因为其中一台的延迟而影响整体的延迟，而且也不会因为JN的数量增多而影响性能（因为NN向JN发送日志是并行的）</li>
</ol>
<h4 id="NameNode的主备切换实现"><a href="#NameNode的主备切换实现" class="headerlink" title="NameNode的主备切换实现"></a>NameNode的主备切换实现</h4><p>NameNode 主备切换主要由 ZKFailoverController、HealthMonitor 和 ActiveStandbyElector 这 3 个组件来协同实现</p>
<ul>
<li>ZKFailoverController 启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。</li>
<li>HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调 ZKFailoverController 的相应方法进行自动的主备选举。</li>
<li>ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</li>
</ul>
<p>NameNode 实现主备切换的流程如下图所示:<br><img src="/images/201702/hdfs2_5.png"></p>
<ol>
<li>HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。</li>
<li>HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会回调 ZKFailoverController 注册的相应方法进行处理。</li>
<li>如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。</li>
<li>ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。</li>
<li>ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。</li>
<li>ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。</li>
</ol>
<p>参考文档:<br><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/" target="_blank" rel="external">https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/</a><br><a href="http://www.cnblogs.com/tgzhu/p/5790565.html" target="_blank" rel="external">http://www.cnblogs.com/tgzhu/p/5790565.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/20/Hadoop1的Hdfs框架/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/20/Hadoop1的Hdfs框架/" itemprop="url">
                  Hadoop1.x的Hdfs框架
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-20T22:10:18+08:00">
                2017-02-20
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>hdfs是一个分布式文件系统。它以文件分块的形式实现对大文件安全的、可靠的以及可快速（高吞吐量）访问的分布式存储。</p>
<h2 id="HDFS架构图"><a href="#HDFS架构图" class="headerlink" title="HDFS架构图"></a>HDFS架构图</h2><img src="/images/201702/hdfs1_1.png">
<h2 id="HDFS一些概念"><a href="#HDFS一些概念" class="headerlink" title="HDFS一些概念"></a>HDFS一些概念</h2><ul>
<li>Block数据块</li>
<li>NameNode</li>
<li>DataNode</li>
<li>Secondary NameNode</li>
</ul>
<h3 id="Block数据块"><a href="#Block数据块" class="headerlink" title="Block数据块"></a>Block数据块</h3><p>HDFS中的所有文件都是<strong>分割成块</strong>存储在Datanode上的，每个块默认64M。每个块都有多个副本存储在不同的机器上：默认有3个副本，3个副本不可能存放在同一个机器上。<br>HDFS副本存放策略:<br><img src="/images/201702/hdfs1_2.png"></p>
<h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><p>NameNode是Hdfs中的master节点<br>主要功能:</p>
<ul>
<li>管理整个文件系统的<strong>命名空间</strong>和控制着客户端对文件的访问。(它不保存文件的内容，而是保存着文件的元数据: <strong>文件名称，所在目录，文件权限，文件拥有者，文件有多少块，每个块有多少副本，块都存在哪些节点上</strong>)</li>
<li>NameNode也负责维护所有这些<strong>文件或目录的打开、关闭、移动、重命名</strong>等操作。(对于实际文件数据的保存与操作，都是由DataNode负责。当一个客户端请求数据时，它仅仅是从NameNode中获取文件的元信息，而具体的数据传输不需要经过NameNode，是由客户端直接与相应的DataNode进行交互)</li>
</ul>
<p>PS. NameNode元信息<em>并不包含每个块的位置信息</em>，这些信息会在NameNode启动时从各个DataNode获取并保存在内存中</p>
<h4 id="fsimage"><a href="#fsimage" class="headerlink" title="fsimage"></a>fsimage</h4><p>fsimage是元数据镜像文件: NameNode启动后，fsimage被加载到内存中</p>
<h4 id="editslog"><a href="#editslog" class="headerlink" title="editslog"></a>editslog</h4><p>editslog是元数据操作日志文件: 客户端要对文件进行读写操作，在这些操作产生的日志就存在了editslog文件中</p>
<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><p>DataNode是Hdfs中的worker节点<br>主要功能:</p>
<ul>
<li>存储数据块</li>
<li>为客户端提供数据块的读写服务</li>
<li>根据NameNode的指示来进行创建、删除、和复制等操作</li>
<li>通过心跳定期向NameNode发送所存储文件块列表信息</li>
</ul>
<h3 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h3><p>NameNode作为Hdfs中的master，不能负载太高，所以需要一个助手来分担压力<br>主要功能:</p>
<ul>
<li>镜像备份（当NameNode出现故障后，通过备份的镜像能挽回一些损失）</li>
<li>日志editslog与镜像fsimage的定期合并(分担NameNode工作)</li>
</ul>
<h4 id="日志editslog与镜像fsimage的定期合并过程"><a href="#日志editslog与镜像fsimage的定期合并过程" class="headerlink" title="日志editslog与镜像fsimage的定期合并过程"></a>日志editslog与镜像fsimage的定期合并过程</h4><p>1、合并之前告知NameNode把所有的操作写到新的edites文件并将其命名为edits.new。<br>2、SecondaryNameNode从NameNode请求fsimage和edits文件<br>3、SecondaryNameNode把fsimage和edits文件合并成新的fsimage文件<br>4、NameNode从SecondaryNameNode获取合并好的新的fsimage并将旧的替换掉，并把edits用第一步创建的edits.new文件替换掉<br>5、更新fstime文件中的检查点</p>
<p>再总结一下整个过程中涉及到NameNode中的相关文件</p>
<ul>
<li>fsimage ：保存的是上个检查点的HDFS的元信息</li>
<li>edits ：保存的是从上个检查点开始发生的HDFS元信息状态改变信息</li>
<li>fstime：保存了最后一个检查点的时间戳</li>
</ul>
<h2 id="HDFS读写操作"><a href="#HDFS读写操作" class="headerlink" title="HDFS读写操作"></a>HDFS读写操作</h2><h3 id="读"><a href="#读" class="headerlink" title="读"></a>读</h3><ol>
<li>客户端发起读请求</li>
<li>客户端与NameNode得到文件的块及位置信息列表</li>
<li>客户端直接和DataNode交互读取数据</li>
<li>读取完成关闭连接</li>
</ol>
<img src="/images/201702/hdfs1_3.png">
<p>在上图中3步骤中，客户端通过网络拓扑，选择最优的DataNode去读取数据<br>网络拓扑简单理解(按照优先级排序):</p>
<ol>
<li>同一节点中的进程</li>
<li>同一机架上的不同节点</li>
<li>同一数据中心不同机架</li>
<li>不同数据中心的节点</li>
</ol>
<h3 id="写"><a href="#写" class="headerlink" title="写"></a>写</h3><ol>
<li>客户端在向NameNode请求之前先写入文件数据到本地文件系统的一个 <strong>临时文件</strong> </li>
<li>待临时文件 <strong>达到块大小</strong> 时开始向NameNode请求DataNode信息</li>
<li>NameNode在文件系统中创建文件并返回给客户端一个数据块及其对应DataNode的地址列表（列表中包含副本存放的地址）</li>
<li>客户端通过上一步得到的信息把创建临时文件块flush到列表中的第一个DataNode</li>
<li>当文件关闭，NameNode会提交这次文件创建，此时，文件在文件系统中可见</li>
</ol>
<p>上面第四步描述的flush过程实际处理过程比较负杂，现在单独描述一下:</p>
<ol>
<li>首先，第一个DataNode是以数据包(数据包一般4KB)的形式从客户端接收数据的，DataNode在把数据包写入到本地磁盘的 <strong>同时</strong> 会向第二个DataNode（作为副本节点）传送数据。</li>
<li>在第二个DataNode把接收到的数据包写入本地磁盘时会向第三个DataNode发送数据包</li>
<li>第三个DataNode开始向本地磁盘写入数据包。此时，数据包以流水线的形式被写入和备份到所有DataNode节点</li>
<li>传送管道中的每个DataNode节点在收到数据后都会向前面那个DataNode发送一个ACK,最终，第一个DataNode会向客户端发回一个ACK</li>
<li>当客户端收到数据块的确认之后，数据块被认为已经持久化到所有节点。然后，客户端会向NameNode发送一个确认</li>
<li>如果管道中的任何一个DataNode失败，管道会被关闭。数据将会继续写到剩余的DataNode中。同时NameNode会被告知待备份状态，NameNode会继续备份数据到新的可用的节点</li>
<li>数据块都会通过计算校验和来检测数据的完整性，校验和以隐藏文件的形式被单独存放在hdfs中，供读取时进行完整性校验</li>
</ol>
<img src="/images/201702/hdfs1_4.png">
<h2 id="HDFS的优缺点"><a href="#HDFS的优缺点" class="headerlink" title="HDFS的优缺点"></a>HDFS的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>高容错性<br>数据自动保存多个副本<br>副本丢失后，自动恢复</li>
<li>适合批处理<br>移动计算而非数据<br>数据位置暴露给计算框架</li>
<li>适合大数据处理<br>GB、TB、甚至PB级数据<br>百万规模以上的文件数量<br>10K+节点规模</li>
<li>流式文件访问<br>一次性写入，多次读取<br>保证数据一致性</li>
<li>可构建在廉价机器上<br>通过多副本提高可靠性<br>提供了容错和恢复机制<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3></li>
<li>低延迟与高吞吐率的数据访问</li>
<li>小文件存取<br>占用NameNode大量内存<br>寻道时间超过读取时间</li>
<li>并发写入、文件随机修改<br>一个文件同一个时间只能有一个写者 </li>
</ul>
<img src="/images/201702/hdfs1_5.png">
<p>参考文档:<br><a href="http://blog.csdn.net/suifeng3051/article/details/48548341" target="_blank" rel="external">http://blog.csdn.net/suifeng3051/article/details/48548341</a><br><a href="http://www.cnblogs.com/meet/p/5439805.html" target="_blank" rel="external">http://www.cnblogs.com/meet/p/5439805.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/19/一致性Hash/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/19/一致性Hash/" itemprop="url">
                  一致性Hash
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-19T19:19:15+08:00">
                2017-02-19
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="环形Hash空间"><a href="#环形Hash空间" class="headerlink" title="环形Hash空间"></a>环形Hash空间</h4><p>按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图<br><img src="/images/201702/hashCode_1.png"></p>
<h4 id="把数据通过一定的hash算法处理后映射到环上"><a href="#把数据通过一定的hash算法处理后映射到环上" class="headerlink" title="把数据通过一定的hash算法处理后映射到环上"></a>把数据通过一定的hash算法处理后映射到环上</h4><p>现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。<br>Hash(object1) = key1；<br>Hash(object2) = key2；<br>Hash(object3) = key3；<br>Hash(object4) = key4；<br>如下图：<br><img src="/images/201702/hashCode_2.png"></p>
<h4 id="将机器通过hash算法映射到环上"><a href="#将机器通过hash算法映射到环上" class="headerlink" title="将机器通过hash算法映射到环上"></a>将机器通过hash算法映射到环上</h4><p>在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。<br>假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中<br>Hash(NODE1) = KEY1;<br>Hash(NODE2) = KEY2;<br>Hash(NODE3) = KEY3;<br>其示意图如下：<br><img src="/images/201702/hashCode_3.png"></p>
<h4 id="机器的删除与添加"><a href="#机器的删除与添加" class="headerlink" title="机器的删除与添加"></a>机器的删除与添加</h4><p>普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。</p>
<ol>
<li>节点（机器）的删除<br>以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图：<img src="/images/201702/hashCode_4.png"></li>
<li>节点（机器）的添加<br>如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图：<img src="/images/201702/hashCode_5.png">
通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。<h4 id="解决平衡性问题"><a href="#解决平衡性问题" class="headerlink" title="解决平衡性问题"></a>解决平衡性问题</h4>根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。<br>——“虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。<br>以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下：<img src="/images/201702/hashCode_6.png">
根据上图可知对象的映射关系：object1-&gt;NODE1-1，object2-&gt;NODE1-2，object3-&gt;NODE3-2，object4-&gt;NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。</li>
</ol>
<p><strong>PS. 判定哈希算法好坏的四个定义：</strong></p>
<ul>
<li>平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</li>
<li>单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 </li>
<li>分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 </li>
<li>负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</li>
</ul>
<p>参考文档:<br><a href="http://blog.csdn.net/cywosp/article/details/23397179/" target="_blank" rel="external">http://blog.csdn.net/cywosp/article/details/23397179/</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/18/一个hive优化的例子/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/18/一个hive优化的例子/" itemprop="url">
                  一个Hive优化的例子
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-18T09:04:32+08:00">
                2017-02-18
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="表结构和需求"><a href="#表结构和需求" class="headerlink" title="表结构和需求"></a>表结构和需求</h3><h4 id="表"><a href="#表" class="headerlink" title="表"></a>表</h4><p>TableName: <strong>logFile</strong></p>
<table>
<thead>
<tr>
<th>id</th>
<th>city1</th>
<th>city2</th>
<th>city3</th>
<th>action</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>BeiJing</td>
<td>ShangHai</td>
<td>ShenZhen</td>
<td>Dance</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<p>TableName: <strong>City</strong></p>
<table>
<thead>
<tr>
<th>id</th>
<th>CityName</th>
<th>CityCode</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>BeiJing</td>
<td>Jing</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<h4 id="需求按照传统SQL语句"><a href="#需求按照传统SQL语句" class="headerlink" title="需求按照传统SQL语句:"></a>需求按照传统SQL语句:</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> b.action, a.CityCode, <span class="keyword">count</span>(<span class="number">1</span>)</div><div class="line"><span class="keyword">from</span> City a</div><div class="line"><span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line"><span class="keyword">on</span> (b.city1=a.CityName <span class="keyword">or</span> b.city2=a.CityName <span class="keyword">or</span> b.city3=a.CityName)</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> b.action, a.CityCode;</div></pre></td></tr></table></figure>
<h4 id="具体表和sql操作结果"><a href="#具体表和sql操作结果" class="headerlink" title="具体表和sql操作结果:"></a>具体表和sql操作结果:</h4><img src="/images/201702/hive_ex_1.png">
<h3 id="把SQL复制到Hive中执行-—-gt-笛卡尔积"><a href="#把SQL复制到Hive中执行-—-gt-笛卡尔积" class="headerlink" title="把SQL复制到Hive中执行 —&gt; 笛卡尔积"></a>把SQL复制到Hive中执行 —&gt; 笛卡尔积</h3><p><strong>报错!</strong> 这是因为 hive 受限于 MapReduce 算法模型，只支持 equi-joins（等值join），要实现上述的非等值 join，可以采用笛卡儿积(full Cartesian product)来实现：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> b.action, a.CityCode, <span class="keyword">count</span>(<span class="number">1</span>)</div><div class="line"><span class="keyword">from</span> City a</div><div class="line"><span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line"><span class="keyword">where</span> (b.city1=a.CityName <span class="keyword">or</span> b.city2=a.CityName <span class="keyword">or</span> b.city3=a.CityName)</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> b.action, a.CityCode;</div></pre></td></tr></table></figure></p>
<h3 id="笛卡尔积占用资源太大-—-gt-union-all"><a href="#笛卡尔积占用资源太大-—-gt-union-all" class="headerlink" title="笛卡尔积占用资源太大 —&gt; union all"></a>笛卡尔积占用资源太大 —&gt; union all</h3><p><strong>笛卡尔积默认不让执行</strong><br>既然不允许非等值 join，采用多个子查询union all，然后汇总(假设logFile表中每一行的三个city都不一样)<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> tmp.action, tmp.CityCode, <span class="keyword">count</span>(<span class="number">1</span>)</div><div class="line"><span class="keyword">from</span></div><div class="line">(</div><div class="line">    <span class="keyword">select</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city1</div><div class="line">    <span class="keyword">union</span> all</div><div class="line">    <span class="keyword">select</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city2</div><div class="line">    <span class="keyword">union</span> all</div><div class="line">    <span class="keyword">select</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city3</div><div class="line">)tmp</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">action</span>, CityCode</div></pre></td></tr></table></figure></p>
<h3 id="优化：map-side-join"><a href="#优化：map-side-join" class="headerlink" title="优化：map side join"></a>优化：map side join</h3><p>如果City是一张小表<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">select</span> tmp.action, tmp.CityCode, <span class="keyword">count</span>(<span class="number">1</span>)</div><div class="line"><span class="keyword">from</span></div><div class="line">(</div><div class="line">    <span class="keyword">select</span> <span class="comment">/*+ MAPJOIN(a) */</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city1</div><div class="line">    <span class="keyword">union</span> all</div><div class="line">    <span class="keyword">select</span> <span class="comment">/*+ MAPJOIN(a) */</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city2</div><div class="line">    <span class="keyword">union</span> all</div><div class="line">    <span class="keyword">select</span> <span class="comment">/*+ MAPJOIN(a) */</span> b.action <span class="keyword">action</span>, a.CityCode CityCode</div><div class="line">    <span class="keyword">from</span> City a</div><div class="line">    <span class="keyword">join</span> <span class="keyword">logFile</span> b</div><div class="line">    <span class="keyword">on</span> a.CityName = b.city3</div><div class="line">)tmp</div><div class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">action</span>, CityCode</div></pre></td></tr></table></figure></p>
<h2 id="开启-parallel"><a href="#开启-parallel" class="headerlink" title="开启 parallel"></a>开启 parallel</h2><p>三个 union 语句之间没有依赖关系，其实是可以并行执行的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> hive.exec.parallel=<span class="literal">true</span>;</div></pre></td></tr></table></figure></p>
<p>参考文档:<br><a href="https://my.oschina.net/leejun2005/blog/307812" target="_blank" rel="external">https://my.oschina.net/leejun2005/blog/307812</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/17/hive的join操作/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/17/hive的join操作/" itemprop="url">
                  Hive的join操作
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-17T11:26:04+08:00">
                2017-02-17
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="join类型"><a href="#join类型" class="headerlink" title="join类型"></a>join类型</h2><ul>
<li>内关联（JOIN）</li>
<li>左外关联（LEFT [OUTER] JOIN)</li>
<li>右外关联（RIGHT [OUTER] JOIN）</li>
<li>全外关联（FULL [OUTER] JOIN）</li>
<li>LEFT SEMI JOIN</li>
<li>笛卡尔积关联（CROSS JOIN）</li>
</ul>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p>TableName: <strong>Name</strong></p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>zhangsan</td>
</tr>
<tr>
<td>2</td>
<td>lisi</td>
</tr>
<tr>
<td>3</td>
<td>wangwu</td>
</tr>
</tbody>
</table>
<p>TableName: <strong>Age</strong></p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>30</td>
</tr>
<tr>
<td>2</td>
<td>29</td>
</tr>
<tr>
<td>4</td>
<td>21</td>
</tr>
</tbody>
</table>
<h2 id="内关联（JOIN）"><a href="#内关联（JOIN）" class="headerlink" title="内关联（JOIN）"></a>内关联（JOIN）</h2><p>返回能关联上的结果<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a</div><div class="line"><span class="keyword">join</span> Age b</div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">--执行结果</span></div><div class="line">1       zhangsan    30</div><div class="line">2       lisi        29</div></pre></td></tr></table></figure></p>
<h2 id="左外关联（LEFT-OUTER-JOIN）"><a href="#左外关联（LEFT-OUTER-JOIN）" class="headerlink" title="左外关联（LEFT [OUTER] JOIN）"></a>左外关联（LEFT [OUTER] JOIN）</h2><p>以LEFT [OUTER] JOIN关键字 <strong>前面的表</strong> 作为主表，和其他表进行关联，返回记录和主表的记录数一致，关联不上的字段置为NULL。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">left</span> <span class="keyword">join</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1   zhangsan   30</div><div class="line">2   lisi       29</div><div class="line">3   wangwu     NULL</div></pre></td></tr></table></figure></p>
<h2 id="右外关联（RIGHT-OUTER-JOIN）"><a href="#右外关联（RIGHT-OUTER-JOIN）" class="headerlink" title="右外关联（RIGHT [OUTER] JOIN）"></a>右外关联（RIGHT [OUTER] JOIN）</h2><p>和左外关联相反，以RIGTH [OUTER] JOIN关键词 <strong>后面的表</strong> 作为主表，和前面的表做关联，返回记录数和主表一致，关联不上的字段为NULL。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">RIGHT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1          zhangsan    30</div><div class="line">2          lisi        29</div><div class="line">NULL       NULL        21</div></pre></td></tr></table></figure></p>
<h2 id="全外关联（FULL-OUTER-JOIN）"><a href="#全外关联（FULL-OUTER-JOIN）" class="headerlink" title="全外关联（FULL [OUTER] JOIN）"></a>全外关联（FULL [OUTER] JOIN）</h2><p>以两个表的记录为基准，返回两个表的记录去重之和，关联不上的字段为NULL。<br><em>注意：FULL JOIN时候，Hive不会使用MapJoin来优化。</em><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1       zhangsan        30</div><div class="line">2       lisi            29</div><div class="line">3       wangwu          NULL</div><div class="line">NULL    NULL            21</div></pre></td></tr></table></figure></p>
<h2 id="LEFT-SEMI-JOIN"><a href="#LEFT-SEMI-JOIN" class="headerlink" title="LEFT SEMI JOIN"></a>LEFT SEMI JOIN</h2><p>以LEFT SEMI JOIN关键字 <strong>前面的表</strong> 为主表，返回主表的KEY也在副表中的记录 <em>(相当于mysql中的 <strong>in</strong> 操作)。</em><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">LEFT</span> SEMI <span class="keyword">JOIN</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1       zhangsan</div><div class="line">2       lisi</div><div class="line"> </div><div class="line"><span class="comment">--等价于：</span></div><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">WHERE</span> a.id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> Age);</div><div class="line"> </div><div class="line"> </div><div class="line"><span class="comment">--也等价于：</span></div><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">join</span> Age b </div><div class="line"><span class="keyword">ON</span> (a.id = b.id);</div><div class="line"> </div><div class="line"><span class="comment">--也等价于：</span></div><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name </div><div class="line"><span class="keyword">FROM</span> <span class="keyword">Name</span> a </div><div class="line"><span class="keyword">WHERE</span> <span class="keyword">EXISTS</span> (<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">FROM</span> Age b <span class="keyword">WHERE</span> a.id = b.id);</div></pre></td></tr></table></figure></p>
<h2 id="笛卡尔积关联（CROSS-JOIN）"><a href="#笛卡尔积关联（CROSS-JOIN）" class="headerlink" title="笛卡尔积关联（CROSS JOIN）"></a>笛卡尔积关联（CROSS JOIN）</h2><p>返回两个表的笛卡尔积结果，不需要指定关联键。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> a.id,</div><div class="line">a.name,</div><div class="line">b.age </div><div class="line"><span class="keyword">FROM</span> lxw1234_a a </div><div class="line"><span class="keyword">CROSS</span> <span class="keyword">JOIN</span> lxw1234_b b;</div><div class="line"> </div><div class="line"><span class="comment">--执行结果：</span></div><div class="line">1       zhangsan        30</div><div class="line">1       zhangsan        29</div><div class="line">1       zhangsan        21</div><div class="line">2       lisi            30</div><div class="line">2       lisi            29</div><div class="line">2       lisi            21</div><div class="line">3       wangwu          30</div><div class="line">3       wangwu          29</div><div class="line">3       wangwu          21</div></pre></td></tr></table></figure></p>
<h2 id="map-site-JOIN"><a href="#map-site-JOIN" class="headerlink" title="map-site JOIN"></a>map-site JOIN</h2><p>如果所有表中只有一张表是小表，那么可以在最大的表通过Mapper的时候将小标完全放倒内存中。Hive可以在map端执行连接过程（称为map-site join）。这样做的优点：</p>
<ul>
<li>小表加入内存，省去常规连接操作所需要的reduce过程</li>
<li>同时减少map过程的执行步骤</li>
</ul>
<h3 id="方法一-直接通过SQL声明"><a href="#方法一-直接通过SQL声明" class="headerlink" title="方法一:直接通过SQL声明"></a>方法一:直接通过SQL声明</h3><p>select /<em>+mapjoin(a)</em>/ a.col1,b.col2<br>from table_a a join table_b b on a.col1=b.col1</p>
<h3 id="方法二-Hive配置来启用，用户也可以配置能够使用这个优化的小表大小"><a href="#方法二-Hive配置来启用，用户也可以配置能够使用这个优化的小表大小" class="headerlink" title="方法二:Hive配置来启用，用户也可以配置能够使用这个优化的小表大小"></a>方法二:Hive配置来启用，用户也可以配置能够使用这个优化的小表大小</h3><p>set hive.auto.convert.join=true;<br>set hive.mapjoin.smalltable.filesize=250000;<br>select a.col1,b.col2<br>from table_a a join table_b b on a.col1=b.col1</p>
<h3 id="mapjoin-还有一个很大的好处是能够进行不等连接的join操作"><a href="#mapjoin-还有一个很大的好处是能够进行不等连接的join操作" class="headerlink" title="mapjoin 还有一个很大的好处是能够进行不等连接的join操作"></a>mapjoin 还有一个很大的好处是能够进行不等连接的join操作</h3><p>如果将不等条件写在where中，那么mapreduce过程中会进行笛卡尔积，运行效率特别低，如果使用mapjoin操作，在map的过程中就完成了不等值的join操作，效率会高很多。<br>例子：<br>select A.a ,A.b from A join B where A.a&gt;B.a</p>
<h3 id="mapjoin的使用场景："><a href="#mapjoin的使用场景：" class="headerlink" title="mapjoin的使用场景："></a>mapjoin的使用场景：</h3><ul>
<li>关联操作中有一张表非常小</li>
<li>不等值的链接操作</li>
</ul>
<p>参考文档：<br><a href="http://lxw1234.com/archives/2015/06/315.htm" target="_blank" rel="external">http://lxw1234.com/archives/2015/06/315.htm</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/16/MapReduce自定义二次排序/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/16/MapReduce自定义二次排序/" itemprop="url">
                  MapReduce自定义二次排序
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-16T20:14:34+08:00">
                2017-02-16
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="具体需求"><a href="#具体需求" class="headerlink" title="具体需求"></a>具体需求</h2><p>1、输入数据：<br>sort1    1<br>sort2    3<br>sort2    77<br>sort2    54<br>sort1    2<br>sort6    22<br>sort6    221<br>sort6    20<br>2、目标输出<br>sort1 1,2<br>sort2 3,54,77<br>sort6 20,22,221</p>
<h2 id="二次排序解决思路"><a href="#二次排序解决思路" class="headerlink" title="二次排序解决思路"></a>二次排序解决思路</h2><p>MapReduce框架不管是默认排序或者是自定义排序都只是对Key值进行排序，现在的情况是这些数据不是key值，怎么办？其实我们可以将原始数据的Key值和其对应的数据组合成一个新的Key值，然后新的Key值对应的还是之前的数字。那么我们就可以将原始数据的map输出变成类似下面的数据结构：<br>{[sort1,1],1}<br>{[sort2,3],3}<br>{[sort2,77],77}<br>{[sort2,54],54}<br>{[sort1,2],2}<br>{[sort6,22],22}<br>{[sort6,221],221}<br>{[sort6,20],20}<br>那么我们只需要对[]里面的新key值进行排序就ok了。然后我们需要自定义一个分区处理器，因为我的目标不是想将新key相同的传到同一个reduce中，而是想将新key中的第一个字段相同的才放到同一个reduce中进行分组合并，所以我们需要根据新key值中的第一个字段来自定义一个分区处理器。通过分区操作后，得到的数据流如下：<br>Partition1:{[sort1,1],1}、{[sort1,2],2}<br>Partition2:{[sort2,3],3}、{[sort2,77],77}、{[sort2,54],54}<br>Partition3:{[sort6,22],22}、{[sort6,221],221}、{[sort6,20],20}</p>
<h2 id="MR的运行流程简单说明"><a href="#MR的运行流程简单说明" class="headerlink" title="MR的运行流程简单说明"></a>MR的运行流程简单说明</h2><img src="/images/201702/map.png">
<img src="/images/201702/reduce.png">
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><img src="/images/201702/map_secondSort.png">
<img src="/images/201702/reduce_secondSort.png">
<h3 id="自定义组合键-更改key结构"><a href="#自定义组合键-更改key结构" class="headerlink" title="自定义组合键(更改key结构)"></a>自定义组合键(更改key结构)</h3><p>自定义组合键的时候，我们需要特别注意，一定要实现WritableComparable接口，并且实现compareTo方法的比较策略。这个用于mapreduce的第一次默认排序，也就是发生在map阶段的sort小阶段，发生地点为环形缓冲区(可以通过io.sort.mb进行大小调整)，但是其对我们最终的二次排序结果是没有影响的。我们二次排序的最终结果是由我们的自定义比较器决定的。</p>
<h3 id="自定义分区器"><a href="#自定义分区器" class="headerlink" title="自定义分区器"></a>自定义分区器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//默认的Hash分区</span></div><div class="line">key.hashCode()&amp;Integer.MAX_VALUE)%numPartitions</div><div class="line"><span class="comment">//自定义分区</span></div><div class="line">key.getFirstKey().hashCode()&amp;Integer.MAX_VALUE)%numPartitions</div></pre></td></tr></table></figure>
<h3 id="自定义比较器"><a href="#自定义比较器" class="headerlink" title="自定义比较器"></a>自定义比较器</h3><p>自定义比较器决定了我们二次排序的结果。自定义比较器需要继承WritableComparator类，并且重写compare方法实现自己的比较策略。</p>
<h3 id="自定义分组策略"><a href="#自定义分组策略" class="headerlink" title="自定义分组策略"></a>自定义分组策略</h3><p>将组合键中第一个值相同的分在一组<br>PS. 每处理完一个分组数据就会去调用一次的reduce函对这个分组来进行处理和输出</p>
<p>JAVA代码在下面参考资料(PS. 因为不会JAVA，所以我的重点在理解)<br>参考资料：<br><a href="http://zengzhaozheng.blog.51cto.com/8219051/1379271" target="_blank" rel="external">http://zengzhaozheng.blog.51cto.com/8219051/1379271</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/15/MapReduce的Shuffle过程/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/15/MapReduce的Shuffle过程/" itemprop="url">
                  MapReduce的Shuffle过程
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-15T11:12:32+08:00">
                2017-02-15
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>官网上Shuffle过程的图:<br><img src="/images/201702/mr_1.png"></p>
<p>举例(WordCount)：<br>File 1 内容：</p>
<blockquote>
<p>My name is Tony<br>My company is pivotal</p>
</blockquote>
<p>File 2 内容：</p>
<blockquote>
<p>My name is Lisa<br>My company is EMC</p>
</blockquote>
<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>Map端数据的处理详细过程如下图：<br><img src="/images/201702/mr_2.png"></p>
<ul>
<li>从磁盘上读取数据</li>
<li>执行map函数</li>
<li>Partition分区(放进内存)</li>
<li>Sort排序(内存排序)</li>
<li>Combine结果(内存预聚合)</li>
<li>将结果写到本地的磁盘上</li>
<li>Merge(对磁盘上的文件合并)</li>
</ul>
<h3 id="执行map函数后"><a href="#执行map函数后" class="headerlink" title="执行map函数后"></a>执行map函数后</h3><p>执行用户编写的map函数<br>接着上面例子:<br><strong>split 0</strong></p>
<blockquote>
<p>My       1<br>name    1<br>is         1<br>Tony     1<br>My          1<br>company     1<br>is       1<br>Pivotal   1</p>
</blockquote>
<p><strong>split 1</strong></p>
<blockquote>
<p>My       1<br>name    1<br>is       1<br>Lisa     1<br>My       1<br>company  1<br>is       1<br>EMC   　　1</p>
</blockquote>
<h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><p>为什么要分区？ 因为有时候会有多个Reducer, Partition就是提前对输入进行处理， 根据将来的Reducer进行分区. 到时候Reducer处理的时候，只需要处理分给自己的数据就可以了。<br>MR自带了一个默认的分区类，HashPartitioner<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K key, V value, <span class="keyword">int</span> numReduceTasks)</span> </span>&#123; </div><div class="line">    <span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks; </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>PS.  numReduceTasks(reduceTask的数量)是用户在提交前设定的，默认为1</p>
<p>结合例子，假设有两个Reducer, 前面两个split做完Partition的结果就会如下：<br><strong>split 0</strong></p>
<blockquote>
<p>Partition 1:<br>company    1<br>is    1<br>is    1</p>
<p>Partition 2:<br>My    1<br>My    1<br>name    1<br>Pivotal    1<br>Tony    1</p>
</blockquote>
<p><strong>split 1</strong></p>
<blockquote>
<p>Partition 1:<br>company    1<br>is    1<br>is    1<br>EMC    1</p>
<p>Partition 2:<br>My    1<br>My    1<br>name    1<br>Lisa    1</p>
</blockquote>
<p>key/value对以及Partition的结果(属于哪个reduce)都会被写入缓冲区。写入之前，key与value 值都会被序列化成字节数组</p>
<h3 id="Sort"><a href="#Sort" class="headerlink" title="Sort"></a>Sort</h3><p>作用：把内存缓冲区中的数据写入到本地磁盘，在写入本地磁盘时先按照partition、再按照key进行排序（quick sort）<br>1、这个spill是由另外单独的线程来完成，不影响往缓冲区写map结果的线程；<br>内存缓冲区默认大小限制为100MB，它有个溢写比例（spill.percent），默认为0.8，当缓冲区的数据达到阈值时，溢写线程就会启动，先锁定这80MB的内存，执行溢写过程，maptask的输出结果还可以往剩下的20MB内存中写，互不影响。然后再重新利用这块缓冲区，因此Map的内存缓冲区又叫做环形缓冲区（两个指针的方向不会变，下面会详述）；<br>2、在将数据写入磁盘之前，先要对要写入磁盘的数据进行一次排序操作，先按<key,value,partition>中的partition分区号排序，然后再按key排序，这个就是sort操作，最后溢出的小文件是分区的，且同一个分区内是保证key有序的；</key,value,partition></p>
<p>接着例子说明(split文件里格式: key,value,partition)：<br><strong>split 0</strong></p>
<blockquote>
<p>company    1    1<br>is    1    1<br>is    1    1<br>My    1    2<br>My    1    2<br>name    1    2<br>Pivotal    1    2<br>Tony    1    2</p>
</blockquote>
<p><strong>split 1</strong></p>
<blockquote>
<p>company    1    1<br>is    1    1<br>is    1    1<br>EMC    1    1<br>My    1    2<br>My    1    2<br>name    1    2<br>Lisa    1    2</p>
</blockquote>
<h3 id="Combine"><a href="#Combine" class="headerlink" title="Combine"></a>Combine</h3><p>combine：执行combine操作要求开发者必须在程序中设置了combine（程序中通过job.setCombinerClass(myCombine.class)自定义combine操作)<br>程序中有<strong>两个阶段</strong>可能会执行combine操作：<br>1、map输出数据根据分区排序完成后，在写入文件之前会执行一次combine操作<br>2、(下面merge过程)如果map输出比较大，溢出文件个数大于  <strong>3</strong>  （此值可以通过属性min.num.spills.for.combine配置）时，在merge的过程（多个spill文件合并为一个大文件）中还会执行combine操作<br>combine主要是把形如<aa,1>,<aa,2>这样的key值相同的数据进行计算，计算规则与reduce一致，比如：当前计算是求key对应的值求和，则combine操作后得到<aa,3>这样的结果</aa,3></aa,2></aa,1></p>
<p>接着例子说明:<br><strong>split 0</strong></p>
<blockquote>
<p>company    1    1<br>is    2    1<br>My    2    2<br>name    1    2<br>Pivotal    1    2<br>Tony    1    2</p>
</blockquote>
<p><strong>split 1</strong></p>
<blockquote>
<p>company    1    1<br>EMC    1    1<br>is    2    1<br>name    1    2<br>Lisa    1    2<br>My    2    2</p>
</blockquote>
<h3 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h3><p>merge过程：当map很大时，每次溢写会产生一个spill_file，这样会有多个spill_file，而最终的一个map task输出只有一个文件，因此，最终的结果输出之前会对多个中间过程进行多次溢写文件（spill_file）的合并，此过程就是merge过程。也即是，待Map Task任务的所有数据都处理完后，会对任务产生的所有中间数据文件做一次合并操作，以确保一个Map Task最终只生成一个中间数据文件。<br>注意：<br>1、如果生成的文件太多，可能会执行多次合并，每次最多能合并的文件数默认为  <strong>10</strong>  ，可以通过属性min.num.spills.for.combine配置；<br>2、多个溢出文件合并时，会进行一次排序，排序算法是多路归并排序<br>3、最终生成的文件格式与单个溢出文件一致，也是按分区顺序存储，并且输出文件会有一个对应的索引文件，记录每个分区数据的起始位置，长度以及压缩长度，这个索引文件名叫做file.out.index</p>
<p>例子没有Merge过程，所以省略</p>
<h2 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h2><img src="/images/201702/mr_3.png">
<h3 id="Copy"><a href="#Copy" class="headerlink" title="Copy"></a>Copy</h3><p>作用：拉取数据<br>过程：Reduce进程启动一些数据copy线程(Fetcher)，通过HTTP方式请求map task所在的TaskTracker获取map task的输出文件。因为这时map task早已结束，这些文件就归TaskTracker管理在本地磁盘中<br>默认情况下，当整个MapReduce作业的所有已执行完成的Map Task任务数超过Map Task总数的5%后，JobTracker便会开始调度执行Reduce Task任务。然后Reduce Task任务默认启动mapred.reduce.parallel.copies(默认为5）个MapOutputCopier线程到已完成的Map Task任务节点上分别copy一份属于自己的数据。 这些copy的数据会首先保存的内存缓冲区中，当内冲缓冲区的使用率达到一定阀值后，则写到磁盘上</p>
<p>接着上面例子：<br><strong>Reducer 节点 1</strong> 共包含两个文件:</p>
<blockquote>
<p>split 0:<br>company    1<br>is    2</p>
<p>split 1:<br>company    1<br>EMC    1<br>is    2</p>
</blockquote>
<p><strong>Reducer 节点 2</strong> 共包含两个文件:</p>
<blockquote>
<p>split 0:<br>name    1<br>Pivotal    1<br>Tony    1<br>My    2</p>
<p>split 1:<br>name    1<br>Lisa    1<br>My    2</p>
</blockquote>
<h3 id="Merge-1"><a href="#Merge-1" class="headerlink" title="Merge"></a>Merge</h3><p>Copy过来的数据会先放入内存缓冲区中，因为 Shuffle 阶段 Reducer 不运行，所以应该把绝大部分的内存都给 Shuffle 用<br>merge 有三种形式：1)内存到内存 2)内存到磁盘 3)磁盘到磁盘。默认情况下第一种形式是不启用的。当内存中的数据量到达一定阈值，就启动内存到磁盘的 merge（图中的第一个merge，之所以进行merge是因为reduce端在从多个map端copy数据的时候，并没有进行sort，只是把它们加载到内存，当达到阈值写入磁盘时，需要进行merge） 。这和map端的很类似，这实际上就是溢写的过程，在这个过程中如果你设置有Combiner，它也是会启用的，然后在磁盘中生成了众多的溢写文件，这种merge方式一直在运行，直到没有 map 端的数据时才结束，然后才会启动第三种磁盘到磁盘的 merge （图中的第二个merge）方式生成最终的那个文件。<br>在远程copy数据的同时(一边Copy一边Merge)，Reduce Task在后台启动了两个后台线程对内存和磁盘上的数据文件做合并操作，以防止内存使用过多或磁盘生的文件过多。</p>
<p>接着上面例子：<br><strong>Reducer 节点 1</strong></p>
<blockquote>
<p>company    1<br>is    2<br>company    1<br>EMC    1<br>is    2</p>
</blockquote>
<p><strong>Reducer 节点 2</strong></p>
<blockquote>
<p>name    1<br>Pivotal    1<br>Tony    1<br>My    2<br>name    1<br>Lisa    1<br>My    2</p>
</blockquote>
<p>参考博客：<br><a href="http://wangzzu.github.io/2016/03/02/hadoop-shuffle/" target="_blank" rel="external">http://wangzzu.github.io/2016/03/02/hadoop-shuffle/</a><br><a href="https://my.oschina.net/dataRunner/blog/611293" target="_blank" rel="external">https://my.oschina.net/dataRunner/blog/611293</a><br><a href="http://www.cnblogs.com/npumenglei/p/3631244.html" target="_blank" rel="external">http://www.cnblogs.com/npumenglei/p/3631244.html</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/14/Hadoop计算Map数/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/14/Hadoop计算Map数/" itemprop="url">
                  Hadoop计算Map数
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-14T22:24:33+08:00">
                2017-02-14
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="计算splitSize"><a href="#计算splitSize" class="headerlink" title="计算splitSize"></a>计算splitSize</h3><p>split的个数由FileInputFormat.getSplits计算出，方法的逻辑如下:<br>1、读取参数mapred.map.tasks，这个参数默认设置为1<br>2、goalSize = totalSize(input文件的总字节数) / mapred.map.tasks<br>3、minSize指的是每个split的最小值，由mapred.min.split.size参数设置，这个参数默认设置为1B<br>4、blockSize，文件物理划分成块，大小配置在hadoop-default.xml，它的默认值是64MB<br>5、splitSize= Math.max(minSize, Math.min(goalSize, blockSize))</p>
<h3 id="通过splitSize逻辑划分文件，计算split的个数-job的MapTask数量就等于split的个数"><a href="#通过splitSize逻辑划分文件，计算split的个数-job的MapTask数量就等于split的个数" class="headerlink" title="通过splitSize逻辑划分文件，计算split的个数(job的MapTask数量就等于split的个数)"></a>通过splitSize逻辑划分文件，计算split的个数(job的MapTask数量就等于split的个数)</h3><p>计算方法逻辑如下:<br>1、 文件大小/splitSize &gt; 1.1，创建一个split，这个split的大小=splitSize，文件剩余大小=文件大小-splitSize<br>2、 文件剩余大小/splitSize&lt;1.1，剩余的部分作为一个split<br>举例:<br>1.input只有一个文件，大小为100M，splitSize为64M。则Split数为2，一个64M，一个36M<br>2.input只有一个文件，大小为65M，splitSize为64M。则Split数为1，split大小为65M<br>3.input只有一个文件，大小为129M，splitSize为64M。则Split数为2，一个64M，一个65M<br>4.input只有一个文件，大小为20M，splitSize为64M。则Split数为1，split大小为20M<br>两个特殊例子:<br>1.input两个文件，分别为40M和20M，mapred.map.tasks人工设置为2。则goalSize=(40+20)/2=30M，splitSize为30M。逻辑切分文件后，第一个文件切分成30M,10M两个split，第二个还是20M。最后有3个MapTask<br>2.input两个文件，分别为40M和20M，mapred.map.tasks默认为1。则goalSize=(40+20)/1=60M，splitSize为60M。逻辑切分文件最后生成两个切片，一个40M，一个20M。即2个MapTask<br>特殊例子总结：<br>mapred.map.tasks并不是设置的越大，JOB执行的效率就越高。Hadoop在处理小文件时效率会变差。</p>
<img src="/images/201702/splitSize.png">
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/12/大数据初学者学习之路/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/12/大数据初学者学习之路/" itemprop="url">
                  大数据初学者学习之路
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-12T20:30:41+08:00">
                2017-02-12
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p>第一章：初识Hadoop<br>第二章：更高效的WordCount<br>第三章：把别处的数据搞到Hadoop上<br>第四章：把Hadoop上的数据搞到别处去<br>第五章：快一点吧，我的SQL<br>第六章：一夫多妻制<br>第七章：越来越多的分析任务<br>第八章：我的数据要实时<br>第九章：我的数据要对外<br>第十章：牛逼高大上的机器学习</p>
<h2 id="第一章：初识Hadoop"><a href="#第一章：初识Hadoop" class="headerlink" title="第一章：初识Hadoop"></a>第一章：初识Hadoop</h2><p>主要了解Hadoop基础知识，并且能搭建Hadoop，编写MR程序能跑起来</p>
<h2 id="第二章：更高效的WordCount"><a href="#第二章：更高效的WordCount" class="headerlink" title="第二章：更高效的WordCount"></a>第二章：更高效的WordCount</h2><p>使用SQL处理分析Hadoop上的数据，方便、高效、易上手、更是趋势<br>主要了解数据仓库工具——Hive，搭建Hive，学习Hive的基本命令<br><img src="/images/201702/lxw1234_1.png"></p>
<h2 id="第三章：把别处的数据搞到Hadoop上"><a href="#第三章：把别处的数据搞到Hadoop上" class="headerlink" title="第三章：把别处的数据搞到Hadoop上"></a>第三章：把别处的数据搞到Hadoop上</h2><p>把各个数据源的数据采集到Hadoop上<br>1、HDFS API<br>比如：Hive中的INSERT语句，Spark中的saveAsTextfile等<br>2、Sqoop<br>Sqoop是一个主要用于Hadoop/Hive与传统关系型数据库Oracle/MySQL/SQLServer等之间进行数据交换的开源框架。<br>3、Flume<br>Flume可以实时的从网络协议、消息系统、文件系统采集日志，并传输到HDFS上<br>4、阿里开源的DataX<br>Hadoop与关系型数据库数据交换的工具，和Sqoop很像<br><img src="/images/201702/lxw1234_2.png"></p>
<h2 id="第四章：把Hadoop上的数据搞到别处去"><a href="#第四章：把Hadoop上的数据搞到别处去" class="headerlink" title="第四章：把Hadoop上的数据搞到别处去"></a>第四章：把Hadoop上的数据搞到别处去</h2><p>1、HDFS API<br>2、Sqoop<br>3、DataX<br><img src="/images/201702/lxw1234_3.png"></p>
<h2 id="第五章：快一点吧，我的SQL"><a href="#第五章：快一点吧，我的SQL" class="headerlink" title="第五章：快一点吧，我的SQL"></a>第五章：快一点吧，我的SQL</h2><p>SQLOnHadoop的框架越来越多，按我的了解，最常用的按照流行度依次为SparkSQL、Impala和Presto.<br>可以了解一下SparkSQL<br><img src="/images/201702/lxw1234_4.png"></p>
<h2 id="第六章：一夫多妻制"><a href="#第六章：一夫多妻制" class="headerlink" title="第六章：一夫多妻制"></a>第六章：一夫多妻制</h2><p>数据的一次采集、多次消费——kafka<br><img src="/images/201702/lxw1234_5.png"></p>
<h2 id="第七章：越来越多的分析任务"><a href="#第七章：越来越多的分析任务" class="headerlink" title="第七章：越来越多的分析任务"></a>第七章：越来越多的分析任务</h2><p>调度监控系统是整个数据平台的中枢系统，类似于AppMaster，负责分配和监控任务。<br>1、Apache Oozie 2、Azkaban 3、Zeus<br><img src="/images/201702/lxw1234_6.png"></p>
<h2 id="第八章：我的数据要实时"><a href="#第八章：我的数据要实时" class="headerlink" title="第八章：我的数据要实时"></a>第八章：我的数据要实时</h2><p>对于需要绝对实时的业务场景，用的比较多的是Storm，对于其他准实时的业务场景，可以是Storm，也可以是Spark Streaming<br><img src="/images/201702/lxw1234_7.png"></p>
<h2 id="第九章：我的数据要对外"><a href="#第九章：我的数据要对外" class="headerlink" title="第九章：我的数据要对外"></a>第九章：我的数据要对外</h2><p>离线：比如，每天将前一天的数据提供到指定的数据源（DB、FILE、FTP）等；<br>离线数据的提供可以采用Sqoop、DataX等离线数据交换工具。<br>实时：比如，在线网站的推荐系统，需要实时从数据平台中获取给用户的推荐数据，这种要求延时非常低（50毫秒以内）。<br>OLAP分析：OLAP除了要求底层的数据模型比较规范，另外，对查询的响应速度要求也越来越高，可能的方案有：Impala、Presto、SparkSQL、Kylin。如果你的数据模型比较规模，那么Kylin是最好的选择。<br>即席查询：即席查询的数据比较随意，一般很难建立通用的数据模型，因此可能的方案有：Impala、Presto、SparkSQL。<br>还有一些方案: HBase、Redis、MongoDB、ElasticSearch<br><img src="/images/201702/lxw1234_8.png"></p>
<h2 id="第十章：牛逼高大上的机器学习"><a href="#第十章：牛逼高大上的机器学习" class="headerlink" title="第十章：牛逼高大上的机器学习"></a>第十章：牛逼高大上的机器学习</h2><p>在我们的业务中，遇到的能用机器学习解决的问题大概这么三类：<br>1、分类问题：包括二分类和多分类，二分类就是解决了预测的问题，就像预测一封邮件是否垃圾邮件；多分类解决的是文本的分类；<br>2、聚类问题：从用户搜索过的关键词，对用户进行大概的归类。<br>3、推荐问题：根据用户的历史浏览和点击行为进行相关推荐。</p>
<p>转载:<a href="http://lxw1234.com/archives/2016/11/779.htm" target="_blank" rel="external">http://lxw1234.com/archives/2016/11/779.htm</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/08/Mongodb安装和简单使用/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xiwu1212@163.com">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Refrain">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Refrain" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/08/Mongodb安装和简单使用/" itemprop="url">
                  Mongodb安装和简单使用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-08T14:20:03+08:00">
                2017-02-08
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Mongodb-下载安装"><a href="#Mongodb-下载安装" class="headerlink" title="Mongodb 下载安装"></a>Mongodb 下载安装</h2><p>下载地址：<a href="http://www.mongodb.org/downloads" target="_blank" rel="external">http://www.mongodb.org/downloads</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tar -xzvf mongodb-osx-ssl-x86_64-3.4.2.tgz</div><div class="line">mv mongodb-osx-x86_64-3.4.2 /opt</div></pre></td></tr></table></figure></p>
<p>MongoDB 的可执行文件位于 bin 目录下，所以可以将其添加到 PATH 路径中：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> PATH=&lt;mongodb-install-directory&gt;/bin:<span class="variable">$PATH</span></div></pre></td></tr></table></figure></p>
<p><mongodb-install-directory> 为你 MongoDB 的安装路径。如本文的 /opt/mongodb-osx-x86_64-3.4.2</mongodb-install-directory></p>
<h2 id="创建数据库目录并启动"><a href="#创建数据库目录并启动" class="headerlink" title="创建数据库目录并启动"></a>创建数据库目录并启动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /data/mongodb_data</div><div class="line">mongod --dbpath /data/mongodb_data</div></pre></td></tr></table></figure>
<p>PS./data/db 是MongoDB默认启动的数据库目录<br>MongoDB 提供了简单的HTTP用户界面，启用该功能需要在启动的时候指定参数–rest<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mongod --dbpath /data/mongodb_data --rest</div></pre></td></tr></table></figure></p>
<p>登录<a href="http://localhost:28017/可查看" target="_blank" rel="external">http://localhost:28017/可查看</a><br><img src="/images/201702/mongodb_1.png"></p>
<h2 id="概念简单说明"><a href="#概念简单说明" class="headerlink" title="概念简单说明"></a>概念简单说明</h2><p>mongodb中基本的概念是文档、集合、数据库<br><img src="/images/201702/mongodb_2.png"></p>
<h2 id="简单shell操作"><a href="#简单shell操作" class="headerlink" title="简单shell操作"></a>简单shell操作</h2><p>之前启动了mongodb服务<br>在本机使用mongo命令进入客户端<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mongo</div></pre></td></tr></table></figure></p>
<h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">use DATABASE_NAME</div></pre></td></tr></table></figure>
<p>如果数据库不存在，则创建数据库，否则切换到指定数据库。<br><img src="/images/201702/mongodb_3.png"></p>
<h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">use DATABASE_NAME</div><div class="line">db.dropDatabase()</div></pre></td></tr></table></figure>
<p>先切换数据库，再使用删除命令<br><img src="/images/201702/mongodb_4.png"></p>
<h3 id="插入文档"><a href="#插入文档" class="headerlink" title="插入文档"></a>插入文档</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.COLLECTION_NAME.insert(document)</div></pre></td></tr></table></figure>
<p>例如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.insert(&#123;title: &apos;mongodbTest&apos;, tags: [&apos;mongodb&apos;, &apos;nosql&apos;]&#125;)</div></pre></td></tr></table></figure></p>
<p>以上实例中test1是我们的集合名，如果该集合不在该数据库中，MongoDB 会自动创建该集合并插入文档。<br>查看已插入文档：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.find()</div></pre></td></tr></table></figure></p>
<h3 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h3><h4 id="update"><a href="#update" class="headerlink" title="update"></a>update</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">db.collection.update(</div><div class="line">   &lt;query&gt;,</div><div class="line">   &lt;update&gt;,</div><div class="line">   &#123;</div><div class="line">     upsert: &lt;boolean&gt;,</div><div class="line">     multi: &lt;boolean&gt;,</div><div class="line">     writeConcern: &lt;document&gt;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<p>参数说明：<br>query : update的查询条件，类似sql update查询内where后面的。<br>update : update的对象和一些更新的操作符（如$,$inc…）等，也可以理解为sql update查询内set后面的<br>upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。<br>multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。<br>writeConcern :可选，抛出异常的级别。<br>例子:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.update(&#123;&apos;title&apos;:&apos;mongodbTest&apos;&#125;,&#123;$set:&#123;&apos;title&apos;:&apos;MongoDB&apos;&#125;&#125;)</div></pre></td></tr></table></figure></p>
<img src="/images/201702/mongodb_5.png">
<h4 id="save"><a href="#save" class="headerlink" title="save"></a>save</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">db.collection.save(</div><div class="line">   &lt;document&gt;,</div><div class="line">   &#123;</div><div class="line">     writeConcern: &lt;document&gt;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<p>参数说明：<br>document : 文档数据。<br>writeConcern :可选，抛出异常的级别。<br>例子:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.save(&#123;&quot;_id&quot; : ObjectId(&quot;589d38f38d1f1dec8daa9d27&quot;),&quot;title&quot; : &quot;mongodb&quot;,&quot;tags&quot; : [&quot;mongodb&quot;,&quot;NoSQL&quot;, &quot;database&quot;]&#125;)</div></pre></td></tr></table></figure></p>
<img src="/images/201702/mongodb_6.png">
<h3 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">db.collection.remove(</div><div class="line">   &lt;query&gt;,</div><div class="line">   &#123;</div><div class="line">     justOne: &lt;boolean&gt;,</div><div class="line">     writeConcern: &lt;document&gt;</div><div class="line">   &#125;</div><div class="line">)</div></pre></td></tr></table></figure>
<p>参数说明：<br>query :（可选）删除的文档的条件。<br>justOne : （可选）如果设为 true 或 1，则只删除一个文档。<br>writeConcern :（可选）抛出异常的级别。<br>例:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.remove(&#123;&apos;title&apos;:&apos;mongodb&apos;&#125;)</div></pre></td></tr></table></figure></p>
<h3 id="查询文档"><a href="#查询文档" class="headerlink" title="查询文档"></a>查询文档</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.collection.find(&#123;key1:value1, key2:value2&#125;).pretty()</div></pre></td></tr></table></figure>
<p>例:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">db.test1.find(&#123;&apos;title&apos;:&apos;mongodb&apos;&#125;).pretty()</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="xiwu1212@163.com" />
          <p class="site-author-name" itemprop="name">xiwu1212@163.com</p>
          <p class="site-description motion-element" itemprop="description">学无止境</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">28</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiwu1212@163.com</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  




  
  

  

  

  

  


</body>
</html>
